
# More about CIs {#AboutCIs}


::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
So far, you have learnt to
ask a RQ, 
identify different ways of obtaining data,
design the study,
collect the data
describe the data,
summarise data graphically and numerically,
and
understand the tools of inference.

**In this chapter**,
you will learn more about *confidence intervals*.
:::





```{r echo=FALSE, fig.cap="", fig.align="center", fig.width=3, out.width="35%"}
SixSteps(5, "Confidence intervals")
```


## General comments

The previous chapter discussed forming a confidence interval (CI) for one proportion.
We will also study CIs in other contexts too.

The following applies to *all* CIs:

* CIs are formed for the unknown *population* parameter (such as the population proportion $p$), based on a *sample* statistic (such as the sample proportion $\hat{p}$).
* CIs give an interval in which the sample statistic is likely to lie, over repeated sampling.
* Loosely speaking, this is usually interpreted as the CIs giving an interval which is likely to straddle the value of the unknown *population* quantity.
  That is, the CI gives an interval of plausible values of the population parameter that may have produced the observed sample statistic.
* Most CIs have the form
   \[
      \text{Statistic} \pm \overbrace{(\text{Multiplier} \times \text{standard error})}^{\text{Called the `margin of error'}}.
   \] 
* The *multiplier* is *approximately* 2 for a 95% CI (from the [68--95--99.7 rule](#def:EmpiricalRule)).
* The *margin of error* is $(\text{Multiplier} \times \text{standard error})$.
* The statistical conditions should always be checked to see if the CI is (at least approximately) statistically valid.







## Interpretation of a CI {#CIInterpretation}

Interpreting CIs correctly is tricky.
The *correct* interpretation (Definition&nbsp;\@ref(def:ConfidenceInterval)) of a 95% CI is the following:

> *If* samples were repeatedly taken many times, and the 95% confidence interval computed for each sample, 95% of these confidence intervals formed would contain the population [*parameter*](#def:Parameter).

This is the idea shown in
`r if (knitr::is_latex_output()) {
   'Fig. \\@ref(fig:RollDiceCIFig).'
} else {
   'the animation in Sect. \\@ref(ConfIntPUnknownP).'
}`
In practice, this definition is unsatisfying, since we almost always have only *one* sample.
And since the value of the parameter is unknown (after all, we went to the bother of taking a sample so we could *estimate* the value of the parameter), we don't know if *our* CI includes the population parameter or not.

A reasonable alternative interpretation is:

> The interval gives a range of values of the parameter that could plausibly (with 95% confidence) have given rise to our observed value of the statistic.

Or we might say that:

> There is a 95% chance that our computed CI straddles the value of the population parameter.

These alternatives are not absolutely correct, but are reasonable interpretations.

Many people will write---and you will see it written in many places---that the CI means that there is a 95% chance that the CI contains the population [parameter](#StatisticsAndParameters).
This is not strictly correct, but is common (probably because it is easier to understand).

I use this analogy:
Most people say the sun rises in the east.
This is incorrect: the sun doesn't *rise* at all.
It *appears* to rise in the east because the earth rotates on its axis.
But almost everyone says that the 'sun rises in the east', and for most circumstances this is fine and serviceable, even though technically incorrect.

Similarly, most people use the final interpretation above for a CI in practice, even though it is technically incorrect.



<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/tin-1568095_640.jpg" width="200px"/>
</div>



`r if (knitr::is_html_output()) '<!--'`
\begin{wrapfigure}{R}{.25\textwidth}
  \begin{center}
    \includegraphics[width=.20\textwidth]{Illustrations/tin-1568095_640.jpg}
  \end{center}
\end{wrapfigure}
`r if (knitr::is_html_output()) '-->'`




::: {.example #EnergyDrinks name="Energy drinks in Canadian youth"}
In Example \@ref(exm:CanadianEnergyDrinks), the approximate 95% CI was from 0.192 to 0.236.
The correct interpretation is:

> If we took many samples of 1516 Canadian youth, and computed the approximate 95% CI for each one, about 95% of those CIs would contain the population proportion.

We don't know if *our* CI includes the value of $p$, however.
We might say:

> This 95% CI is likely to straddle the actual value of $p$. 

or

> The range of values of $p$ that could plausibly (with 95% confidence) have produced $\hat{p} = 0.241$ is between 0.192 and 0.236. 

In practice, the CI is usually interpreted as saying:

> There is a 95% chance that the population proportion of Canadian youth who have experienced sleeping difficulties after consuming energy drinks is between 0.192 to 0.236.

This is not strictly correct, but is commonly used and sufficient for us.
:::


::: {.thinkBox .think data-latex="{iconmonstr-light-bulb-2-240.png}"}
In Example \@ref(exm:KoalasCrossingRoads) about koalas crossing roads, the approximate 95% CI was from 0.130 to 0.209.

What is the correct interpretation of this CI?

`r webexercises::hide()`
The correct interpretation is: 

> If we took many similar samples, about 95% of these would contain the population proportion

We might also say this:

> There is a 95% chance that this CI we computed straddles the population proportion.

In practice, most people think of it like this (even though it is not strictly correct):

> There is a 95% chance that the population proportion is between 0.130 and 0.209.

`r webexercises::unhide()`
:::







## Validity and confidence intervals {#ValidityCIs}

When constructing confidence intervals, certain *statistical validity conditions* must be true; these ensure that the sampling distribution is sufficiently close to a normal distribution for the [68--95--99.7 rule](#def:EmpiricalRule) rule to apply.

If these conditions are *not* met, the sampling distribution may not be normally distributed, so the 68--95--99.7 rule (on which the CI is based)  maybe inappropriate, so the CI itself may also be inappropriate.

In addition to the statistical validity condition, the *internal validity* and *external validity* of the study should be discussed also (Fig.&nbsp;\@ref(fig:ValiditiesCI)).

Regarding *external validity*, all the CI computations in this book  assume a *simple random sample*.
If the sample is from a [*random* sampling method](#RandomSamples), but not from a [*simple random sample*](#SRS), then methods exist for producing CIs that are externally valid, but are more complicated than those described in this book.

If the sample is a [non-random sample](#NonRandomSamples), then the CI may be reasonable for the quite specific population that *is* represented by the sample;
however, the sample probably does not represent the more general population that is probably intended.

*Externally validity* requires that a study is also internally valid.
*Internal validity* can only be discussed if details are known about the study design.


```{r ValiditiesCI, echo=FALSE, fig.cap="Four types of validities for studies.", fig.align="center", fig.height=4, out.width="90%"}
par( mar = c(0.15, 0.15, 0.15, 0.15))
openplotmat()

pos <- array(NA, 
             dim = c(12, 2))
pos[1, ] <- c(0.25, 0.90) # External
pos[2, ] <- c(0.45, 0.90) # Internal
pos[3, ] <- c(0.65, 0.90)   # Statistical
pos[4, ] <- c(0.85, 0.90)   # Ecological

pos[5, ] <- c(0.25, 0.50)   # EX: conditions
pos[6, ] <- c(0.45, 0.50)   # IN: conditions
pos[7, ] <- c(0.65, 0.50)   # ST: conditions
pos[8, ] <- c(0.85, 0.50)   # ECO: conditions

pos[9, ] <- c(0.25, 0.08)   # EX: upshot
pos[10, ] <- c(0.45, 0.08)   # IN: upshot
pos[11, ] <- c(0.65, 0.08)   # ST: upshot
pos[12, ] <- c(0.85, 0.08)   # ECO: upshot

textplain( mid = c(0.07, pos[1, 2]),
           lab = "Type:",
           adj = c(0.5, 1))
textplain( mid = c(0.07, pos[5, 2]),
           lab = "Condition:",
           adj = c(0.5, 1))
textplain( mid = c(0.07, pos[9, 2]),
           lab = "Implication:",
           adj = c(0.5, 1))


straightarrow(from = pos[1, ], to = pos[5, ], 
              lty = 1, 
              lcol = "black",
              lwd = 2)
straightarrow(from = pos[2, ], to = pos[6, ], 
              lwd = 2,
              lcol = "black",
              lty = 1)
straightarrow(from = pos[3, ], to = pos[7, ], 
              lwd = 2,
              lcol = "black",
              lty = 1)
straightarrow(from = pos[4, ], to = pos[8, ], 
              lwd = 2,
              lcol = "black",
              lty = 1)


straightarrow(from = pos[5, ], to = pos[9, ], 
              lty = 3, 
              lcol = "black",
              lwd = 2)
straightarrow(from = pos[6, ], to = pos[10, ], 
              lwd = 3,
              lcol = "black",
              lty = 3)
straightarrow(from = pos[7, ], to = pos[11, ], 
              lwd = 2,
              lcol = "black",
              lty = 3)
straightarrow(from = pos[8, ], to = pos[12, ], 
              lwd = 2,
              lcol = "black",
              lty = 3)

textrect( pos[1, ], 
           lab = "External\n validity", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "aliceblue",
           lcol = "aliceblue")
textrect( pos[2, ], 
           lab = "Internal\n validity", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "aliceblue",
           lcol = "aliceblue")
textrect( pos[3, ], 
           lab = "Statistical\n validity", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "aliceblue",
           lcol = "aliceblue")
textrect( pos[4, ], 
           lab = "Ecological\n validity", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "aliceblue",
           lcol = "aliceblue")

textrect( pos[5, ], 
           lab = "Random\n samples", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "darkseagreen1",
           lcol = "darkseagreen1")
textrect( pos[6, ], 
           lab = "Study is\n well-designed", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "darkseagreen1",
           lcol = "darkseagreen1")
textrect( pos[7, ], 
           lab = "Specific\n conditions", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "darkseagreen1",
           lcol = "darkseagreen1")
textrect( pos[8, ], 
           lab = "Understand\n study design", 
           radx = 0.09, 
           rady = 0.125, 
           shadow.size = 0,
           box.col = "darkseagreen1",
           lcol = "darkseagreen1")

textrect( pos[9, ], 
           lab = "Sample\n represents\n population", 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = "mistyrose",
           lcol = "mistyrose")
textrect( pos[10, ], 
           lab = c("Within-sample\n conclusions\n are sound"), 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = "mistyrose",
           lcol = "mistyrose")
textrect( pos[11, ], 
           lab = "Statistical\n methods\n appropriate", 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = "mistyrose",
           lcol = "mistyrose")
textrect( pos[12, ], 
           lab = "Results\n seen in\n real world", 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = "mistyrose",
           lcol = "mistyrose")

```


In addition, CIs also require that the sample size is less than 10% of the population size; however this is almost always the case.




<iframe src="https://learningapps.org/watch?v=paixpst9c22" style="border:0px;width:100%;height:600px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>




## Quick revision exercises {#Chap21-QuickReview}

1. True or false: CIs *always* have 95% confidence.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = FALSE )}`
1. True or false: The statistical validity conditions concern *external* validity.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = FALSE )}`
1. True or false: CIs give intervals in which the value of a *population* parameter will fall.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = FALSE )}`
1. True or false: All other things being equal, a 95% CI is *wider* than a 90% CI.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = TRUE )}`
1. The 'multiplier times the standard error' is called the   
`r if( knitr::is_html_output(exclude = "epub") ) {longmcq( c(
           "CI",
  answer = "margin of error",
           "sampling variation"
) )}`
1. What is the missing word: A CI gives an interval in which we are fairly sure that the value of the ????? is within.
`r if( knitr::is_html_output(exclude = "epub") ) {longmcq( c(
           "Sample statistic",
  answer = "Population parameter",
           "Population sample"
) )}`

`r if (!knitr::is_html_output()) '<!--'`
::: {.progressBox .progress}
**Progress:**  `r webexercises::total_correct()`
:::
`r if (!knitr::is_html_output()) '-->'`




## Exercises {#AboutCIsExercises}

Selected answers are available in Sect.&nbsp;\@ref(AboutCIsAnswer).


::: {.exercise #AboutCIsInterpretation}
A researcher was computing a 95% CI for a single proportion to estimate the proportion of trees with apple scabe [@hirst1962epidemiology], and found that $\hat{p} = 0.314$ and $\text{s.e.}(\hat{p}) = 0.091$.

What is wrong with the following conclusion that the researcher made?

> The approximate 95% CI for the sample proportion is between 0.223 and 0.405.
:::



::: {.exercise #AboutCIsInterpretation2}
A researcher was computing a 95% CI for a single proportion to estimate the proportion of trees with apple scabe [@hirst1962epidemiology], and found that $\hat{p} = 0.314$ and $\text{s.e.}(\hat{p}) = 0.091$.

What is wrong with the following conclusion that the researcher made?

> This CI means we are 95% confident that between 22.3 and 40.5 trees are infected with apple scab.
:::



