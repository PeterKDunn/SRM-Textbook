
# CIs for mean differences (paired data) {#PairedCI}
\index{Research question!relational}


```{r, child = if (knitr::is_html_output()) {'./introductions/30-CIs-MeanDifference-HTML.Rmd'} else {'./introductions/30-CIs-MeanDifference-LaTeX.Rmd'}}
```


## Introduction: students starting university {#PairedIntro}


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/meal-3236971_1280.jpg" width="200px"/>
</div>


What happens to students' weight when they start university?
Among other changes, many students will be responsible for their own meals for the first time.
Perhaps these students forgo healthy foods for convenient, but less healthy, foods.
This may mean that, on average, their weight increases.
Or perhaps they lose weight, as they cannot afford to purchase sufficient or healthy food.

One approach to studying this is to take a sample of students who are beginning university and measure their weight, and then a *different* sample of students some later time and measure their weight.
This is comparing *between* individuals.
This between-individuals design requires comparing the means of two *different* groups of students, the topic of the next chapter.

Another approach is to record some students' weights as they begin university, and then obtain *the same* students' weight at some later time.
The comparison is *within* individuals (Sect.\ \@ref(Intervention)), and the RQ is a *descriptive RQ*: the *Outcome* is the mean *change* in weight, and the response variable is the weight *change* for each individual student.
Each student has a *pair* of weight measurements, and the study produces *paired data*, the topic of this chapter.

This second approach was used to answer this question (@levitsky2004freshman, @DASL:WeightChange):

> For Cornell University students, what is the *mean weight change* in students after $12$ weeks at university?


## Paired data {#PairedData}
\index{Data!paired}

*Paired data* refers to situations where every observation in one group is related to, or can be matched sensibly to, one unique observation in another group.
Paired data can be used to answer a special case of *repeated-measures RQs* (Sect.\ \@ref(RQsRepeatedMeasures)), having within-individual comparisons for two states.
In many cases, two observations are taken from the same individuals.
Because of this, computing the *differences* between the pairs of observations makes sense.
The two groups are *not* independent (Sect.\ \@ref(Independence)).

Pairing data, when appropriate, is useful because individuals can vary substantially.
Using paired data, rather than data from independent individuals, means that extraneous variables (potentially, *confounding* variables) are held constant for those paired observations.
In this sense, pairing is a form of blocking (Sect.\ \@ref(ExpManagingConfounding)).
Pairing is a good design strategy when the individuals in the pair are similar for many extraneous variables.


::: {.definition #PairedData name="Paired data"}
*Paired data* occurs in situations where every observation in one group is related to, or can be matched sensibly to, one unique observation in another group.
:::


Paired data arises in studies using a *within-individuals* comparison (Sect.\ \@ref(Intervention)), but appears in other ways too.
Consider these examples of paired data:

* Blood pressure is recorded on the same individuals *before* and *after* receiving a drug.
  Each person receives a pair of measurements, and their *change* in blood pressure is recorded.
* The number of visitors is recorded at many national parks on the first weekend in summer, and on the first weekend on winter.
  Each national park receives a pair of measurements, and the *change* in visitor numbers for each national park between these time points is recorded.
* The body temperature of dogs is measured using two types of thermometers.
  Each dog receives a pair of measurements, and the *difference* between the two recorded temperatures from the thermometers is recorded.
* Height is measured for each twin in a pair.
  Pairing the heights for each twin is reasonable given the shared genetics (and probably environments also).
  The *difference* between the height of the twins can be recorded for each pair.

Many of these examples can be extended to beyond two measurements.
For instance, blood pressures can be recorded every thirty minutes, or temperatures can be compared using three different types of thermometers.
We only study *pairs* of measurements, and only for quantitative variable.


## Summarising data {#SummarisingPairedCI}

Consider the student weight-loss study described above.
Weight is measured for the same students at the start of university and after $12$\ weeks at university.
Each student receives a pair of measurements, and the *change* in weight for each individual can be recorded
`r if (knitr::is_latex_output()) {
   '(Table\\ \\@ref(tab:DataWeightChange)).'
} else {
   '(data below).'
}`

```{r DataWeightChange}
data(StudentWt)

SWlen <- length(StudentWt$Week1)

Labels <- paste("No.", 
                1 : length(StudentWt$Student))

tb1 <- array( cbind( Labels[1:5 ],
                     StudentWt$Week1[1:5 ],
                     StudentWt$Week12[1:5 ],
                     StudentWt$GainWt[1:5 ]),
                     dim = c(5, 4) )
                     

T1 <- knitr::kable(pad(tb1,
                       surroundMaths = TRUE,
                       targetLength = 4,
                       digits = 1),
                   format = "latex",
                   valign = 't',
                   align = "c",
                   linesep = "",
                   col.names = c("Student", 
                                 "Wk 1", 
                                 "Wk 12", 
                                 "Gain"),
                   row.names = FALSE,
                   escape = FALSE,
                   booktabs = TRUE) %>%
  add_header_above(c( " " = 1, 
                      "Weight (in kg)" = 3),
                   line = TRUE,
                   bold = TRUE) %>%
  row_spec(0, bold = TRUE)


tb2 <- array( cbind( Labels[(SWlen - 4):SWlen ],
                     StudentWt$Week1[(SWlen - 4):SWlen ],
                     StudentWt$Week12[(SWlen - 4):SWlen ],
                     StudentWt$GainWt[(SWlen - 4):SWlen ]),
                     dim = c(5, 4) )


T2 <- knitr::kable(pad(tb2,
                       surroundMaths = TRUE,
                       targetLength = 4,
                       digits = 1),
                   format = "latex",
                   valign = 't',
                   align = c("r", "c", "c", "r"),
                   linesep = "",
                   col.names = c("Student", 
                                 "Wk 1", 
                                 "Wk 12", 
                                 "Gain"),
                   row.names = FALSE,
                   escape = FALSE,
                   booktabs = TRUE) %>%
  add_header_above(c( " " = 1, 
                      "Weight (in kg)" = 3),
                   line = TRUE,
                   bold = TRUE) %>%
  row_spec(0, bold = TRUE)

out <- knitr::kables(list(T1, T2),
                     format = "latex",
                     label = "DataWeightChange",
                     caption = "The student weight-change data: The weight of students in Week\\ 1 at university, in Week\\ 12, and the weight gain (all in kg). These are the first five and the last five of the $68$ total observations.") %>% 
  kable_styling(font_size = 8)
out2 <- prepareSideBySideTable(out,
                               gap = "\\enskip") 
out2

```

```{r}
if( knitr::is_html_output() ) {
  kable( pad(StudentWt,
             surroundMaths = TRUE,
                       targetLength = 4,
                       digits = 1),
         format = "html",
         align = "c",
         booktabs = TRUE,
         longtable = FALSE, 
         col.names = c("Student", "Week 1", "After 12 weeks", "Weight gain"),
         caption = "The student weight-change data: The weight of students in Week\\ 1 at university, in Week\\ 12, and the weight gain (all in kg)") %>% 
    row_spec(0, bold = TRUE)
}
```


A boxplot comparing students' weights at Week\ $1$ and at Week\ $12$ (that is, *not* treating the data as paired) shows that the distribution of weights, and the median weights, are very similar (Fig.\ \@ref(fig:ComparePairedBoxplotsHistogram), left panel).
Any difference is difficult to see and detect, due to the amount of variation in the weights of the students.
In addition, the weight of the same person in Week\ 1 and Week\ 12 cannot be identified; that connection has been lost.
For instance, whether individual students lost or gained weight cannot be determined.

An appropriate graph is *a histogram* of the weight *gains* (that is, treating the data as *paired*), which makes the change in weight much easier to see and detect (Fig.\ \@ref(fig:ComparePairedBoxplotsHistogram), right panel).
It is also easy to see that some students *lost* weight from Week\ $1$ to Week\ $12$.
Graphing the *Week\ $1$* and *Week\ $12$* data may also be useful too, but a graph of the differences is *crucial*, as the RQ is about the differences.
A case-profile plot (Sect.\ \@ref(CaseProfilePlot)) is also appropriate, but is difficult to read here as the sample size is too large (a case-profile plot contains a line for each unit of analysis).


```{r ComparePairedBoxplotsHistogram, fig.align="center", out.width='80%', fig.cap="Plots of the weight-loss data. Left: Treating the data incorrectly as not paired. Right: A histogram of weight changes (the vertical grey line represents no change in weight).", fig.height = 3.25, fig.width = 7}

par(mfrow = c(1, 2))

boxplot( cbind(StudentWt$Week1,
               StudentWt$Week12),
         names = c("Week 1", "Week 12"),
         las = 1,
         col = plot.colour,
         ylim = c(40, 105),
         ylab = "Weight (in kg)",
         main = "A boxplot of student weights\nin Week 1 and Week 12")

out <- hist( StudentWt$GainWt,
             breaks = seq(-3, 4, by = 0.5),
             plot = FALSE)

plot(x = c(-3, 4),
     y = c(0, 15),
      xlab = "Weight gain (kg)",
      ylab = "Frequency",
      las = 1,
     type = "n",
      main = "Histogram of weight gains\nfrom Week 1 to Week 12")
box()

abline(v = 0, 
       col = "grey", 
       lty = 1,
       lwd = 2)
plot(out,
     add = TRUE,
     col = plot.colour)


#hist(StudentWt$GainWt,
#     xlab = "Weight gain (in kg)",
#     ylab = "No. of students",
#     main = "Histogram of weight gains")
# plot(x = c(0.75, 2.25),
#      y = c(40, 110),
#      type = "n",
#      las = 1,
#      ylab = "Weight (in kg)",
#      xlab = "",
#      main = "iugoiug")
# 
#  for (i in 1:length(StudentWt$Week1)){
#    lines( x = c(1, 2),
#           y = c(StudentWt$Week1[i],
#                 StudentWt$Week12[i]) )
# }

```


<!-- Since each unit of analysis has two observations about weight, the *change* (or the *difference*) in weight can be computed for *each* student. -->
<!-- Then, questions can be asked about the *population mean difference*, which is not the same as *difference between two separate population means* (the subject of the next chapter). -->
<!-- In paired data, finding the difference between the two measurements for each *individual* unit of analysis makes sense, since each unit of analysis (each student) has two related observations. -->



<!-- Case-profile plot not very helpful: -->

<!-- for (i in (1:68)){lines( x=c(1,2), y = c(StudentWt$Week1[i], StudentWt$Week12[i]));  -->
<!-- points(x=c(1,2), y = c(StudentWt$Week1[i], StudentWt$Week12[i]), pch= 19, cex = 0.5)} -->

Since the RQ is about the weight *changes*, a numerical summary of the *differences* is essential; the Week\ $1$ and the Week\ $12$ data can also be summarised.
Since the weights and the differences are quantitative, the appropriate *numerical summary* includes means, standard deviations, and so on, as appropriate (found using a computer).
In the formal summary table 
`r if (knitr::is_latex_output()) {
   '(Table\\ \\@ref(tab:WeightGainSummary)),'
} else {
   '(below),'
}`
notice that the standard deviation of the difference is *not* the difference between the two given values of the standard deviation. (Likewise for the standard error.)
The sample error of the difference is  
\[
  \text{s.e.}(\bar{x}) =  \frac{0.956}{\sqrt{68}} = 0.116.
\]
All statistics are slightly different in Weeks\ $1$ and\ $12$; in particular, a slight weight gain is seen.


```{r WeightGainSummary}
WtGain.DataSummary <- array( dim = c(3, 4))

WtGain.DataSummary[1, 1] <- mean(StudentWt$Week1)
WtGain.DataSummary[2, 1] <- mean(StudentWt$Week12)
WtGain.DataSummary[3, 1] <- mean(StudentWt$GainWt)

WtGain.DataSummary[1, 2] <- median(StudentWt$Week1)
WtGain.DataSummary[2, 2] <- median(StudentWt$Week12)
WtGain.DataSummary[3, 2] <- median(StudentWt$GainWt)

WtGain.DataSummary[1, 3] <- sd(StudentWt$Week1)
WtGain.DataSummary[2, 3] <- sd(StudentWt$Week12)
WtGain.DataSummary[3, 3] <- sd(StudentWt$GainWt)

WtGain.DataSummary[1, 4] <- findStdError(StudentWt$Week1)
WtGain.DataSummary[2, 4] <- findStdError(StudentWt$Week12)
WtGain.DataSummary[3, 4] <- findStdError(StudentWt$GainWt)

rownames(WtGain.DataSummary) <- c("Week 1 weight (in kg)", 
                                  "Week 12 weight (in kg)", 
                                  "Weight gain (in kg)")

if( knitr::is_latex_output() ) {
  kable(pad(WtGain.DataSummary,
            targetLength = c(5, 4, 6, 5),
            surroundMaths = TRUE,
            digits = c(2, 1, 3, 3)),
        format = "latex",
        booktabs = TRUE,
        longtable = FALSE,
        escape = FALSE,
        align = "c",
        col.names = c("Mean", "Median", "Standard deviation", "Standard error"),
        digits = 2,
        caption = "The mean, median, standard deviation and standard error for the weight-gain data") %>%
    row_spec(0, bold = TRUE) %>%
    row_spec(3, italic = TRUE) %>%
    kable_styling(font_size = 8)
} else {
  kable(pad(WtGain.DataSummary,
            targetLength = c(5, 4, 6, 5),
            surroundMaths = TRUE,
            digits = c(2, 1, 3, 3)),
        format = "html",
        booktabs = TRUE,
        longtable = FALSE,
        escape  = FALSE,
        align = "c",
        col.names = c("Mean", "Median", "Standard deviation", "Standard error"),
        digits = 2,
        caption = "The mean, median, standard deviation and standard error for the weight-gain data") %>%
    row_spec(0, bold = TRUE) 
}
```



## Mean differences {#CIMeanDiffExample}

The parameter for studying the mean change in students weights is $\mu_d$, the population mean *weight gain* (in kg).
The subscript $d$ is a reminder that we are working with *differences* between Week\ 1 and Week\ 12 weights.

Finding the *difference* in weight for each student seems sensible: each student has a *Week\ $1$* and *Week\ $12$* measurement.
Using these differences, the process for computing a CI is the same as in Chap.\ \@ref(OneMeanConfInterval), where these changes (or differences) are treated as the data.
Either weight *gain* or weight *loss* could be used as the differences.


::: {.tipBox .tip data-latex="{iconmonstr-info-6-240.png}"}
Be clear about *how* the differences are computed.
Differences could be computed as  *Week\ $1$* minus *Week\ $12$* (the weight *loss*), or *Week\ $12$* minus *Week\ $1$* (the weight *gain*).

Either is fine: provided you are consistent throughout, the meaning of any conclusions will be the same.
Here, weight *gain* is used.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Some weight gains are *negative*.
This does *not* mean a negative weight.
Since the differences are computed as *Week\ $12$* minus *Week\ $1$*, a negative value means that the *Week\ $1$ weight* is greater than the *Week\ $12$ weight* value: that is, a weight *loss*.
:::


## Notation {#PairedNotationCI}

The notation used for paired data reflects that we work with the *differences* (Table\ \@ref(tab:PairedNotation)).
Apart from that, the notation is similar to that used in Chap.\ \@ref(OneMeanConfInterval).


```{r PairedNotation}
DiffNotation <- array(dim = c(5, 2))
colnames(DiffNotation) <- c(	"One sample mean", 
                             "Mean difference")
rownames(DiffNotation) <- c(	"The observations:",
                             "Sample mean:",
                             "Standard deviation:",
                             "Standard error of $\\bar{x}$:",
                             "Sample size:")


if( knitr::is_latex_output() ) {
  DiffNotation[1, ] <- c(	"Values: $x$", 
                          "Differences: $d$")
  DiffNotation[2, ] <- c(	"$\\bar{x}$",		
                          "$\\bar{d}$")
  DiffNotation[3, ] <- c(	"$s$", 			
                          "$s_d$")
  DiffNotation[4, ] <- c(	"$\\displaystyle\\text{s.e.}(\\bar{x}) = \\frac{s}{\\sqrt{n}}$",
                          "$\\displaystyle\\text{s.e.}(\\bar{d}) = \\frac{s_d}{\\sqrt{n}}$")
  DiffNotation[5, ] <- c(	"Number of \\emph{observations}: $n$",
                          "Number of \\emph{differences}: $n$")
  
  kable( DiffNotation,
         format = "latex",
         booktabs = TRUE,
         align = c("c", "c"),
         longtable = FALSE,
         escape = FALSE,
         col.names = colnames(DiffNotation),
         caption = "The notation used for mean differences (paired data) compared to the notation used for one sample mean") %>%
    kable_styling(font_size = 8) %>%
    row_spec(0, bold = TRUE) 
}
if( knitr::is_html_output() ) {
  
  DiffNotation[1, ] <- c(	"Values: $x$", 	
                          "Differences: $d$")
  DiffNotation[2, ] <- c(	"$\\bar{x}$",		
                          "$\\bar{d}$")
  DiffNotation[3, ] <- c(	"$s$", 			
                          "$s_d$")
  DiffNotation[4, ] <- c(	"$\\displaystyle\\text{s.e.}(\\bar{x}) = \\frac{s}{\\sqrt{n}}$",
                          "$\\displaystyle\\text{s.e.}(\\bar{d}) = \\frac{s_d}{\\sqrt{n}}$")
  DiffNotation[5, ] <- c(	"Number of *observations*: $n$",
                          "Number of *differences*: $n$")
  
  kable( DiffNotation,
                format = "html",
                booktabs = TRUE,
                longtable = FALSE,
                align = c("c", "c"),
                col.names = colnames(DiffNotation),
                caption = "The notation used for mean differences (paired data) compared to the notation used for one sample mean") %>%
    row_spec(0, bold = TRUE) 
}
```




## Describing sampling distribution 
\index{Sampling distribution!paired quantitative data}

The study concerns the mean weight change, where the differences were defined as weight gains.
Every possible sample of $n = 68$ students comprises different students, and hence produces different Week\ $1$ and Week\ $12$ weights, and hence different weight gains.
Hence, the sample mean weight gains vary from sample to sample, and have a *sampling distribution* and a *standard error*.

Since the differences are like a single sample of data (Chap.\ \@ref(OneMeanConfInterval)), the sampling distribution for the differences has a similar sampling distribution to the mean of a single sample $\bar{x}$ (provided the conditions are met; Sect.\ \@ref(ValidityPaired)).


::: {.definition #DEFSamplingDistributionDbar name="Sampling distribution of a sample mean difference"}
The *sampling distribution of a sample mean differences* is (when certain conditions are met (Sect.\ \@ref(ValidityPaired))) described by:

* an approximate normal distribution,
* centred around the *sampling mean* whose value is the population mean *difference* $\mu_d$,
* with a standard deviation, called the standard error of the difference, of $\displaystyle\text{s.e.}(\bar{d}) = \frac{s_d}{\sqrt{n_d}}$,

where $n$ is the number of differences, and $s_d$ is the standard deviation of the individual differences in the sample.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
A mean or a median may be appropriate for describing the *data*.
However, the sampling distribution describes the distribution of the *sample means* , *not* the data.
Since the sampling distribution (under certain conditions) has a symmetric *normal distribution*, the mean *is* appropriate for describing the sampling distribution.
:::


For the weight-gain data, the sample mean differences $\bar{d}$ are described by (Fig.\ \@ref(fig:WtGainSamplingDist)):

* approximate normal distribution,
* with a sampling mean whose value is $\mu_{{d}}$,
* with a *standard error* of $\text{s.e.}(\bar{d}) = 0.1159764$.

Many decimal places are shown here; results will be rounded when reported.
 
 

```{r WtGainSamplingDist, fig.cap="The sampling distribution is a normal distribution; it describes how the sample mean weight gain varies in samples of size $n = 68$", fig.align="center", fig.width=9.0, fig.height=2.5, out.width='95%'}
mn <- mean(StudentWt$GainWt)
n <- length(StudentWt$GainWt)
stdd <- sd(StudentWt$GainWt)

se <- stdd/sqrt(n)

par( mar = c(4, 0.5, 0.5, 0.5) )
out <- plotNormal(0,
                  se,
                  xlab = "Sample mean difference in weight gain (in kg)", 
                  cex.axis = 0.95,
                  ylim = c(0, 5.0),
                  showXlabels = c( 	
                    expression( mu-0.348),
                    expression( mu-0.232), 
                    expression( mu-0.116), 
                    expression( mu ),
                    expression( mu + 0.116), 
                    expression( mu + 0.232), 
                    expression( mu + 0.348) ) )

arrows(x0 = 0,
       x1 = 0,
       y0 = max(out$y) * 1.2,
       y1 = max(out$y),
       angle = 15,
       length = 0.1)

text(x = 0,
     y = max(out$y) * 1.2,
     pos = 3,
     labels = expression(Sampling~mean~difference))



arrows(x0 = 0,
       x1 = 0 + se,
       y0 = 0.30 * max(out$y),
       y1 = 0.30 * max(out$y),
       code = 3, # Arrows both ends
       angle = 15,
       length = 0.1)

text(x = 0 + (se / 2),
     y = 0.30 * max(out$y),
     labels = expression( atop(Std.~error,
                               s.e.(bar(italic(d)))==0.116)) )


arrows(x0 = mn,
       x1 = mn,
       y0 = 0.7 * max(out$y),
       y1 = 0,
       angle = 15,
       length = 0.1)
text(x = mn,
     y = 0.7 * max(out$y),
     pos = 3,
     labels = expression(bar(italic(d)) == 0.0282) )
```



## Computing confidence intervals {#MeanDiffCI}
\index{Confidence intervals!paired quantitative data}

The CI for the mean difference has the same form as for a single mean (Chap.\ \@ref(OneMeanConfInterval)), so an approximate $95$% confidence interval (CI) for $\mu_d$ is  
\[
	\bar{d} \pm (2 \times\text{s.e.}(\bar{d})).
\]
This is the same as the CI for $\bar{x}$ if the differences are treated like the data.
For the weight-gain data:  
\[
	0.8618 \pm (2 \times 0.1159764),
\]
or $0.862\pm 0.232$ (so the *margin of error* is $0.232$).
Equivalently, the CI is from $0.862 - 0.232 = 0.630$, up to $0.862 + 0.232 = 1.094$.
We write:

> The mean weight gain from Week\ $1$ and\ $12$ is $0.86$\ kg ($\text{s.e.} = 0.116$; $n = 68$), with an *approximate* $95$%\ CI from $0.63$\ kg to $1.09$\ kg.

The CI means that the plausible values for the population mean weight gain are between $0.63$\ kg and $1.09$\ kg.
Alternatively, 
we are $95$% confident that, between Weeks\ $1$ and\ $12$, the population mean weight gain is between $0.63$\ kg and $1.09$\ kg.
A weight gain of this size, though, may not have practical importance.


<iframe src="https://learningapps.org/watch?v=piue8vvyk22" style="border:0px;width:100%;height:600px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>


## Using software

Statistical software can produce *exact* $95$%\ CIs, which may be slightly different than the *approximate* $95$%\ CI (since the $68$--$95$--$99.7$ rule gives *approximate* multipliers).
For the weight-loss data, the *approximate* and *exact* $95$%\ CIs are the same to two decimal places.
From the jamovi output (Fig.\ \@ref(fig:WeightGainTestOutput)) we can write:

> The mean weight gain from Week\ $1$ to Week\ $12$ is $0.86$\ kg ($\text{s.e.} = 0.116$; $n= 68$), with a $95$%\ CI between $0.63$ to $1.09$\ kg


```{r WeightGainTestOutput, fig.cap="The weight-gain data: jamovi output", fig.align="center", out.width="100%", fig.show="hold"}
knitr::include_graphics("jamovi/WeightGain/WeightGain-PairedTOutput.jpg")
```


## Statistical validity conditions {#ValidityPaired}
\index{Statistical validity!paired quantitative data}

As with any confidence interval, these results apply [under certain conditions](#exm:StatisticalValidityAnalogy).
The conditions under which the CI is statistically valid for paired data are similar to those for one sample mean, rephrased for differences.

The CI computed above is statistically valid if *one* of these conditions is true:

1. The sample size of differences is at least $25$; *or*
1. The sample size of differences is smaller than $25$,
   *and*
   the *population* of *differences* has an approximate normal distribution.

The sample size of $25$ is a rough figure here, and some books give other (similar) values (such as $30$).
This condition ensures that the *distribution of the sample means has an approximate normal distribution* (so that, for example, the [$68$--$95$--$99.7$ rule](#def:EmpiricalRule) can be used).
Provided the sample size is larger than about $25$, this will be approximately true *even if* the distribution of the individuals in the population does not have a normal distribution.
That is, when $n > 25$ the sample means generally have an approximate normal distribution, even if the data themselves don't have a normal distribution.


::: {.example #StatisticalValidityWeightGain name="Statistical validity"}
For the weight-gain data, the sample size is $n = 68$, larger than $25$, so the results are statistically valid.
We do not require that the differences *in the population*, or the weights in either Week\ $1$ or Week\ $12$, to follow a normal distribution.
:::




## Example: invasive plants {#PairedInvasivePlantsCI}

Skypilotis a native alpine wildflower growing in the Colorado Rocky Mountains (USA).
In recent years, a willow shrub has been encroaching on skypilot territory and, because willow often flowers early, researchers [@kettenbach2017shrub] are concerned that the willow may 'negatively affect pollination regimes of resident alpine wildflower species' (p.\ 6965).
One RQ was:

> In the Colorado Rocky Mountains, what is the mean difference between first-flowering day for the native skypilot and the encroaching willow?

Data for both species was collected at $25$ different sites, so the data are *paired* (Sect.\ \@ref(PairedIntro)), a form of blocking (Sect.\ \@ref(ExpManagingConfounding)).
The unit of analysis is the *site*, and the unit of observation is the *plant*.
The data are shown in
`r if( knitr::is_latex_output() ) {
    'Table\\ \\@ref(tab:FloweringData).'
} else {
    'the table below.'
}`
The 'first-flowering day' is the number of days since the start of the year (e.g., January\ $12$ is 'day\ $12$') when flowers were first first observed.

The parameter is $\mu_d$, which we define as the population mean *difference* between the day of first flowering for skypilot, less the day of first flowering for willow.
Hence, a *positive* value for the difference means that the skypilot values are larger, and hence that willow flowered first.

::: {.tipBox .tip data-latex="{iconmonstr-info-6-240.png}"}
Explaining *how* the differences are computed is important.
The differences here are skypilot minus willow first-flowering days.
:::


Since the raw data are available, the data should be summarised graphically (Fig.\ \@ref(fig:FloweringPlots)) and numerically (Table\ \@ref(tab:FloweringSummary)), using software (Fig.\ \@ref(fig:Floweringjamovi)).

The standard error of the mean difference is $\text{s.e.}(\bar{d}) = 0.940$, from Fig.\ \@ref(fig:Floweringjamovi) or Table\ \@ref(tab:FloweringSummary).
The approximate $95$%\ CI is $1.36 \pm (2\times 0.940)$, or from $-0.52$ to $3.24$ days.
Figure\ \@ref(fig:Floweringjamovi) gives the $95$%\ CI as $-0.58$ to $3.30$ days.
Remembering that *positive* differences mean willow flowers earlier, we write (using the exact CI):

> From the sample, the mean difference in the day of first flowering is $1.36$ days earlier for the willow ($\text{s.e.} = 0.940$; $n = 25$), with an approximate $95$%\ CI between $0.52$ days earlier for skypilot to $3.24$ days earlier for willow.

The CI should be statistically valid since $n = 25$.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Be clear in your conclusion about *how* the differences are computed.
Make sure to interpret the CI consistent with how the differences are defined.
:::




## Example: chamomile tea {#ChamomileTea-Paired-CI}

A study of patients with Type\ 2 diabetes mellitus (T2DM) randomly allocated $32$ patients into a control group (who drank hot water), and $32$ to receive chamomile tea (@rafraf2015effectiveness, p.\ 164):

> The study was blinded so that the allocation of the intervention or control group was concealed from the researchers and statistician [...]
> The intervention group ($n = 32$) consumed one cup of chamomile tea [...] three times a day immediately after meals (breakfast, lunch, and dinner) for $8$\ weeks. 
> The control group ($n = 32$) consumed an equivalent volume of warm water during the $8$-week period...

The total glucose (TG) was measured for each individual, in both groups, both before the intervention and after eight weeks on the intervention.
The data are not available, so a graphical summary of the data cannot be produced; however, a data summary is given in the article (motivating Table\ \@ref(tab:TGsummaryTable)).
The following RQs can be asked:

> * For patients with T2DM, what is the mean reduction in TG after eight weeks drinking *chamomile tea*?
> * For patients with T2DM, what is the mean reduction in TG after eight weeks drinking *hot water*?

For the *tea group*, the standard error of the *reduction* in TG is $\text{s.e.}(\bar{d}) = 30.37/\sqrt{32} = 5.37$, so an approximate $95$%\ CI for the *reduction* in TG is  
\[
  38.62\pm (2\times 5.37), \text{or from $27.88$ to $49.36$ mg.dl$^{-1}$}.
\]
For the *control group*, the standard error of the *reduction* in TG is $\text{s.e.}(\bar{d}) = 36.66/\sqrt{32} = 6.48$, so an approximate $95$%\ CI for the *reduction* in TG is  
\[
  -7.12\pm (2\times 6.48), \text{or from $-20.08$ to $5.84$ mg.dl$^{-1}$}.
\]
(A *negative* reduction means an *increase* in TG.)
The chamomile tea appears to reduce TG, but not the hot water.
Is the difference between the two treatments due to sampling variation?
This is studied further in Sect.\ \@ref(ChamomileTea-Paired-HT).


```{r TGsummaryTable}
TGsummary <- array(dim = c(3, 7) )

rownames(TGsummary) <- c("Chamomile tea",
                          "Control",
                          "Difference")
colnames(TGsummary) <- c("n",
                          "BaselineMean",
                          "BaselinesSD",
                          "PostMean",
                          "PostSD",
                          "ChangeMean",
                          "ChangeSD")

TGsummary[1, ] <- c(32, 
                     203.00, 54.96,
                     164.37, 50.70,
                     38.62, 30.37)
TGsummary[2, ] <- c(32,
                     178.25, 53.06,
                     185.37, 52.59,
                     -7.12, 36.66)
TGsummary[3, ] <- c(NA,
                     24.75, NA,
                     21.00, NA,
                     45.74, NA)

if( knitr::is_latex_output() ) {
  
  knitr::kable(pad(TGsummary,
                   surroundMaths = TRUE,
                   targetLength = c(2, 6, 5, 6, 5, 5, 5),
                   digits = c(0, 2, 2, 2, 2, 2, 2)),
               format = "latex",
               align = "c",
               linesep = "",
               caption = "The total glucose (in mg.dl$^{-1}$)",
               col.names = c("$n$",
                             "Mean", "Std. dev.", 
                             "Mean", "Std. dev.",
                             "Mean", "Std. dev."),
               row.names = TRUE,
               escape = FALSE,
               booktabs = TRUE) %>%
    row_spec(0, bold = TRUE) %>%
    row_spec(3, italic = TRUE) %>%
    kable_styling(font_size = 8) %>%
    add_header_above( c(" " = 2,
                        "Baseline" = 2,
                        "After 8 weeks" = 2,
                        "Reduction" = 2),
                      bold = TRUE)
}

if( knitr::is_html_output() ) {
  kable( pad(TGsummary,
                   surroundMaths = TRUE,
                   targetLength = c(2, 6, 5, 6, 5, 5, 5),
                   digits = c(0, 2, 2, 2, 2, 2, 2)),
         format = "html",
         align = "c",
         booktabs = TRUE,
         longtable = FALSE,
         col.names =  c("$n$",
                        "Mean", "Std. dev.", 
                        "Mean", "Std. dev.",
                        "Mean", "Std. dev."),
         caption = "The total glucose (in mg.dl$^{-1}$)") %>% 
    row_spec(0, bold = TRUE)
}

```

We write:

> The mean reduction in TG for those drinking chamoile tea is $38.62$\ mg.dl^-1^ (approx. $95$%\ CI: $27.88$ to $49.36$\ mg.dl^-1^), and $-7.12$\ mg.dl^-1^ for those drinking water (approx. $95$%\ CI: $-20.08$ and $-5.84$\ mg.dl^-1^).

The intervals have a $95$% chance of straddling the population mean reduction in TG.
The sample sizes are larger than $25$, so the results are statistically valid.


## Chapter summary

## Quick review questions {#Chap23-QuickReview}

Are the following statements *true* or *false*?

::: {.webex-check .webex-box}
1. For paired data, the mean of the *differences* is treated like the mean of a single variable.\tightlist  
`r if( knitr::is_html_output() ) { torf( answer=TRUE )}`
1. An appropriate graph for displaying paired data is often a histogram of the differences.  
`r if( knitr::is_html_output() ) { torf( answer=TRUE )}`
1. The *population* mean difference is denoted $\mu_d$.  
`r if( knitr::is_html_output() ) { torf( answer=TRUE )}`
1. The standard error of the sample mean difference is denoted $s_d$.  
`r if( knitr::is_html_output() ) { torf( answer=FALSE )}`
:::




## Exercises {#PairedCIExercises}

Selected answers are available in Sect.\ \@ref(PairedCIExercisesAnswer).


::: {.exercise #MeanDiffWhichPaired}
Which of these scenarios are *paired*?

1. Heart rate is measured for each individual when sitting and when standing.
  (Some individuals have their heart rate recorded first while sitting, and some first while standing.)
  Each person receives a pair of measurements, and the *difference* in heart rate between sitting and standing is recorded.
1. The mean protein concentrations were compared in sea turtles before and after being rehabilitated  [@data:March2018:turtles].
:::


::: {.exercise #MeanDiffWhichPaired2}
Which of these scenarios are *paired*?

1. Heart rate was recorded for $36$ people, both before and after exercise, to determine how much the average heart rate increase.
1. The mean HDL cholesterol concentration is recorded for $22$ males and $19$ females, and the means compared.
:::


::: {.exercise #MeanDiffGrowingSquashCI}
[*Dataset*: `Fruit`]
The effect of rainfall on growing Chayote squash (*Sechium edule*) was studied [@mukherjee2019diversity], comparing the size of the fruit in a year with normal rainfall (2015) compared to fruit in a dry year (2014) on $24$ farms:

> For Chayote squash grown in Bangalore, what is the mean difference in fruit weight between a normal and dry year?

Ten fruits were gathered from each farm in both years, and the average (mean) weight recorded for the farm.
Since the same farms are used in both years, the data are *paired* 
`r if( knitr::is_latex_output() ) {
  '(Table\\ \\@ref(tab:FruitsData)).'
} else {
  '(see above).'
}`
Data is missing for Farm\ 20 in the dry year (2014), so there are $n = 23$ differences.


```{r FruitsData, echo=FALSE}
data(Fruit)

Fruit$Farm <- 1 : length(Fruit$FWeight2014)

FruitTab <- dplyr::select(Fruit,
                          Farm,
                          FWeight2014,
                          FWeight2015)
FruitTab$Change <- FruitTab$FWeight2015 - FruitTab$FWeight2014

if( knitr::is_latex_output() ) {
  
 T1 <- knitr::kable(pad(FruitTab[1:5, ],
                        digits = c(0, 2, 2, 2),
                        surroundMaths = TRUE,
                        targetLength = c(2, 6, 6, 6)),
                     format = "latex",
                     valign = 't',
                     align = "c",
                     linesep = "",
                     col.names = c("Farm", 
                                   "Dry", 
                                   "Normal",
                                   "Change"),
                     row.names = FALSE,
                     escape = FALSE,
                     booktabs = TRUE) %>%
   add_header_above(c( " " = 1,
                       "Avge fruit weight (kg)" = 3),
                    bold = TRUE) %>%
    row_spec(0, bold = TRUE) 
  
  
  T2 <- knitr::kable(pad(FruitTab[20:24, ],
                        digits = c(0, 2, 2, 2),
                        surroundMaths = TRUE,
                        targetLength = c(2, 6, 6, 7)),
                     format = "latex",
                     valign = 't',
                     align = "c",
                     linesep = "",
                     col.names = c("Farm", 
                                   "Dry", 
                                   "Normal",
                                   "Change"),
                     row.names = FALSE,
                     escape = FALSE,
                     booktabs = TRUE)  %>%
   add_header_above(c( " " = 1,
                       "Avge fruit weight (kg)" = 3),
                    bold = TRUE) %>%
    row_spec(0, bold = TRUE) 
  
  out <- knitr::kables(list(T1, T2),
                       format = "latex",
                       label = "FruitsData",
                       caption = "The weight of fruits (in g) in two different years. One observation is missing for Field\ 20.") %>% 
    kable_styling(font_size = 8)
  out2 <- prepareSideBySideTable(out) 
  out2 
}

if( knitr::is_html_output() ) {
  kable( pad(FruitTab,
             digits = c(0, 2, 2, 2),
                        surroundMaths = TRUE,
                        targetLength = c(2, 6, 6, 7)),
         format = "html",
         align = "c",
         booktabs = TRUE,
         longtable = FALSE,
         col.names = c("Farm", 
                       "Dry", 
                       "Normal",
                       "Change (in g)"),
         caption = "The weight of fruits (in g) in two different years. One observation is missing for Field\ 20.") %>% 
    row_spec(0, bold = TRUE)
}
```

1. What is the *unit of analysis*?
   What is the *units of observation*?
2. Create a numerical summary table for the data (Fig.\ \@ref(fig:FruitDescriptivesjamovi)).
3. Create a suitable graph to display the data.
4. Construct an approximate $95$%\ CI for the mean difference in fruit weight.
:::



```{r FruitDescriptivesjamovi, fig.cap="jamovi output for the fruit data", fig.align="center", out.width='70%'}
knitr::include_graphics("jamovi/Fruit/Fruit-Descriptives.png")
```



```{r}
data(Captopril)

Captopril$Differences <- Captopril$Before - Captopril$After

bloodS <- subset(Captopril, BP == "S")
bloodS <- bloodS[, c("Before", 
                     "After", 
		     "Differences")]

bloodS2 <- cbind( "Before" = bloodS$Before[1:8], 
                  "After" = bloodS$After[1:8],
                  "Before" = c(bloodS$Before[9:15], NA), 
                  "After" = c(bloodS$After[9:15], NA) )
```


::: {.exercise #PairedCIExercisesCaptopril}
[*Dataset*: `Captopril`]
In a study of hypertension [@data:hand:handbook; @data:macgregor:essential], $15$ patients were given a drug (Captopril) and their systolic blood pressure measured (in mm Hg) immediately before and two hours after being given the drug (Table\ \@ref(tab:CICaptoprilData)).

1. Explain why it is sensible to compute differences as the *Before* minus the *After* measurements.
   What do the differences *mean* when computed this way?
1. Compute an *approximate* $95$%\ CI for the mean difference.
1. Write down the *exact* $95$%\ CI using the computer output (Fig.\ \@ref(fig:CaptoriljamoviCI)). 
1. Why are the two CIs different?
:::



```{r CaptoriljamoviCI, fig.cap="jamovi output for the Captoril data", fig.align="center", out.width="80%", fig.show="hold"}
knitr::include_graphics("jamovi/CaptoprilAll/CaptoprilAll-PairedTOutput.png") 
#knitr::include_graphics("SPSS/CaptoprilAll/CaptoprilAll-PairedTOutput.png")
```




::: {.exercise #PairedCIExercisesBrocolli}
Some people struggle to eat the recommended intake of vegetables.
One study explored ways to increase vegetable intake in teens [@data:Fritts2018:Vegetables].
Teens rated the taste of raw broccoli, and raw broccoli served with a specially-made dip.

Each teen ($n = 100$) had a *pair* of measurements: the taste rating of the broccoli *with* and *without* dip.
Taste was assessed using a '$100$\ mm visual analog scale', where a *higher* score means a *better* taste.
In summary:

* For raw broccoli, the mean taste rating was $56.0$ (with $s = 26.6$);
	 <!-- %  (SDs); so if $n=101$ we'd get SE: 2.647 -->
* For raw broccoli served with dip, the mean taste rating was $61.2$ (with $s = 28.7$).

Because the data are paired, *differences* are the best way to describe the data.
The mean difference in the ratings was $5.2$, with $\text{s.e.}(\bar{d}) = 3.06$. 
From this information:

1. Construct a suitable numerical summary table.
1. Compute the approximate $95$%\ CI for the mean difference in taste ratings.
:::
<!-- (working backwards from the $t$-score). Looks like $n=101$. n=100...? -->



::: {.exercise #PairedCIExercisesSmokeExercise}
A study  [@data:Allen2018:Smoking] examined the effect of exercise on smoking.
Men and women were assessed on their 'intention to smoke', both before and after exercise for each subject (using two quantitative questionnaires).
Smokers ('smoking at least five cigarettes per day') aged\ $18$ to\ $40$ were enrolled for the study.
For the $23$ women in the study, the mean intention to smoke after exercise *reduced* by $0.66$ (with a standard error of $0.37$).

1. Find an approximate $95$% confidence interval for the population mean reduction in intention to smoke for women after exercising.
1. Is this CI statistically valid?
:::

```{r out.width='80%'}
data(Anorexia)

ANCB <- subset(Anorexia, 
               Treatment=="CB")
```


::: {.exercise #PairedCIExercisesAnorexia}
[*Dataset*: `Anorexia`]
Young girls ($n = 29$) with anorexia received cognitive behavioural treatment (@data:hand:handbook, Dataset 285), and their weight before and after treatment were recorded.
In summary:

* Before the treatment, the mean weight was $`r round(mean(ANCB$Before), 2)`$ pounds ($s = `r round(sd(ANCB$Before), 2)`$ pounds);
* After the treatment, the mean weight was $`r round(mean(ANCB$After), 2)`$ pounds ($s = `r round(sd(ANCB$After), 2)`$ pounds).

If the standard deviation of the weight *loss* was $`r round(sd( ANCB$After - ANCB$Before), 2)`$ pounds, find an approximate $95$%\ CI for the population mean weight loss. 
Do you think the treatment had any impact on the mean weight of the girls?
:::


::: {.exercise #StressSurgeryCI}
[*Dataset*: `Stress`]
The concentration of beta-endorphins in the blood is a sign of stress.
One study (@data:hand:handbook, Dataset 232; @hoaglin2011exploring) measured the beta-endorphin concentration for $19$ patients about to undergo surgery.

Each patient had their beta-endorphin concentrations measured $12$--$14$ hours before surgery, and also $10$ minutes before surgery.
A numerical summary (from the jamovi output) is in Table\ \@ref(tab:StressTable).

1. Use the jamovi output in Fig.\ \@ref(fig:StressDescriptivesjamovi) to construct an *approximate* $95$%\ CI for the *increase* in stress as surgery gets closer.
2. Use the jamovi output in Fig.\ \@ref(fig:StressDescriptivesjamovi) to write down the *exact* $95$%\ CI for the *increase* in stress as surgery gets closer.
3. Why is there a difference between the two CIs?
4. Is the CI likely to be statistically valid?
:::


```{r StressDescriptivesjamovi, fig.cap="jamovi output for the surgery-stress data", fig.align="center", out.width='70%'}
knitr::include_graphics("jamovi/Stress/StressDescriptives.png")
```




::: {.exercise #MeanDiffCOVIDCI}
A study of $n = 213$ Spanish health students [@romero2020physical] measured (among other things) the number of minutes of vigorous physical activity (PA) performed by students *before* and *during* the COVID-19 lockdown (from March to April 2020 in Spain).
Since the *before* and *during* lockdown were both measured on *each* participant, the data are *paired* (within individuals).
The data are summarised in Table\ \@ref(tab:COVIDsummaryTable).

1. Explain what the differences *mean*.
1. Compute the standard error of the differences.
1. Compute the approximate $95$%\ CI, and interpret what it means.
:::


```{r COVIDsummaryTable}
COVID.summary     <- array( dim = c(3, 2))
colnames(COVID.summary) <- c("Mean (mins)", 
                             "Std. dev. (mins)")
rownames(COVID.summary) <- c("Before",
                             "During",
                             "Increase")


COVID.summary[1, ] <- c(28.47,
                        54.13)
COVID.summary[2, ] <- c(30.66,
                        30.04)
COVID.summary[3, ] <- c(2.68,
                        51.30)


if( knitr::is_latex_output() ) {
  knitr::kable( pad(COVID.summary,
                    surroundMaths = TRUE,
                    targetLength = c(5, 5),
                    digits = 2),
               format = "latex",
               booktabs = TRUE,
               longtable = FALSE,
               escape = FALSE,
               caption = "Summary information for the COVID-lockdown exercise data for $n = 214$ Spanish students",
               align = "c") %>%
    row_spec(0, bold = TRUE) %>%
    row_spec(3, italic = TRUE) %>%
    kable_styling(font_size = 8)
} 
if( knitr::is_html_output() ) {
   knitr::kable( pad(COVID.summary,
                    surroundMaths = TRUE,
                    targetLength = c(5, 5),
                    digits = 2),
                 format = "html",
                 caption = "Summary information for the COVID-lockdown exercise data for $n = 214$ Spanish students")
}
```




<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to in-chapter questions:**


:::
`r if (knitr::is_html_output()) '-->'`

