
# Internal validity in experimental studies {#DesignExperiment}
\index{Internal validity!experimental studies}\index{Study design!experimental|(}




<!-- Introductions; easier to separate by format -->

```{r, child = if (knitr::is_html_output()) {'./introductions/07-ResearchDesign-Internal-Exp-HTML.Rmd'} else {'./introductions/07-ResearchDesign-Internal-Exp-LaTeX.Rmd'}}
```


## Introduction {#Chap7-Intro}

A well-designed study is needed to draw solid conclusions (Def.\ \@ref(def:StudyDesign)): a study with high *internal validity* (Sect.\ \@ref(def:InternalValidity)) and high *external validity* (Sect.\ \@ref(def:ExternalValidity)).
Some study design decisions to maximise internal validity are discussed in this chapter (for experimental studies).



::: {.example #InternalValidity name="Importance of internal validity"}
@beaman2013profitability describe an experiment where free fertilizer was provided to a sample of female farmers in Mali (at the recommended rate, or at half the recommended rate).

The farmers knew they were in the study, so changed their farm management: they employed more hired labour and used more herbicide.
Consequently, the yields for *all* farmers improved, so knowing if the fertilizer dose impacted yield is difficult.
The study had poor *internal validity*.
:::


Specific design strategies for maximising internal validity include:

* Managing confounding (Sect.\ \@ref(ExpManagingConfounding)).
* Managing the Hawthorne effect by blinding individuals (Sect.\ \@ref(HawthorneEffectExperimental)).
* Managing the observer-effect by blinding the researchers (Sect.\ \@ref(ObserverEffectExperimental)).
* Managing the placebo effect by using objective measures and controls (Sect.\ \@ref(PlaceboEffectExperimental)).
* Managing the carry-over effect by using washouts (Sect.\ \@ref(CarryOverEffectExperimental)).

Not all of these strategies will be relevant to every study.
This chapter discusses experimental studies; the next chapter considers design strategies for observational studies.



<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


For this chapter, consider this relational RQ (based on @data:Bird2008:wholegrain) with an intervention:

> Among Australians, is the average faecal weight the same for people eating provided food made from wholegrain *Himalaya 292* compared to eating provided food made from refined cereal?  


## Managing confounding {#ExpManagingConfounding}
\index{Internal validity!experimental studies!managing confounding}

Suppose that the researchers for the *Himalaya 292* study created two groups:

* *Group\ A*: women recruited at a female-only gym.
* *Group\ B*: men recruited at a local nursing home.

The researchers then gave *Himalaya 292* to Group\ A, and the refined cereal to Group\ B.
If a difference in faecal weight was detected between the two groups, the difference may due to:

* the different *diets* (the explanatory variable) for each group;
* the different *sexes* in each groups (Group\ A was all women; Group\ B was all men);
* the different *ages* in each group (Group\ A is likely to be younger on average than those in Group\ B);
* the different *overall health* in each group (Group\ A would generally be healthier than those in Group\ B).

Any difference in faecal weight detected between the two groups may not be because of the diets (Table\ \@ref(tab:ConfoundingGroups)): the study has very poor internal validity, due to poor research design.

Sex, age and overall health are *confounding variables* (Def.\ \@ref(def:ConfoundingVariable)).\index{Variables!confounding}
For example, the age of the subject may be related to faecal weight (older people tend to eat less, and eat differently, than younger people), and the research design means that older people are more likely to be consuming the refined cereal.
This is an extreme case of *confounding* (Fig.\ \@ref(fig:ConfoundingDiagram)); usually, confounding is more subtle (and more difficult to detect) than in this example.


```{r}
if( knitr::is_latex_output() ) {
  ConfoundTable <- array( dim = c(4, 3) )
  
  colnames(ConfoundTable) <- c("\\textbf{Variable}", 
                               "\\textbf{Group A}",
                               "\\textbf{Group B}")
  
  ConfoundTable[1, ] <- c("\\textbf{Sex}",
                          "Women",
                          "Men")
  ConfoundTable[2, ] <- c("\\textbf{Age}",
                          "Younger",
                          "Older")
  ConfoundTable[3, ] <- c("\\textbf{Cereal}",
                          "*Himalaya 292*",
                          "Refined")
  ConfoundTable[4, ] <- c("\\textbf{Fitness}",
                          "Fitter",
                          "Less fit")
  
  ConfoundTable[3, 2] <- "\\textit{Himalaya 292}"
} else {
  ConfoundTable <- array( dim = c(4, 3) )
  
  colnames(ConfoundTable)<- c( "",
                               "Group A",
                               "Group B")
  ConfoundTable[1, ] <- c("*Sex*",
                          "Women",
                          "Men")
  ConfoundTable[2, ] <- c("*Age*",
                          "Younger (in general)",
                          "Older (in general)")
  ConfoundTable[3, ] <- c("*Cereal*",
                          "*Himalaya 292*",
                          "Refined")
  ConfoundTable[4, ] <- c("*Fitness*",
                          "Very fit (in general)",
                          "Less fit (in general)")
  
  IMG1 <- array( NA, dim = c(1, 1))
  IMG1[1, 1] <- "![](./Pics/iconmonstr-candy-5-240.png){#id .class height=60px}<br>
               ![](./Pics/iconmonstr-arrow-down-thin-240.png){#id .class height=50px} <br>
               ![](./Pics/iconmonstr-generation-4-240.png){#id .class height=60px}"
  
  IMG2 <- array( NA, dim = c(1, 1))
  IMG2[1, 1] <- "![](./Pics/iconmonstr-candy-8-240.png){#id .class height=60px} <br>
               ![](./Pics/iconmonstr-arrow-down-thin-240.png){#id .class height=50px} <br>
               ![](./Pics/iconmonstr-generation-15-240.png){#id .class height=60px}"
}
```


\begin{figure}
\begin{minipage}{0.40\textwidth}
\captionof{table}{Comparing Groups\ A and\ B: An extreme example of confounding\label{tab:ConfoundingGroups}}
\fontsize{8}{12}\selectfont
```{r}
kable(ConfoundTable[, c(2, 1, 3)],
      format = "latex",
      longtable = FALSE,
      booktabs = TRUE,
      table.env = "@empty",
      escape = FALSE, # For latex to work in LaTeX commands
      align = c("r", "c", "l"))   
```
\end{minipage}
%% Add a gap between elements
\hspace{0.08\textwidth}
%%%
\begin{minipage}{0.52\textwidth}%
```{r, fig.width=4.5, fig.height=2, out.width='98%'}
par( mar = c(0.1, 0.1, 0.1, 0.1))
openplotmat()

pos <- array(NA, 
             dim = c(3, 2)) 
pos[1, ] <- c(0.25, 0.25) # Faecal wt
pos[2, ] <- c(0.75, 0.25) # Diet
pos[3, ] <- c(0.50, 0.75) # Age


straightarrow(from = pos[2,], 
              to = pos[1,], 
              lty = 2, 
              lwd = 2,
              lcol = "grey")
straightarrow(from = pos[3,], 
              to = pos[1,], 
              lty = 1, 
              lwd = 2,
              lcol = "black")
straightarrow(from = pos[3,], 
              to = pos[2,], 
              lty = 1, 
              lwd = 2,
              lcol = "black")


text(x = 0.5,
     y = 0.46,
     cex = 0.85,
     pos = 3,
     labels = "Actual links")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 3,
     labels = "Apparent")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 1,
     labels = "link")

textrect( pos[1,], 
          lab = "Faecal wt",
          radx = 0.14,
          rady = 0.075,
          shadow.size = 0,
          lcol = ResponseColour,
          box.col = ResponseColour)
textrect( pos[2,], 
          lab = "Diet", 
          radx = 0.14,
          rady = 0.075,
          shadow.size = 0,
          lcol = ExplanatoryColour,
          box.col = ExplanatoryColour)
textrect( pos[3,], 
          box.col = "white",
          lcol = grey(0.75),
          shadow.size = 0,
          radx = 0.20,
          rady = 0.075,
          col = grey(0.3),
          lab = "Age")
```
\captionof{figure}{An extreme example of confounding\label{fig:ConfoundingDiagram}}
\end{minipage}
\end{figure}


```{r ConfoundingGroups}
if ( knitr::is_html_output()) {
  
  kable( list( IMG1,
               ConfoundTable[, c(2, 1, 3)],
               IMG2),
         caption = "Comparing Groups A and B: An extreme example of confounding",
         format = "html",
         align = "c",
         escape = FALSE) %>%
    kable_styling(full_width = FALSE)
} 
```


<!-- The figure for LaTeX is in the minipage (combined with data table), so only need show it for the HTML -->
`r if (knitr::is_latex_output()) '<!--'`
```{r ConfoundingDiagram, fig.width=5, fig.height=4, out.width='55%', fig.align="center", fig.cap="An extreme example of confounding"}
par( mar = c(0.5, 0.5, 0.5, 0.5))
openplotmat()

pos <- array(NA, 
             dim = c(3, 2)) 
pos[1, ] <- c(0.25, 0.25) # Faecal wt
pos[2, ] <- c(0.75, 0.25) # Diet
pos[3, ] <- c(0.50, 0.75) # Age


straightarrow(from = pos[3,], # Age to...
              to = pos[1,],   # ... Faceal wt
              lty = 2, 
              lwd = 2,
              lcol = "grey")
straightarrow(from = pos[3,], # Age to...
              to = pos[2,],   # ... Diet
              lty = 2, 
              lwd = 2,
              lcol = "grey")


straightarrow(from = pos[2,], 
              to = pos[1,], 
              lty = 1, 
              lwd = 2,
              lcol = "grey")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 3,
     labels = "Apparent")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 1,
     labels = "link")

textrect( pos[1,], 
          lab = "Faecel wt",
          radx = 0.15,
          rady = 0.075,
          shadow.size = 0,
          lcol = ResponseColour,
          box.col = ResponseColour)
textrect( pos[2,], 
          lab = "Diet", 
          radx = 0.15,
          rady = 0.075,
          shadow.size = 0,
          lcol = ExplanatoryColour,
          box.col = ExplanatoryColour)
textrect( pos[3,], 
          box.col = "white",
          lcol = grey(0.75),
          shadow.size = 0,
          radx = 0.20,
          rady = 0.075,
          col = grey(0.3),
          lab = "Age")
```

`r if (knitr::is_latex_output()) '-->'`


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*The groups being compared should be as similar as possible*, apart from the difference being studied.
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-andrea-piacquadio-3768131.jpg" width="200px"/>
</div>




Confounding can be managed by:

* *Restricting* the study to a certain group, by keeping some variables approximately constant.
  These variables are called *control variables*.\index{Confounding!experimental studies!control variables}
  If possible, a reason for this restriction should be given.
* *Blocking*.\index{Confounding!experimental studies!blocking}
  Units of analysis are arranged into different groups contining individuals that are similar to one another (see Sect.\ \@ref(PairedTTest-SoilN) for an example).
  

::: {.definition #Blocking name="Blocking"}
*Blocking* occurs when units of analysis are arranged in separate groups of similar units (called *blocks*).
:::


* *Analysing* using special methods (beyond this book), after recording the values of potential confounding variables.
  Because of this, *recording all potential extraneous variables* is important.
  Most studies involving people record the participants' age and sex, as these two variables are common confounders.
  Once a sample is obtained, recording this extra information usually requires little extra effort.
* *Randomly allocating* individuals to the comparison groups.\index{Confounding!analysis}
  Random allocation should ensure that potential confounding variables are approximately evenly spread between the comparison groups. \index{Confounding!experimental studies!random allocation}
  This is true for potential confounders that have been identified (such as age), and also for variables that may *not* have even been considered as confounders, or are hard to measure or observe (such as genetic conditions).


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Record* all the extraneous variables likely to be important for understanding the data.
This may include information about the *individuals* in the study, and the *circumstances* of the individuals in the study.
:::


Multiple approaches can be used, such as randomly allocating individuals to groups, *and* recording other variables that can be managed through analysis.

*Restricting* and *blocking* are useful if one or two variables are known, or thought likely, to cause confounding.
*Analysing* requires recording all the variables suspected of being confounders.
*Randomly allocating* is superior when possible, because the chance of confounding is reduced for variables not even suspected as being confounders.

Common to many of these methods is to ensure that any potential confounding variables are recorded (Sect.\ \@ref(RecordExtraneous)), to ensure no *lurking variables* exist that may compromise the results.
  
  
  
::: {.example #HimalayaConfounding name="Managing confounding"}
For the *Himalaya* study, different methods can be used to manage confounding due to age.

The study could be *restricted* to only study people under $30$.
Age would be the *control variable*.

*Blocking* could be used by finding similar pairs of subjects (e.g., pairs of subjects of the same sex, with similar age and weight).
Then, one of each pair is given the refined cereal diet, and one given the *Himalaya 292* diet.
The *differences* in faecal weight for each pair can be analysed using special methods (see Chap.\ \@ref(TestPairedMeans) for example). 

Information *about the individuals* could be *recorded*, such as age and pre-study weight.
Information *about the circumstances* of the individuals could also be *recorded*, such as the suburb where they live.
Then, special methods of analysis could be used to analyse the data.

Participants could be *randomly allocated* into one of two groups, so both groups would have a similar spreads of ages (and other potential confounders).
Then groups could be randomly allocated to receive one of the diets (Fig.\ \@ref(fig:RandomAllocationHimalaya)).

In the *Himalaya 292* study, individuals were randomly allocated randomly to the diets (p.\ 1033).
:::




```{r RandomAllocationHimalaya, echo=FALSE, fig.cap="Random allocation can occur in two places for the Himalaya study", fig.align="center", fig.height=3, out.width='65%'}

showStudyDesign(studyType = "TrueExp",   
                addIndividuals = TRUE,
                addByResearchers = FALSE,
                addImages = TRUE,   
                addRandomAllocationText = TRUE, 
                imageList = c("./Pics/iconmonstr-candy-5-240.png",
                              "./Pics/iconmonstr-candy-8-240.png"),
                addCNames = c("Himalaya 292",
                              "Refined"))
```


:::{.exampleExtra  data-latex=""}
An experiment to study the effect of using ginko to enhance memory [@data:Solomon2002:Ginko] compared two groups: one using ginko ($n = 111$), and one using a fake, non-active supplement ($n = 108$).
The authors randomly allocated participants to each group, then compared the two groups to ensure that no obvious differences initially existed between the groups that might explain differences in the response variable (Table\ \@ref(tab:GinkoDemographics)).

Two groups are similar in terms of age, education and gender distribution.
Any difference in outcome between the groups is probably due to the treatment.



```{r GinkoDemographics}
Ginko <- array( dim = c(3, 3) )
colnames(Ginko) <- c("Characteristic", 
                     "Group A (Ginko)", 
		     "Group B (Fake)")

Ginko[1, ] <- c("Average age (in years)", 
                "68.7", 
		"69.9")
Ginko[2, ] <- c("Men (number; percentage)", 
                "46 (41%)", 
		"45 (42%)")
Ginko[3, ] <- c("Average years of education", 
                "14.4", 
		"14.0")

if( knitr::is_latex_output() ) {
  kable(Ginko,
        format = "latex",
        longtable = FALSE,
        booktabs = TRUE,
        #escape = FALSE, # For latex to work in \rightarrow
        linesep  =  c("", "", "", "\\addlinespace", "", "", ""), # Otherwise addes a space after five lines... 
        caption = "Comparing the two groups in the ginko-memory study",
        align = c("r", "c", "c"))   %>%
   kable_styling(full_width = FALSE, font_size = 8) %>%
   row_spec(0,bold = TRUE) # Columns headings in bold
}

if( knitr::is_html_output() ) {
  kable(Ginko,
        format = "html",
        align = c("r", "r", "r"),
        longtable = FALSE,
        caption = "Comparing the two groups in the ginko-memory study",
        booktabs = TRUE) 
}
```
:::


:::{.exampleExtra  data-latex=""}
Researchers explored the use of dominant and non-dominant hands for chest compression in student paramedics using an experimental study [@cross2019impact].
Students were randomly divided into two groups: DHOS (dominant hand on chest) and NDHOC (non-dominant hand on chest).
The two groups were then compared:

| Demographic                  | All participants ($n = 75$) | DHOC ($n = 37$) | NDHOC ($n = 38$) 
| ----------------------------:+:-----------------------------:+:-----------------:+:----------------:
| Average age (years)          | $23.4$                        | $22.5$            | $24.3$
| Gender: percentage Female    | $51$%                         | $53$%             | $47$%

The two groups appear to be very similar in terms of average age of participants, and the percentage of female participants.
If differences are observed in the study between the DHOC and NDHOC groups, it is probably due to the treatment.
The study should have reasonable internal validity.
:::




<!-- (ref:BlockingHimalaya) Blocking in the *Himalaya* study, based on age -->

<!-- ```{r  BlockingHimalaya, fig.cap="(ref:BlockingHimalaya)",  fig.align="center", fig.width=8, fig.height=5, out.width="80%"} -->
<!-- showStudyDesignBlocking(studyType = "TrueExp",    -->
<!--                         addIndividuals = TRUE) -->
<!-- ``` -->





::: {.example #Manure name="Analysis to manage confounding"}
An experimental study [@schroder2015maize] compared nitrogen (N) and phosphorus (P) concentrations in maize, for evenly-injected liquid manure and band-injected liquid manure.
As potential confounding variables, the researchers also recorded the average temperature and the precipitation (between May\ 1 and September\ 30) at each site.
:::


Individuals may be randomly allocated into groups (in true experiments).
In addition, groups may be randomly allocated to receive treatments (in true and quasi-experiments).
<!-- Random allocation can be shown, in general, as in Fig.\ \@ref(fig:RandomAllocationGeneral). -->


<!-- ```{r RandomAllocationGeneral, echo=FALSE, fig.cap="Random allocation in general, with more than two treatments and groups", fig.align="center", fig.height=3, out.width='65%'} -->
<!-- showStudyDesign(studyType = "TrueExp",    -->
<!--                 addIndividuals = TRUE,     -->
<!--                 addImages = FALSE, -->
<!--                 addByResearchers = FALSE, -->
<!--                 addGroupNames = c("Group 1", "Group 2", "Group 3"), -->
<!--                 addCNames = c("Treatment 1", "Treatment 2", "Treatment 3"), -->
<!--                 addRandomAllocationText = TRUE) -->
<!-- ``` -->





## Random allocation vs random sampling {#Random-sampling-allocation}
\index{Confounding!random allocation}\index{Sampling}

Random *sampling* and random *allocation* are different concepts (Fig.\ \@ref(fig:RandomAllocationSampling)), with different purposes, but are often confused:

* *Random sampling* impacts *external* validity.
  Its purpose is *finding individuals* to study.
* *Random allocation* helps eliminate confounding issues, by distributing possible confounders across treatment groups.
  *Random allocation* impacts *internal* validity.
  Its purpose is *allocating treatments to individuals*.



```{r RandomAllocationSampling, echo=FALSE, fig.cap="Comparing random allocation and random sampling", fig.align="center", fig.height=3, out.width='75%'}

showStudyDesign(studyType = "TrueExp", 
                addIndividuals = TRUE, 
                addCompareText = TRUE, 
                addResearcherControl = FALSE, 
                addInternalValidityText = TRUE,
                addByResearchers = FALSE,
                addRandomAllocationText = TRUE, 
                addRandomSamplingText = TRUE, 
                addExternalValidityText = TRUE, 
                addSampling = TRUE)
```


<iframe src="https://learningapps.org/watch?v=poh7e35e222" style="border:0px;width:100%;height:500px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>
 


## Hawthorne effect and blinding individuals {#HawthorneEffectExperimental}
\index{Hawthorne effect}\index{Blinding!individuals}

Suppose patients in the *Himalaya 292* study were being watched (or waited for) while defecating.
Could this lead to a misleading conclusion?

People, and perhaps animals, may behave differently if they know (or think) they are being watched, which could compromise the internal validity of the study.
This is called the *Hawthorne effect*.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-binoculars-8-240.png" width="50px"/>
</div>


::: {.definition #HawthorneEffect name="Hawthorne effect"}
The Hawthorne effect is the tendency of individuals to change their behaviour if they know (or think) they are being observed.
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


::: {.example #HawthorneFruitVege name="Hawthorne effect"}
People are more health-conscious if they know they will be examined regularly.
For example, a study aiming to increase fruit and vegetable intake in young adults [@clark2019educational] noted that the observed increases in intake 'could be explained by the Hawthorne effect' as they 'know they are being observed...'. (p.\ 96).
:::


The impact of the Hawthorne effect can be minimized by blinding the individuals in the experiment, so that:

* the individuals do not know that they are *participating* in a study; and/or
* the individuals do not know the *aims of the study*; and/or 
* the individuals do not know which *treatment they are receiving* in the study. 

Blinding *people* to knowing they are involved in a study is often difficult, as ethics often requires informed consent (Sect.\ \@ref(Common-Ethical-Issues)).


::: {.example #HawthorneHimalaya name="Hawthorne effect"}
The *Himalaya 292* article reports that (p.\ 1033):

> The study was explained fully to the subjects, both verbally and in writing, and each gave their written, informed consent... 

That is, the subjects knew they were in a study, and knew the aims of the study, so the Hawthorne effect may influence the results in this study.
However, the subjects did not know *which* diet they were given
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-photomix-company-216729.jpg" width="200px"/>
</div>


::: {.example #HawthorneTeeth name="Hawthorne effect"}
@lorenz2019effect compared the efficacy of a new type of toothpaste.
Participants were given either a new or an existing toothpaste formulation, and evaluations of plaque remaining on the teeth were taken.
*Both* groups recorded a reduced amount of plaque.

The reason was the Hawthorne effect: since all participants knew they were being assessed after brushing, they brushed better than usual.
:::


## Observer effect and blinding researchers {#ObserverEffectExperimental}
\index{Observer effect}\index{Blinding!researchers}

Suppose the *researchers* assessing the study outcomes *knew the diet* allocated to each patient.
Could this lead to a misleading conclusion?

Perhaps surprisingly, researchers' expectations or hopes for how the new diet will perform may unconsciously influence how the researchers interact with the individuals, and so perhaps (unconsciously) influence the behaviour of the individuals in the study.
This is called *observer effect*.
(In experiments, it is sometimes called the *experimenter effect*.)
This could compromise the internally validity of the study.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-idea-10-240.png" width="50px"/>
</div>


::: {.definition #ObserverEffect name="Observer effect"}
The observer effect occurs when the researchers unconsciously change their behaviour to conform to expectations because they know what values of the explanatory variable apply to the individuals.
This may then cause the *individuals* to change their behaviour or reporting also.
:::


The impact of the observer effect can be minimized by blinding the researchers, so that they do not know which treatments the individuals are receiving.
The researchers *giving* the treatment and the researchers *evaluating* the treatment can both be blinded, by using a third party.
For example, the researchers may give an assistant two drugs, labelled\ A and\ B.
The assistant administers the drug and evaluates the participants' response to the treatments.
Later, the assistant tells the researchers whether Drug\ A or Drug\ B performed better, but only the researchers know which drugs the labels\ A and\ B refer to (Fig.\ \@ref(fig:BlindingThirdParty)).


```{r, BlindingThirdParty, echo=FALSE, fig.align="center", fig.cap="Using a third party to avoid the observer effect", fig.height=3, fig.width=8, out.width='85%'}
showStudyDesign(studyType = "TrueExp", 
                addIndividuals = TRUE, 
                addThirdParty = TRUE)    
```



::: {.example #ObsEffectyPain name="Observer effect"}
In a study [@seo2020role] that examined the impact of an injection to alleviate post-operative umbilical pain, the authors stated (p.\ 392):

> ...the postoperative pain scores were gathered by a nurse practitioner who was blinded to the usage of bupivacaine to avoid observer-expectancy bias [i.e., the observer effect].
:::


The observer effect does not just apply to situations with *people* as individuals.


::: {.example #CleverHans name="Observer effect"}
`r if (knitr::is_latex_output()) {
   'Clever Hans'
} else {
   "['Clever Hans'](https://en.wikipedia.org/wiki/Clever_Hans)"
}`
was a horse that seemed to perform simple mental arithmetic.
By using an experiment where the people interacting with the horse were blinded, Carl Stumpf realised that the horse was responding to involuntary (and unconscious) cues from the trainer.

The same effect has been observed in narcotic sniffer dogs [@bambauer2012defending], who may respond to their handlers' unconscious cues.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The *observer effect* is when the researcher *unconsciously* influence the individuals, and are not aware it is occurring.
*Intentionally* influencing the individuals is fraud.
:::


<iframe src="https://learningapps.org/watch?v=puedghp1c22" style="border:0px;width:100%;height:500px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>


## Placebo effect, controls and blinding {#PlaceboEffectExperimental}
\index{Placebo effect}\index{Blinding!individuals}\index{Control group}

To know whether the *Himalaya* diet changed faecal weight, the researchers compared the outcome for people on the *Himalaya* diet to the outcome for people on a refined-cereal diet.
The people on the refined-cereal diet acted as the *control group* (Sect.\ \@ref(Intervention)).
The refined cereal acted as a benchmark; like a *placebo*.

Perhaps surprisingly, individuals in a study may report effects of a treatment, even if they have not received an active treatment.
This could compromise the internally validity of the study.
This is called the *placebo effect*, which generally only impacts people as individuals.


::: {.definition #PlaceboEffect name="Placebo effect"}
The placebo effect occurs when individuals report perceived or actual effects, despite not receiving an active treatment.
:::


To manage the placebo effect, researchers should record *objective* data rather than patient-reported outcomes when possible [@enck2013placebo].
In addition, *blinding* the individuals and the researchers may help manage the placebo effect, as then the individuals cannot know which group they are in.



::: {.example #PlaceboColours name="Placebo effect"}
Three active pain relievers were compared to different-coloured placebo [@data:Huskisson1974:placebo] in $22$ patients.
The most pain relief was experienced by those taking *red* placebos (Fig.\ \@ref(fig:Placebos)), who experienced even more pain relief than those given true pain relievers.
Note that the outcome is subjective: a *patient*-reported outcome.
:::


```{r Placebos, echo=FALSE, fig.align="center", out.width='65%', fig.width=5.75, fig.height=3.5, fig.cap="Pain relief, for various pain relief medicine and placebos"}
data(Placebos)

par( xpd = TRUE,   # Allows plotting outside plot area
     mar = c(4, 4, 4, 4) + 0.1 )  # DEFAULT: c(5, 4, 4, 2) + 0.1
	 
plot( c(0, 2.75) ~ range(Time), 
      data = Placebos,
      las = 1, 
      type = "n", 
      axes = FALSE,
      main = "Average pain relief for various medications",
      xlab = "Time (hours)", 
      ylab = "Pain relief score")
axis(side = 1)
axis(side = 2,
     las = 1,
     at = seq(0, 2, by = 0.5))
box()

# abline seems to go outside margins...? Because of xpd?
lines( x = c(0, 6.3),
       y = c(1, 1), 
       lty = 2,
       col = "grey")
lines( x = c(0, 6.3),
       y = c(2, 2), 
       lty = 2,
       col = "grey")
mtext(" Moderate\n relief",
      side = 4,
      at = c(5.75, 2),
      las = 1,
      adj = 0,
      cex = 0.9)
mtext(" Slight\n relief",
      side = 4,
      at = c(5.5, 1),
      las = 1,
      adj = 0,
      cex = 0.9)

lines( Asp ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       col = "black", 
       lty = 1,
       lwd = 2)

lines( Placebo ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       col = "orange", 
       lty = 2,
       lwd = 2)

lines( PlaceboRed ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       lty = 2,
	     col = "red", 
       lwd = 2)

legend("top", 
	col = c("red", 
	        "black", 
	        "orange"), 
	lwd = 2, 
	lty = c(3, 1, 2),
	bty = "n",
	ncol = 2,
	#horiz = TRUE,
	legend = c("Red placebos", 
	           "Aspirin", 
	           "All Placebos"))
# Add initial point at t = 0, as all lines start there and last plot overtakes the colour
points(x = 0,
       y = 0,
       pch = 21,
       bg = "white",
       col = "black")
```




<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-help-3-240.png" width="50px"/>
</div>



::: {.example #HimalayaPlacebo name="Placebo effect"}
In the *Himalaya* study, the individuals 'were not told the identity of the test cereal in the foods provided' (@data:Bird2008:wholegrain, p.\ 1033).
The subjects were blinded to the diet they were exposed to.
However, some may *think* they are on the refined cereal or *Himalaya* diet, and respond accordingly (perhaps unconsciously).
The use of the refined cereal was acting as a control.
Researchers measured faecal weight, an *objective* outcome, to minimise the placebo effect.
:::


:::{.exampleExtra  data-latex=""}
A study of placebos [@data:Waber2008:Placebo] gave half the subjects a placebo, but told them the pill was an expensive (implying 'effective') pain killer.
The other half were also given a placebo, but were told the pill was a discount (implying 'less effective') pain killer.
About $85$% of participants in the first group reported a pain reduction, yet only $61$% in the second group reported a pain reduction.
Remember: *both* groups actually received a placebo!
Again, 'pain relief' is subjective.
:::


## Carry-over effect and washouts {#CarryOverEffectExperimental}
\index{Carry-over effect}\index{Washouts}

In the *Himalaya* study, the diet is a *between-individuals* comparison: one group of patients is given the refined cereal diet (the control), and a different group of people was given *Himalaya 292*.
The study *also* used a *within-individuals* comparison: each person in the study was actually placed on both diets at different times.

Suppose all patients spent four weeks on the *Himalaya 292* diet, then the next four weeks on the refined cereal diet.
Potentially, the first diet could still be impacting the subjects' faecal weight for a little while after stopping the first diet.
This could compromise the internally validity of the study.
This is an example of the *carry-over effect*: when the influence of one treatment carries over to influence the next treatment.
The carry-over effect is only a concern for *within-individuals* comparisons.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-chart-21-240.png" width="50px"/>
</div>


::: {.definition #CarryoverEffect name="Carryover effect"}
The carry-over effect occurs when the influence of one treatment influences individuals' responses to subsequent treatments.
:::


The impact of the carry-over effect may be minimized by using a *washout* or similar between treatments.
For example, after tasting a food sample, participants may rinse their mouth with water before tasting another food sample.
For the *Himalaya* study, between using the special diets, the participants could spend two weeks on their usual (before-study) diet.
This is called a *washout period*.


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


::: {.example #HimalayaCarryOver name="Carry-over effect"}
In the *Himalaya* study, 'there was no washout period' (@data:Bird2008:wholegrain, p.\ 1033) since the response variable was only recorded after individuals spent four weeks on each diet.
Since faecal weight was not measured until the *end* of this four weeks, the effect of the diet change would be minimal.
:::


::: {.example #HimalayaWashout name="Carry-over effect"}
An engineering study [@miller2019behavioral] examined drivers' exposure to lane-keeping systems on their driving performance.
Subjects were exposed to a driving simulation that used a lane-keeping system, and then to a driving simulation without using a lane-keeping system.
The researchers found that driving performance was impacted when drivers moved from a simulation *with* a lane-keeping system to one *without* a lane-keeping system.
:::


::: {.exampleExtra  data-latex=""}
In @jaskiewicz2020chest, student paramedics performed chest compression in real-life (RL), and also using virtual reality (VR).
A relaxation percentage of about $50$% is ideal.

When used by itself, the VR method produced an average relaxation percentage of $45.5$%.
However, when the RL method was used first, and then followed by the VR method, the average VR relaxation method percentage was $74.7$%.

The response of the individuals was different depending on whether the RL method was used first.
This is an example of the carry-over effect.
:::


Sometimes, when relevant, researchers can *randomly allocate* the *order* in which the treatments (i.e., the diets) are used (a *cross-over study*).
That is, some participants start by spending four weeks on the *Himalaya 292* diet, then four weeks on the refined cereal diet; meanwhile, other participants start by spending four weeks on the refined cereal diet, then four weeks on the *Himalaya 292* diet.


::: {.example #HimalayaCarryOver2 name="Carry-over effect"}
In the *Himalaya* study, the 'subjects were allocated randomly to [...] dietary treatments' (@data:Bird2008:wholegrain, p.\ 1033).
Subjects were randomly allocated to begin the study on either the *Himalaya 292* diet *or* the refined cereal diet.
:::


::: {.example #ParamedOrder name="Washout periods"}
@data:MacDonald:Resuscitation required paramedics to conduct eight different tasks (such as electrical defibrillation and intravenous cannulation).
Each of the $16$ paramedics began the series of tasks at a random task, to mitigate the carry-over effect.
A washout period between tasks was also used.
:::


## Describing blinding {#DescribingBlinding}
\index{Blinding!descriptions}\index{Blinding}

*Blinding* occurs when those involved in the study do not know information about the study.
*Individuals* in the study may be blinded to 

* whether they are *involved in a study*;
* the *aims of the study* in which they are participants; and/or 
* *which comparison group* they are in.

The *researchers* and the *analysts* can be blinded to which comparison groups apply to the individuals. 

When blinding is used in as many ways as possible, the internal validity of the study is increased and bias reduced.
However, when people are the individuals, ethics requirements may mean that they need to know they are in a study (especially if the study is experimental), and the purpose of the study.

If *only* the individuals are blinded to the comparison groups, the study is called *single blind*.\index{Blinding!single}
If *both* the researchers and participants are blinded to the comparison groups, the study is called *double blind*.\index{Blinding!double}
If the researchers, participants *and* the analyst are blinded to the comparison groups, the study is called *triple blind*.\index{Blinding!triple}
Rather than using these terms, explicitly stating who or what is blinded is clearer.


::: {.thinkBox .think data-latex="{iconmonstr-light-bulb-2-240.png}"}
Why might it be necessary to blind the *analyst* to the treatments used?
:::


Blinding should be considered in all studies when possible (it is *not* always possible).
*Blinding participants does not just apply to people*; it also may apply to animals (Example\ \@ref(exm:CleverHans)).


::: {.example #BlindingCowpea name="Double-blinding"}
@bulte2014behavioral compared yields from modern and traditional cowpea crops in Tanzania.
The two seed types ('traditional' and 'modern') were made similar in appearance so the farmers were blinded.
The seed type would eventually become obvious as the crop grew, but 'key inputs were already provided' by then (p.\ 817).
:::



## Recording extraneous variables {#RecordExtraneous}
\index{Variables!extraneous}

One way to design a quality study is to record information about many extraneous variables.
Various reasons for doing this have been given:

* To evaluate *external validity* to determine if the sample is representative of the population (Sect.\ \@ref(Representative-samples)), by comparing the sample and population.
* To improve *internal validity*, by helping to manage confounding:

  * by using special methods of analysis (Sect.\ \@ref(ExtraneousVariables)).
  * by avoiding lurking variables (Sect.\ \@ref(ExtraneousVariables)).
  * by determining if the comparison groups are similar (Sect.\ \@ref(ExpManagingConfounding)).
  * by using the information in analysis (Sect.\ \@ref(ExpManagingConfounding)).


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Record the values of all extraneous variables that may be important in the study*!
:::


\index{Study design!experimental|)}

## Chapter summary {#Chap7-Summary}

Designing effective *experimental* studies (Fig.\ \@ref(fig:DesignConsiderations)) requires researchers to *manage or minimise confounding* where possible, by *restricting* the study to certain groups; *blocking* individuals into similar groups; through special *analysis* methods; and/or through *random allocation* of the units of analysis.

Well-designed experimental studies also try to manage the *Hawthorne effect* (e.g., by blinding *participants*); the *observer effect* (e.g., by blinding the *researchers*); the *placebo effect* (e.g., by using controls, and using objective outcomes); and the *carry-over effect* (e.g., by using a washout, or randomly allocating the treatment order).
This ensures that the results and conclusions from our studies are correctly interpreted.

`r if (knitr::is_html_output()){
  'The following short video may help explain some of these concepts:'
}`

<div style="text-align:center;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/eic_LjXT4qc" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture"></iframe>
</div>


Often, however, not all of these strategies can always be used.
For instance, people often know they are involved in an experimental study, so the Hawthorne effect may impact conclusions.
In these cases, the possible impacts should be minimized as far as possible, and then the likely impact on the conclusions discussed.
The impact of these issues are often reported as *limitations* in a journal article (Chap.\ \@ref(Interpretation)).


(ref:DesignConsiderations-Caption) Design considerations for experimental studies. Note: lurking variables become confounding variables when recorded in the study, and so can be managed. The arrows indicate the main design strategy to (perhaps partially) manage the indicated potential bias. Not all strategies are possible for every study.

```{r DesignConsiderations, echo=FALSE, fig.cap='(ref:DesignConsiderations-Caption)', out.width='75%', fig.align="center",  fig.width=7.00} 
# fig.height=6,
source("R/showDesignConsiderations.R")
showDesignConsiderations(studyType = "Experiment")
```




::: {.example #DesignExample name="Research design"}
@cross2019impact (p.\ 3) comparing chest compressions by student paramedics using dominant and non-dominant hands:

> ...participants were allocated randomly to one of two groups: 'dominant hand on chest' or 'non-dominant hand on chest'. 
> Group allocation was determined by a computer-generated randomisation schedule...

The participants were blinded to the *purpose* of the study, but not to which group they were allocated.
The analyst was also blinded to the group allocations.
This study used many good design features.
:::


## Quick review questions {#Chap7-QuickReview}

::: {.webex-check .webex-box}
A study [@doosti2016development] wanted to determine the relationship between the surface temperature of the apple, and the depth of bruising.
The researchers purposefully hit apples with three different *forces* ($200$, $700$ and $1200$\ mJ) to inflict bruises.
The researchers then recorded the *depth* of the bruising, and recorded the *surface temperature* at each bruise location.

The study was conducted separately for three different *regions* of the apple (lower; middle; upper), and each apple was only used once.

1. The *response variable* is \tightlist
`r if( knitr::is_html_output() ) {longmcq( c(
	"The force used on the apples",
	answer = "The depth of the bruising",
	"The location of the bruising",
	"The surface temperature at the bruise site"))} else {"________________."}`
2. The *explanatory variable* is
`r if( knitr::is_html_output() ) {longmcq( c(
	"The force used on the apples",
	"The depth of the bruising",
	"The location of the bruising",
	answer = "The surface temperature at the bruise site"))} else {"________________."}`
`r if (knitr::is_html_output()) '<!--'`  
3. What is the role of the variable 'The location of the bruising'?  
   a. A confounding variable: it may be related to the explanatory variable only.
   b. A confounding variable: it may be related to the response variable and explanatory variables.
   c. An extraneous variable: it may be related to the response variable only.
   d. A lurking variable: we don't know how it might be related to the response and explanatory variables.
`r if (knitr::is_html_output()) '-->'`
`r if (knitr::is_latex_output()) '<!--'`
3. What is the role of the variable 'The location of the bruising'?  
`r longmcq( c(
	"A confounding variable: it may be related to the explanatory variable only",
	"A confounding variable: it may be related to the response variable and explanatory variables",
	answer = "An extraneous variable: it may be related to the response variable only",
	"A lurking variable: we don't know how it might be related to the response and explanatory variables"))`
`r if (knitr::is_latex_output()) '-->'`
4. True or false: The researchers could minimise the effects of confounding by incorporating potential confounding variables in the analysis.  \tightlist
`r if( knitr::is_html_output() ) {torf( TRUE)}`
5. True or false: The researchers could use random allocation of the treatments to the apples to minimise confounding.  
`r if( knitr::is_html_output() ) {torf( TRUE)}`
6. True or false: The *carry-over* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
7. True or false: The *Hawthorne* effect is likely to be a big problem in this study. 
`r if( knitr::is_html_output() ) {torf( FALSE)}`
8. True or false: The *placebo* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
9. True or false: The *observer* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE )}`
:::



## Exercises {#DesigningExperimentsExercises}

Answers to odd-numbered questions are available in App.\ \@ref(Answers).


::: {.exercise #DesignExpTrueFalse}
Are the following statements *true* or *false*?

1. Experimental studies *must* use random samples. \tightlist  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
2. An experimental study *must* blind the researchers.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
3. An experimental study *must* blind the participants.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
4. Experimental studies *must* use a control group. 
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
5. In experimental studies, the treatments *must* be allocated by the researchers.  
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
:::


::: {.exercise #DesignExpImproveIV}
:::: {.webex-check .webex-box}
Which of the following can be used to improve internal validity in experiments?

   * Blinding the individuals.  \tightlist
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
   * Using a control group.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
   * Using special methods of analysis.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
   * Randomly allocating treatments to groups.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
   * Blinding the researchers.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
   * Using random samples.
`r if( knitr::is_html_output() ) {mcq( c("Yes", answer = "No"))}` 
::::
:::


::: {.exercise #DesignExpExtraneous}
`r if (knitr::is_html_output()) '<!--'`
Extraneous variables are variables that are related to the response variable.  
Which of the following types of variables are special types of extraneous variables?  
(a)\ Lurking variables; (b)\ explanatory variables; (c)\ confounding variables.
`r if (knitr::is_html_output()) '-->'`
`r if (knitr::is_latex_output()) '<!--'`
Extraneous variables are variables that are related to the response variable.  
Which of the following types of variables are special types of extraneous variables?

* Lurking variables `r mcq( c(answer = "Extraneous", "Not extraneous") )` 
* Explanatory variables `r mcq( c("Extraneous", answer = "Not extraneous") )` 
* Confounding variables `r mcq( c(answer = "Extraneous", "Not extraneous") )`
`r if (knitr::is_latex_output()) '-->'`
:::


::: {.exercise #DesignExpWeightLoss}
Consider a study comparing the average weight loss for patients who do at least $30$\ mins of exercise a day (Group\ A), to patients who do less than $30$\ mins of exercise a day (Group\ B).
Which of the following statements are true?

1. The extraneous variable is the amount of exercise per day (in hours).\tightlist
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
2. The response variable is the weight loss for each person.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
3. The explanatory variable is whether or not the patient performs at least 30 minutes of exercise per day.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
4. The response variable is the **average** weight loss.
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
5. The explanatory variable is the amount of exercise the patient does per day (in hours).
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
6. Age is likely to be a lurking variable.
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
7. Age is an extraneous variable.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
8. Age is likely to be a confounding variable.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}`

Which of the following are possible **confounding** variables?

   * The sex of the patients. \tightlist
  `r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
   * The initial weight of the patients.
  `r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
   * The names of the patients.
  `r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
:::


::: {.exercise #DesignExpParamedicsPills}
Paramedics were involved in a study to compare two new pills (Treatment\ A, and Treatment\ B) to treat Post Traumatic Stress Disorder (PTSD).  

1. What would be the control group? \tightlist
`r if( knitr::is_html_output() ) {
   longmcq( c("The group receiving Treatment A",
              "A group of paramedics who do not have PTSD",
              "The group receiving Treatment B",
              "A group of paramedics not involved in the study",
              "A group of people with PTSD who are not paramedics",
              answer = "A group receiving a pill that looks just like Treatment A and B, but has no effective ingredient"))}`

2. The patients did not know which treatment they received.
What is this called?
`r if( knitr::is_html_output() ) {
   longmcq( c("Blinding the researchers",
              "Double blinding",
              "Managing confounding",
              answer = "Blinding the participants"))}`

3. What is the purpose of blinding the participants?
`r if( knitr::is_html_output() ) {
   longmcq( c("To ensure that researchers did not unintentionally influence the results",
              answer = "To ensure that participants did not change their behaviour because of the treatment they were receiving",
              "To manage confounding"))}`
:::


::: {.exercise #ResearchDesignFertilizer}
A scientist compares the effects of two types of fertiliser on the yield of tomatoes (based on @klanian2018integrated).
He plants tomato seedlings, and fertilises with Fertiliser\ I, and later records the yield of tomatoes.
He then immediately plants more tomato seedlings in the same field, fertilises with Fertilizer\ II, and measures the yield of tomatoes.

What potential problems can you identify with the study design?
:::


::: {.exercise #ResearchTasteOfWater2}
A scientist is testing whether tap water tastes the same as bottled water in a taste test (based on @teillet2010consumer).
The scientist provides people with a plastic cup of either bottled or tap water, and she asks them to give a rating of the taste on a scale of $1$ (terrible) to $5$ (fantastic).

What potential problems can you identify with the study design?
:::


:::::: {.exercise #ResearchDesignTasteOfWater3}
Consider this RQ (based on @teillet2010consumer):

> For university students, is the taste of tap water better than the taste of bottled water?

This RQ needs some clarification, but you decide to answer this question using an *experiment*.
How would you manage:

:::: {.cols data-latex=""}
::: {.col data-latex="{0.4\textwidth}"}

1. random allocation?
2. blinding?
3. double blinding?

:::

::: {.col data-latex="{0.05\textwidth}"}
\ 
<!-- an empty Div (with a white space), serving as
a column separator -->
:::

::: {.col data-latex="{0.5\textwidth}"}

4. finding a control?
5. finding a random sample?

:::

::::

::::::


::: {.exercise #ResearchDesignSunscreen}
In a study of time spent applying sunscreen [@data:Heerfordt2018:sunscreen], the Aim was to 'determine whether time spent on sunscreen application is related to the amount of sunscreen used' (p.\ 117).
The study is described as follows (p.\ 118):

> The volunteers were asked to apply the provided sunscreen [...] the way they would normally do on a sunny day at the beach in Denmark [...]
> The volunteers wore swimwear during the whole session. 
> No other information was given. 
> Participants applied sunscreen behind a curtain and were not observed during application. 
> Measurements of time and sunscreen weight were made without the subjects' being aware of this.

1. What are the response and explanatory variables?
1. The researchers also recorded age, height, weight and body surface area of each participant. 
   Why would they have done this?
1. The researchers also compared the mean values of the response variable for males and females, 
   and the mean values of the explanatory variable for males and females. 
   Why would they have done this? 
1. What design features are evident in the quote?
:::


<!-- https://bmcoralhealth.biomedcentral.com/articles/10.1186/s12903-018-0588-1  About tooth brushing -->


<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to in-chapter questions:**

- \textbf{\textit{Quick Revision} questions:}
**1.** Surface temperature at the bruise.
**2.** Depth of the bruising.
**3.** Extraneous: likely to be related to the response variable only.
**4.** True.
**5.** True.
**6.** False.
**7.** False.
**8.** False.
**9.** False.
:::
`r if (knitr::is_html_output()) '-->'`
