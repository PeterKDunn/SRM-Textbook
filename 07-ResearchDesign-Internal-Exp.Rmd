
# Internal validity in experimental studies {#DesignExperiment}



<!-- Introductions; easier to separate by format -->

```{r, child = if (knitr::is_html_output()) {'./introductions/07-ResearchDesign-Internal-Exp-HTML.Rmd'} else {'./introductions/07-ResearchDesign-Internal-Exp-LaTeX.Rmd'}}
```


## Introduction {#Chap7-Intro}

To draw solid conclusions, a well-designed study is needed: a study with high [*internal validity*](#def:InternalValidity).
When studying the relationship between the response and explanatory variables, ideally other explanations for changes in the value of response variable can be ruled out, so any remaining changes we see can be attributed to changes in the value of the explanatory variable.
Many aspects of the design must be considered to achieve this goal, some of which are discussed in this chapter.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
One goal of study design is to maximise internal validity: to design a study to isolate the relationship of interest, by eliminating, as well as possible, all other possible explanations.
:::


::: {.example #InternalValidity name="Importance of internal validity"}
Researchers [@beaman2013profitability] describe an experiment where free fertilizer was provided to a sample of female farmers in Mali (at the recommended amount rate, or at half the recommended rate).

Since all the farmers knew they were in the study, the farmers changed their farm management: they employed more hired labour and used more herbicide.
Consequently, the yields for *all* farmers improved, so knowing whether the amount of fertilizer applied changed yield is difficult.
The study had poor *internal validity*.
:::


Specific design strategies for maximising [internally validity](#def:InternalValidity) include:

* Managing confounding (Sect.\ \@ref(ExpManagingConfounding)).
* Managing the Hawthorne effect by blinding individuals (Sect.\ \@ref(HawthorneEffectExperimental)).
* Managing the observer-effect by blinding the researchers (Sect.\ \@ref(ObserverEffectExperimental)).
* Managing the placebo effect using controls (Sect.\ \@ref(PlaceboEffectExperimental)).
* Managing the carry-over effect using washout periods (Sect.\ \@ref(CarryOverEffectExperimental)).
* Recording potential extraneous variables (Sect.\ \@ref(RecordExtraneous)).

Not all of these will be relevant to every study.
This chapter discusses experimental studies; the next chapter considers design issues for observational studies.



<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


For this chapter, consider this RQ (based on @data:Bird2008:wholegrain):

> Among Australians, is the average faecal weight the same for people eating provided food made from wholegrain *Himalaya 292* compared to eating provided food made from refined cereal?  

::: {.thinkBox .think data-latex="{iconmonstr-light-bulb-2-240.png}"}
For the *Himalaya 292* study:\label{thinkBox:HimalayaPOCI}
\vspace{-2ex}

1. Determine P, O, C and I.
1. What are the variables?
1. What *type* of study is this?

`r if (!knitr::is_html_output()) '<!--'`
`r webexercises::hide()`
1. **P**: Australians. **O**: average faecal weight. **C**: between those eating food made using refined cereal, and those eating food made from *Himalaya 292*. There appears to be an intervention (*provided* food).
2. The information that *must* be gathered from each individual: the faecal weight; the type of grain consumed (refined or *Himalaya 292*).
3. True experiment.
`r webexercises::unhide()`
`r if (!knitr::is_html_output()) '-->'`
:::


## Managing confounding {#ExpManagingConfounding}

Suppose that the researchers for the *Himalaya 292* study created two groups:

* **Group A**:  Women recruited at a female-only gym.
* **Group B**:  Men recruited at a local nursing home.

The researchers then gave *Himalaya 292* to Group A, and the refined cereal to Group B.
If a difference in faecal weight was detected between the two groups, the difference may due to:

* The different *diets* (the explanatory variable) for each group;
* The different *sexes* in each groups (Group A was all women; Group B was all men);
* The different *age* in each group was different (Group A is likely to be younger on average; Group B is likely to be older on average);
* The different health and fitness levels in each group (Group A would generally be healthier than those in Group B).

That is, any difference detected between the two groups may not be because of the cereal (Table\ \@ref(tab:ConfoundingGroups)): the study has very poor internal validity, due to poor study design.

These other variables are *confounding variables* (Def.\ \@ref(def:ConfoundingVariable)).
For example, the age of the subject may be related to faecal weight (older people tend to eat less, and eat differently, than younger people), and the study design means that older people are more likely to consume the refined cereal.
This is an extreme case of *confounding*; usually, confounding is more subtle (and hence more difficult to detect) than in this example.


```{r}
if( knitr::is_latex_output() ) {
  ConfoundTable <- array( dim = c(4, 3) )
  
  colnames(ConfoundTable) <- c("\\textbf{Variable}", 
                               "\\textbf{Group A}",
                               "\\textbf{Group B}")
  
  ConfoundTable[1, ] <- c("\\textbf{Sex}",
                          "Women",
                          "Men")
  ConfoundTable[2, ] <- c("\\textbf{Age}",
                          "Younger",
                          "Older")
  ConfoundTable[3, ] <- c("\\textbf{Cereal}",
                          "*Himalaya 292*",
                          "Refined")
  ConfoundTable[4, ] <- c("\\textbf{Fitness}",
                          "Fitter",
                          "Less fit")
  
  ConfoundTable[3, 2] <- "\\textit{Himalaya 292}"
} else {
  ConfoundTable <- array( dim = c(4, 3) )
  
  colnames(ConfoundTable)<- c( "",
                               "Group A",
                               "Group B")
  ConfoundTable[1, ] <- c("*Sex*",
                          "Women",
                          "Men")
  ConfoundTable[2, ] <- c("*Age*",
                          "Younger (in general)",
                          "Older (in general)")
  ConfoundTable[3, ] <- c("*Cereal*",
                          "*Himalaya 292*",
                          "Refined")
  ConfoundTable[4, ] <- c("*Fitness*",
                          "Very fit (in general)",
                          "Less fit (in general)")
  
  IMG1 <- array( NA, dim = c(1, 1))
  IMG1[1, 1] <- "![](./Pics/iconmonstr-candy-5-240.png){#id .class height=60px}<br>
               ![](./Pics/iconmonstr-arrow-down-thin-240.png){#id .class height=50px} <br>
               ![](./Pics/iconmonstr-generation-4-240.png){#id .class height=60px}"
  
  IMG2 <- array( NA, dim = c(1, 1))
  IMG2[1, 1] <- "![](./Pics/iconmonstr-candy-8-240.png){#id .class height=60px} <br>
               ![](./Pics/iconmonstr-arrow-down-thin-240.png){#id .class height=50px} <br>
               ![](./Pics/iconmonstr-generation-15-240.png){#id .class height=60px}"
}
```


\begin{figure}
\begin{minipage}{0.40\textwidth}
\captionof{table}{Comparing Groups A and B: An extreme example of confounding\label{tab:ConfoundingGroups}}
```{r}
kable(ConfoundTable[, c(2, 1, 3)],
      format = "latex",
      longtable = FALSE,
      booktabs = TRUE,
      table.env = "@empty",
      escape = FALSE, # For latex to work in LaTeX commands
      align = c("r", "c", "l"))   
```
\end{minipage}
%% Add a gap between elements
\hspace{0.08\textwidth}
%%%
\begin{minipage}{0.52\textwidth}%
```{r, fig.width=4.5, fig.height=2, out.width='98%'}
par( mar = c(0.1, 0.1, 0.1, 0.1))
openplotmat()

pos <- array(NA, 
             dim = c(3, 2)) 
pos[1, ] <- c(0.25, 0.25) # Faecal wt
pos[2, ] <- c(0.75, 0.25) # Diet
pos[3, ] <- c(0.50, 0.75) # Age


straightarrow(from = pos[2,], 
              to = pos[1,], 
              lty = 2, 
              lwd = 2,
              lcol = "grey")
straightarrow(from = pos[3,], 
              to = pos[1,], 
              lty = 1, 
              lwd = 2,
              lcol = "black")
straightarrow(from = pos[3,], 
              to = pos[2,], 
              lty = 1, 
              lwd = 2,
              lcol = "black")


text(x = 0.5,
     y = 0.46,
     cex = 0.85,
     pos = 3,
     labels = "Actual link")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 3,
     labels = "Apparent")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 1,
     labels = "link")

textrect( pos[1,], 
          lab = "Faecal wt",
          radx = 0.14,
          rady = 0.075,
          shadow.size = 0,
          lcol = ResponseColour,
          box.col = ResponseColour)
textrect( pos[2,], 
          lab = "Diet", 
          radx = 0.14,
          rady = 0.075,
          shadow.size = 0,
          lcol = ExplanatoryColour,
          box.col = ExplanatoryColour)
textrect( pos[3,], 
          box.col = "white",
          lcol = grey(0.75),
          shadow.size = 0,
          radx = 0.20,
          rady = 0.075,
          col = grey(0.3),
          lab = "Age")
```
\captionof{figure}{An extreme example of confounding\label{fig:ConfoundingDiagram}}
\end{minipage}
\end{figure}


```{r ResultsTable}
if ( knitr::is_html_output()) {
  
  kable( list( IMG1,
               ConfoundTable[, c(2, 1, 3)],
               IMG2),
         caption = "Comparing Groups A and B: An extreme example of confounding",
         format = "html",
         align = "c",
         escape = FALSE) %>%
    kable_styling(full_width = FALSE)
} 
```


<!-- The figure for LaTeX is in the minipage (combined with data table), so only need show it for the HTML -->
`r if (knitr::is_latex_output()) '<!--'`
```{r ResultsPlot, fig.width=5, fig.height=4, out.width='55%', fig.align="center", fig.cap="An extreme example of confounding"}
par( mar = c(0.5, 0.5, 0.5, 0.5))
openplotmat()

pos <- array(NA, 
             dim = c(3, 2)) 
pos[1, ] <- c(0.25, 0.25) # Faecal wt
pos[2, ] <- c(0.75, 0.25) # Diet
pos[3, ] <- c(0.50, 0.75) # Age


straightarrow(from = pos[2,], 
              to = pos[1,], 
              lty = 1, 
              lwd = 2,
              lcol = "grey")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 3,
     labels = "Apparent")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 1,
     labels = "link")

textrect( pos[1,], 
          lab = "Faecel wt",
          radx = 0.15,
          rady = 0.075,
          shadow.size = 0,
          lcol = ResponseColour,
          box.col = ResponseColour)
textrect( pos[2,], 
          lab = "Diet", 
          radx = 0.15,
          rady = 0.075,
          shadow.size = 0,
          lcol = ExplanatoryColour,
          box.col = ExplanatoryColour)
textrect( pos[3,], 
          box.col = "white",
          lcol = grey(0.75),
          shadow.size = 0,
          radx = 0.20,
          rady = 0.075,
          col = grey(0.3),
          lab = "Age")
```

`r if (knitr::is_latex_output()) '-->'`


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*The groups being compared should be as similar as possible*, apart from the difference being studied (in the *Himalaya 292* study, the diet).
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-andrea-piacquadio-3768131.jpg" width="200px"/>
</div>




Confounding can be managed in different ways:

* **Restricting** the study to a certain group, by keeping some variables approximately constant.
  These variables are called *control variables*.
  If possible, a reason for this restriction should be given.
* **Blocking**.
  The data can be analysed separately for different groups.
  

::: {.definition #Blocking name="Blocking"}
*Blocking* is when units of analysis are arranged in separate groups of similar units (called *blocks*) , then those groups are studied separately.
:::


* **Analysing** using special methods, after recording the values of potential confounding variables.
  Because of this, *recording all potential extraneous variables* is important.
  Most studies involving people record the participants' age and sex, as these two variables are common confounders.
  Once a sample is obtained, recording this extra information usually requires little extra effort.
* **Randomly allocating** people to the comparison groups.
  Random allocation should ensure that potential confounding variables are approximately evenly spread between the comparision groups. 
  This is true for potential confounders that have been identified (such as age), and also for variables that may *not* have even been considered as confounders, or are hard to measure or observe (such as genetic conditions).

::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Record* all the extraneous variables likely to be important for understanding the data.
This may include information about the *individuals* in the study, and the *circumstances* of the individuals in the study.
:::


Multiple approaches can be used, such as randomly allocating individuals to groups, *and* recording other variables that can be managed through analysis (Example\ \@ref(exm:GinkoGroups)).

The first two approaches (*restricting*; *blocking*) are useful if one or two variables are known, or thought likely, to cause confounding.
The third approach (*analysing*) requires recording all the variables suspected of being confounders.
The fourth approach (*randomly allocating*) is superior if possible, because it reduces the chance of confounding for variables not even suspected as being confounding variables.

Common to many of these methods is to ensure that any potential confounding variables are recorded (Sect.\ \@ref(RecordExtraneous)), to ensure no *lurking variables* exist that may compromise the results.
  
  
  
::: {.example #HimalayaConfounding name="Managing confounding in the Himalaya study"}
For the *Himalaya* study, different methods can be used to manage confounding due to age.

The study could be *restricted* to study people under 30.
Alternatively, *blocking* could be used to study people under 30, and 30 and over (Fig.\ \@ref(fig:BlockingHimalaya)).

Information about the individuals could be *recorded*, such as age.
Information about the circumstances of the individuals could also be *recorded*, such as the suburb where they live.
Then, special methods of analysis could be used to analyse the data.
In the *Himalaya 292* study, the sex, age, pre-study weight and pre-study BMI were recorded for each individual, and used in the subsequent analysis.

*Randomly allocating* participants into two groups would produce groups with an approximately even spread of ages.
Other potential confounding variables would be evenly spread between the two groups also.
In the *Himalaya* study, the units of analysis (the people) could be randomly allocated to a group, and then the groups randomly  allocated a diet by a toss of a coin (Fig.\ \@ref(fig:RandomAllocationHimalaya)).

In the *Himalaya 292* study, the article reports that 'Subjects were allocated randomly to [...] dietary treatments...' (@data:Bird2008:wholegrain, p. 1033).
:::



::: {.example #GinkoGroups name="Comparing groups"}
An experiment to study the effect of using ginko to enhance memory [@data:Solomon2002:Ginko] compared two groups: one using ginko ($n = 111$), and one using a fake, non-active supplement ($n = 108$).
The authors randomly allocated participants to each group, then compared the two groups to ensure that no obvious differences initially existed between the groups that might explain  differences in the response variable (Table\ \@ref(tab:GinkoDemographics)).

Two groups are similar in terms of age, education and gender distribution.
Any difference in outcome between the groups is probably due to the treatment.
:::


```{r GinkoDemographics}
Ginko <- array( dim = c(3, 3) )
colnames(Ginko) <- c("Characteristic", 
                     "Group A (Ginko)", 
		     "Group B (Fake)")

Ginko[1, ] <- c("Average age (in years)", 
                "68.7", 
		"69.9")
Ginko[2, ] <- c("Men (number; percentage)", 
                "46 (41%)", 
		"45 (42%)")
Ginko[3, ] <- c("Average years of education", 
                "14.4", 
		"14.0")

if( knitr::is_latex_output() ) {
  kable(Ginko,
        format = "latex",
        longtable = FALSE,
        booktabs = TRUE,
        #escape = FALSE, # For latex to work in \rightarrow
        linesep  =  c("", "", "", "\\addlinespace", "", "", ""), # Otherwise addes a space after five lines... 
        caption = "Comparing the two groups in the ginko-memory study",
        align = c("r", "c", "c"))   %>%
   kable_styling(full_width = FALSE, font_size = 10) %>%
   row_spec(0,bold = TRUE) # Columns headings in bold
}

if( knitr::is_html_output() ) {
  kable(Ginko,
        format = "html",
        align = c("r", "r", "r"),
        longtable = FALSE,
        caption = "Comparing the two groups in the ginko-memory study",
        booktabs = TRUE) 
}
```



:::{.exampleExtra  data-latex=""}
Researchers explored the use of dominant and non-dominant hands for chest compression in student paramedics using an experimental study [@cross2019impact].
Students were randomly divided into two groups: DHOS (dominant hand on chest) and NDHOC (non-dominant hand on chest).
The two groups were then compared:

| Demographic                  | All participants ($n = 75$) | DHOC ($n = 37$) | NDHOC ($n = 38$) 
| ----------------------------:+:---------------------------:+:---------------:+:----------------:
| Average age (years)          | 23.4                        | 22.5            | 24.3
| Gender: percentage Female    | 51%                         | 53%             | 47%

The two groups appear to be very similar in terms of average age of participants, and the percentage of female participants.
If differences are observed in the study between the DHOC and NDHOC groups, it is probably due to the treatment.
The study should have reasonable internal validity.
:::




(ref:BlockingHimalaya) Blocking in the *Himalaya* study, based on age

```{r  BlockingHimalaya, fig.cap="(ref:BlockingHimalaya)",  fig.align="center", fig.width=8, fig.height=5, out.width="80%"}
showStudyDesignBlocking(studyType = "TrueExp",   
                        addIndividuals = TRUE)
```





::: {.example #Manure name="Analysis to manage confounding"}
An experimental study [@schroder2015maize] compared nitrogen (N) and phosphorus (P) concentrations in maize, for evenly-injected liquid manure and band-injected liquid manure.
As potential confounding variables, the researchers also recorded the average temperature and the precipitation (between May 1 and September 30) at each site.
:::



```{r RandomAllocationHimalaya, echo=FALSE, fig.cap="Random allocation can occur in two places for the Himalaya study", fig.align="center", fig.height=3, out.width='65%'}

showStudyDesign(studyType = "TrueExp",   
                addIndividuals = TRUE,
                addByResearchers = FALSE,
                addImages = TRUE,   
                addRandomAllocationText = TRUE, 
                imageList = c("./Pics/iconmonstr-candy-5-240.png",
                              "./Pics/iconmonstr-candy-8-240.png"),
                addCNames = c("Himalaya 292",
                              "Refined"))
```

Individuals may be randomly allocated to groups (true experiment), and/or groups may be randomly allocated treatments (true or quasi-experiment).
Random allocation can be shown, in general, as in Fig.\ \@ref(fig:RandomAllocationGeneral).


```{r RandomAllocationGeneral, echo=FALSE, fig.cap="Random allocation in general, with more than two treatments and groups", fig.align="center", fig.height=3, out.width='65%'}
showStudyDesign(studyType = "TrueExp",   
                addIndividuals = TRUE,    
                addImages = FALSE,
                addByResearchers = FALSE,
                addGroupNames = c("Group 1", "Group 2", "Group 3"),
                addCNames = c("Treatment 1", "Treatment 2", "Treatment 3"),
                addRandomAllocationText = TRUE)
```
	

## Random allocation vs random sampling {#Random-sampling-allocation}

Random *sampling* and random *allocation* are different concepts (Fig.\ \@ref(fig:RandomAllocationSampling)), that serve different purposes, but are often confused:

* *Random sampling* impacts *external* validity, and concerns *finding the individuals* to study.
* *Random allocation* helps eliminate confounding issues, by distributing possible confounders across treatment groups.
  *Random allocation* impacts *internal* validity, and concerns *allocating treatments to individuals*.



```{r RandomAllocationSampling, echo=FALSE, fig.cap="Comparing random allocation and random sampling", fig.align="center", fig.height=3, out.width='75%'}

showStudyDesign(studyType = "TrueExp", 
                addIndividuals = TRUE, 
                addCompareText = FALSE, 
                addResearcherControl = FALSE,
                addInternalValidityText = TRUE,
                addByResearchers = FALSE,
                addRandomAllocationText = TRUE, 
                addRandomSamplingText = TRUE, 
                addExternalValidityText = TRUE, 
                addSampling = TRUE)
```


<iframe src="https://learningapps.org/watch?v=poh7e35e222" style="border:0px;width:100%;height:500px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>
 
 



## Hawthorne effect and blinding individuals {#HawthorneEffectExperimental}

Suppose patients in the *Himalaya 292* study were being watched (or waited for) while defecating.
Could this lead to a misleading conclusion?

People, and perhaps animals, may behave differently if they know (or think) they are being watched, which could compromise the [internal validity](#def:InternalValidity) of the study.
This is called the *Hawthorne effect*.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-binoculars-8-240.png" width="50px"/>
</div>


::: {.definition #HawthorneEffect name="Hawthorne effect"}
The Hawthorne effect is the tendency of individuals to change their behaviour if they know (or think) they are being observed.
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


::: {.example #HawthorneFruitVege name="Hawthorne effect"}
People are more health-conscious if they know they will be examined regularly.
For example, a study aiming to increase fruit and vegetable intake in young adults [@clark2019educational] noted that the changes recorded "could be explained by the Hawthorne effect", since being in the study can "cause participants to change behavior because they know they are being observed..." [@clark2019educational].
:::


The impact of the Hawthorne effect can be minimized by [blinding](#Blinding) the individuals in the experiment, so that the they do not know:

* that they are in a study;
* the aims of the study; and/or 
* which treatment they are receiving in the study. 

Blinding *people* to knowing they are involved in a study is often difficult, as ethics often requires peoples' informed consent.


::: {.example #HawthorneHimalaya name="Hawthorne effect"}
The *Himalaya 292* article reports that (p. 1033):

> The study was explained fully to the subjects, both verbally and in writing, and each gave their written, informed consent... 

That is, the subjects knew they were in a study, and knew the aims of the study, so the Hawthorne effect may influence the results in this study.
However, the subjects did not know *which* diet they were on (@data:Bird2008:wholegrain, p. 1033).
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-photomix-company-216729.jpg" width="200px"/>
</div>


::: {.example #HawthorneTeeth name="Hawthorne effect"}
In a study [@lorenz2019effect] to compare the efficacy of a new type of toothpaste, participants were given either a new or an existing toothpaste formulation, and evaluations of plaque remaining on the teeth were taken.
*Both* groups recorded a reduced amount of plaque.

The reason was the Hawthorne effect: since all participants knew they were being assessed after brushing, they brushed better than usual.
:::


## Observer effect and blinding researchers {#ObserverEffectExperimental}

Suppose the *researchers* assessing the study outcomes *knew the diet* allocated to each patient.
Could this lead to a misleading conclusion?

Perhaps surprisingly, researchers' expectations or hopes for how the new diet will perform may unconsciously influence how the researchers interact with the individuals, and perhaps (unconsciously) influence the behaviour of the individuals in the study.
This is called *observer effect*.
(In experiments, it is sometimes called the *experimenter effect*.)
This could compromise the [internally validity](#def:InternalValidity) of the study.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-idea-10-240.png" width="50px"/>
</div>


::: {.definition #ObserverEffect name="Observer effect"}
The observer effect occurs when the researchers unconsciously change their behaviour to conform to expectations because they know what values of the explanatory variable apply to the individuals.
This may cause the *individuals* to change their behaviour or reporting also.
:::


The impact of the observer effect can be minimized by blinding the researchers, so that they do not know which treatments the individuals are receiving.
The researchers *giving* the treatment and the researchers *evaluating* the treatment can both be blinded, by using a third party.
For example, the researchers may give an assistant two drugs, labelled A and B.
The assistant administers the drug and evaluates the participants' response to the treatments.
Later, the assistant tells the researchers whether Drug A or Drug B performed better, but only the researchers know which drugs the labels A and B refer to (Fig.\ \@ref(fig:BlindingThirdParty)).


```{r, BlindingThirdParty, echo=FALSE, fig.align="center", fig.cap="Using a third party to avoid the observer effect", fig.height=3, fig.width=8, out.width='85%'}
showStudyDesign(studyType = "TrueExp", 
                addIndividuals = TRUE, 
                addThirdParty = TRUE)    
```



::: {.example #ObsEffectyPain name="Observer effect"}
In a study [@seo2020role] that examined the impact of an injection to alleviate post-operative umbilical pain, the authors stated (p. 392):

> ...the postoperative pain scores were gathered by a nurse practitioner who was blinded to the usage of bupivacaine to avoid observer-expectancy bias [i.e., the observer effect].
:::


The observer effect does not just apply to situations with *people* as individuals.


::: {.example #CleverHans name="Observer effect"}
`r if (knitr::is_latex_output()) {
   'Clever Hans'
} else {
   "['Clever Hans'](https://en.wikipedia.org/wiki/Clever_Hans)"
}`
was a horse that seemed to perform simple mental arithmetic.
Carl Stumpf realised that the horse was responding to involuntary (and unconscious) cues from the trainer, by using an experiment where the people interacting with the horse were blinded.

The same effect has been observed in narcotic sniffer dogs [@bambauer2012defending], who may respond to their handlers' unconscious cues.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The *observer effect* is when the researcher *unconsciously* influences the individuals, and are not aware it is occurring.
*Intentionally* influencing the individuals is called [fraud](#Fraud).
:::


<iframe src="https://learningapps.org/watch?v=puedghp1c22" style="border:0px;width:100%;height:500px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>


## Placebo effect and blinding {#PlaceboEffectExperimental}

To know whether the *Himalaya* diet changed faecal weight, the researchers compared the outcome to people on a refined-cereal diet.
The people on the refined-cereal diet acted as the *control group* (Sect.\ \@ref(Comparison)).
The refined cereal acted as a benchmark; like a *placebo*.

Perhaps surprisingly, individuals in a study may report effects of a treatment, even if they have not received an active treatment.
This could compromise the [internally validity](#def:InternalValidity) of the study.
This is called the *placebo effect*, which generally only impacts people as individuals.


::: {.example #PlaceboColours name="Placebo effect"}
Three active pain relievers were compared to different-coloured placebo [@data:Huskisson1974:placebo] in 22 patients.
The most pain relief was experienced by those taking *red* placebos (Fig.\ \@ref(fig:Placebos)), who experienced even more pain relief than those given true pain relievers.
:::


```{r Placebos, echo=FALSE, fig.align="center", out.width='65%', fig.width=5.75, fig.height=4, fig.cap="Pain relief, for various pain relief medicine and placebos"}
data(Placebos)

par( xpd = TRUE,   # Allows plotting outside plot area
     mar = c(4, 4, 4, 4) + 0.1 )  # DEFAULT: c(5, 4, 4, 2) + 0.1
	 
plot( c(0, 2.75) ~ range(Time), 
      data = Placebos,
      las = 1, 
      type = "n", 
      axes = FALSE,
      main = "Mean pain relief for various medications",
      xlab = "Time (hours)", 
      ylab = "Pain relief score")
axis(side = 1)
axis(side = 2,
     las = 1,
     at = seq(0, 2, by = 0.5))
box()

# abline seems to go outside margins...? Because of xpd?
lines( x = c(0, 6),
       y = c(1, 1), 
       lty = 2,
       col = "grey")
lines( x = c(0, 6),
       y = c(2, 2), 
       lty = 2,
       col = "grey")
mtext(" Moderate\n relief",
      side = 4,
      at = c(5.75, 2),
      las = 1,
      adj = 0,
      cex = 0.9)
mtext(" Slight\n relief",
      side = 4,
      at = c(5.5, 1),
      las = 1,
      adj = 0,
      cex = 0.9)

lines( Asp ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       col = "black", 
       lty = 1,
       lwd = 2)

lines( Placebo ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       col = "orange", 
       lty = 2,
       lwd = 2)

lines( PlaceboRed ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       lty = 2,
	     col = "red", 
       lwd = 2)

legend("top", 
	col = c("red", 
	        "black", 
	        "orange"), 
	lwd = 2, 
	lty = c(3, 1, 2),
	bty = "n",
	ncol = 2,
	#horiz = TRUE,
	legend = c("Red placebos", 
	           "Aspirin", 
	           "All Placebos"))
# Add initial point at t = 0, as all lines start there and last plot overtakes the colour
points(x = 0,
       y = 0,
       pch = 21,
       bg = "white",
       col = "black")
```




<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-help-3-240.png" width="50px"/>
</div>


::: {.definition #PlaceboEffect name="Placebo effect"}
The placebo effect occurs when individuals report perceived or actual effects, despite not receiving an active treatment.
:::


To manage the placebo effect, researchers should record *objective* data (rather than patient-reported outcomes, as in Example\ \@ref(exm:PlaceboColours)) when possible [@enck2013placebo].
In addition, *blinding* the individuals and the researchers may help manage the placebo effect, as then the individuals cannot not know which group they are in.


::: {.example #HimalayaPlacebo name="Placebo effect"}
In the *Himalaya 292* study, the authors report that the individuals "were not told the identity of the test cereal in the foods provided" (@data:Bird2008:wholegrain, p. 1033).
The subjects were [blinded](#Blinding) to the diet they were exposed to.
However, some may *think* they are on the refined cereal or *Himalaya* diet, and respond accordingly (perhaps unconsciously).
The use of the refined cereal was acting as a control.
Researchers measured faecal weight, an objective outcome, to minimise the placebo effect.
:::


:::{.exampleExtra  data-latex=""}
A study of placebos [@data:Waber2008:Placebo] gave half the subjects a placebo, but told them the pill was an expensive (implying 'effective') pain killer (\$2.50 per tablet).
The other half were also given a placebo, but were told the pill was a discount (implying 'less effective') pain killer (\$0.10 per tablet).
About 85% of participants in the first group reported a pain reduction, yet only 61% in the second group reported a pain reduction.
Remember: *both* groups actually received a placebo!
Again, 'pain relief' is subjective.
:::


## Carry-over effect and washout periods {#CarryOverEffectExperimental}

In the *Himalaya* study, the diet is a *between-individuals* comparison: One group of patients is given the refined cereal diet (the control), and a different group of people was given *Himalaya 292*.
The study *also* used a *within-individuals* comparison: each person in the study was actually placed on both diets.
Suppose that all patients spent four weeks on the *Himalaya 292* diet, then the next four weeks on the refined cereal diet.

Potentially, the first diet could still be impacting the subjects' faecal weight for a little while after stopping the first diet.
This could compromise the [internally validity](#def:InternalValidity) of the study.
This is an example of the *carry-over effect*: when the influence of one treatment carries over into the influence of the next treatment.
The carry-over effect is only a concern for *within-individuals* comparisons.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-chart-21-240.png" width="50px"/>
</div>


::: {.definition #CarryoverEffect name="Carryover effect"}
The carry-over effect occurs when the influence of one treatment influences individuals' responses to subsequent treatments.
:::


The impact of the carry-over effect may be minimized by using a *washout* or similar between treatments.
For example, after tasting a food sample, participants may rinse their mouth with water before tasting another food sample.
For the *Himalaya* study, between using the special diets, the participants could spend two weeks on their usual (before-study) diet.
This is called a *washout period*.


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


::: {.example #HimalayaCarryOver name="Carry-over effect"}
In the *Himalaya 292* study, the authors report that 'there was no washout period' (@data:Bird2008:wholegrain, p. 1033) since the response variable was only recorded after individuals spent four weeks on each diets.
Since faecal weight was not measured until the *end* of this four weeks, the effect of the diet change would be minimal.
:::


::: {.example #HimalayaWashout name="Carry-over effect"}
An engineering study [@miller2019behavioral] examined drivers' exposure to lane-keeping systems on their driving performance.
Subjects were exposed to a driving simulation that used a lane-keeping system, and then to a driving simulation without using a lane-keeping system.
The researchers found that driving performance was impacted when drivers moved from a simulation *with* a lane-keeping system to one *without* a lane-keeping system.
:::


::: {.exampleExtra  data-latex=""}
In @jaskiewicz2020chest, student paramedics performed chest compression in real-life (RL), and also using virtual reality (VR).
A relaxation percentage of about 50% is ideal.

When used by itself, the VR method produced an average relaxation percentage of 45.5%.
However, when the RL method was used first, and then followed by the VR method, the average VR relaxation method percentage was 74.7%.

The response of the individuals was different depending on whether the RL method was used first.
This is an example of the carry-over effert.
:::


Sometimes, when relevant, researchers can *randomly allocate* the *order* in which the treatments (i.e., the diets) are used (a *cross-over study*).
That is, some participants start by spending four weeks on the *Himalaya 292* diet, then four weeks on the refined cereal diet; meanwhile, other participants start by spending four weeks on the refined cereal diet, then four weeks on the *Himalaya 292* diet.


::: {.example #HimalayaCarryOver2 name="Carry-over effect"}
In the *Himalaya 292* study, the authors report that "subjects were allocated randomly to [...] dietary treatments" (@data:Bird2008:wholegrain, p. 1033).
Subjects were randomly allocated to begin the study on the *Himalaya 292* diet, while others started on the refined cereal diet.
:::


::: {.example #ParamedOrder name="Washout periods"}
A study of paramedics [@data:MacDonald:Resuscitation] required paramedics to conduct eight different tasks (such as electrical defibrillation and intravenous cannulation).
The *order* in which each of the 16 paramedics performed the eight tasks was arranged so that not every paramedic started with Task 1, followed by Task 2, etc. to mitigate the carry-over effect.
A washout period between tasks was also used.
:::


## Describing blinding {#DescribingBlinding}

*Blinding* occurs when those involved in the study do not know information about the study.
The *individuals* in the study may be blinded to 

* being in a study;
* the aims of the study in which they are participants; and/or 
* which comparison groups or connection values apply to them.

The *researchers* and the *analysts* can be blinded to which comparison groups or connection values apply to the individuals. 

When as many participants as possible are blinded in as many ways as possible, the internal validity of the study is increased and bias reduced.
However, when people are the individuals, ethics requirements may mean that they need to know they are in a study (especially if the study is experimental), and the purpose of the study.

If *only* the participants are blinded to the comparison groups or connections that apply to them, the study is called *single blind*.
If *both* the researchers and participants are blinded to the comparison groups or connections that apply, the study is called *double blind*.
If the researchers, participants *and* the analyst are blinded to the comparison groups or connections that apply , the study is called *triple blind*.
Rather than using these terms, explicitly stating who or what is blinded is clearer.


::: {.thinkBox .think data-latex="{iconmonstr-light-bulb-2-240.png}"}
Why might it be necessary to blind the *analyst* to the treatments used?
:::


Blinding should be considered in all studies when possible (and it is *not* always possible).
*Blinding participants does not just apply to people*; it also may apply to animals (Example\ \@ref(exm:CleverHans)).


::: {.example #BlindingCowpea name="Double-blinding"}
In a cropping study comparing yields from modern and traditional cowpea crops in Tanzania [@bulte2014behavioral], the two seed types ('traditional' and 'modern') were made similar in appearance so the farmers were blinded.
The seed type would eventually become obvious as the crop grew, but "key inputs were already provided" by that stage (p. 817).
:::


::: {.example #BlindingParamedic  name="Blinding"}
In a study comparing chest compressions with dominant and non-dominant hands of student paramedics [@cross2019impact], the individuals "were blinded to the specific research question..." (@cross2019impact, p. 2).
However, participants could not be blinded to which group they were in (dominant hand on chest; non-dominant hand on chest).
In this case, participants were only *partially* blinded.
The article also reports that "Data were analysed by a biostatistician blinded to group allocation" (@cross2019impact, p. 3).
:::



## Recording extraneous variables {#RecordExtraneous}

One way to design a quality study is to record information about many extraneous variables.
Various reasons for doing this have been given:

* To compare the sample to the population, to determine if the sample is representative (external validity; Sect.\ \@ref(Representative-samples)).
* To explain some variation in the response variable, so that the relationship between the response and explanatory variable can be revealed (Sect.\ \@ref(ExtraneousVariables)).
* To manage confounding:
  * To avoid lurking variables (Sect.\ \@ref(ExtraneousVariables)).
  * To determine if the groups being compared are similar (Sect.\ \@ref(ExpManagingConfounding)).
  * To use the information in analysis (Sect.\ \@ref(ExpManagingConfoundingAnalysis)).


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Record the values of all extraneous variables that may be important in the study*!
:::


## Summary {#Chap7-Summary}

Designing effective *experimental* studies (Fig.\ \@ref(fig:DesignConsiderations)) requires researchers to *manage or minimise confounding* where possible, by:

* *restricting* the study to certain groups;
* *blocking* individuals into similar groups;
* through special *analysis* methods; and/or 
* through *random allocation* of the units of analysis.

Well-designed experimental studies also try to manage:

* the *Hawthorne effect* (e.g., by blinding participants);
* the *observer effect* (e.g., by blinding the researchers);
* the *placebo effect* (e.g., by blinding, and using objective outcomes); and
* the *carry-over effect* (e.g., by using a washout, or randomly allocating the treatment order).

This ensures that the results and conclusions from our studies are correctly interpreted.

`r if (knitr::is_html_output()){
  'The following short video may help explain some of these concepts:'
}`

<div style="text-align:center;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/eic_LjXT4qc" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture"></iframe>
</div>


Often, however, not all of these issues can always be managed (Table\ \@ref(tab:BiasesStudied)).
For instance, individuals often know they are involved in an experimental study, so the Hawthorne effect may impact conclusions.
In these cases, the possible impacts should be minimized as far as possible, and then the likely impact on the conclusions discussed.
The impact of these issues are often reported as *limitations* in a journal article (Chap.\ \@ref(Interpretation)), perhaps part of the Discussion section.



```{r BiasesStudied, echo=FALSE}
Biases <- array(NA, 
                dim = c(3, 3) )


if( knitr::is_latex_output() ) {
  Biases[1, ] <-  c("Hawthorne effect",
                    "\\textbf{Individuals} aware of being in a study, or aware of explanatory variable value",
                    "Behaviour of \\textbf{individuals} may change, or what individuals report may change")
  Biases[2, ] <-  c("Placebo effect",
                    "\\textbf{Individuals} \\emph{think} they are in a study, or \\emph{think} they have a specific value for explanatory variable",
                    "Behaviour of \\textbf{individuals} may change, or what individuals report may change")
  Biases[3, ] <-  c("Observer effect",
                    "\\textbf{Researcher} is aware of explanatory variable value",
                    "Behaviour of \\textbf{researcher} may change based on expectations, and perhaps (unconsciously) communicated to \\textbf{individuals}, who then may also act or report differently")
  
  
  knitr::kable(Biases,
               format = "latex",
               longtable = FALSE,
               booktabs = TRUE,
               escape = FALSE,
               linesep = "\\addlinespace",
               caption = "Different design biases studied in this book related to the researchers and the individuals",
               col.names = c("Name", 
                             "Who/what is aware of what", 
                             "What changes or is compromised")) %>%
    kable_styling(font_size = 10) %>%
    row_spec(0, bold = TRUE)%>%
    column_spec(column = 1, width = "18mm") %>%
    column_spec(column = 2, width = "55mm") %>%
    column_spec(column = 3, width = "55mm")
}
if( knitr::is_html_output() ) {
  Biases[1, ] <-  c("[Hawthorne effect](#HawthorneEffectExperimental)",
                    "**Individuals** are aware of being in a study, or aware of explanatory variable value",
                    "Behaviour of **individuals** may change, or what individuals report may change")
  Biases[2, ] <-  c("[Placebo effect](#PlaceboEffectExperimental)",
                    "**Individuals** think they are in a study, or think they have a specific value for explanatory variable",
                    "Behaviour of **individuals** may change, or what individuals report may change")
  Biases[3, ] <-  c("[Observer effect](#ObserverEffectExperimental)",
                    "**Researcher** is aware of explanatory variable value",
                    "Behaviour of **researcher** may change based on expectations, and perhaps (unconsciously) communicated to individuals, who then may also act or report differently")
  
  
  knitr::kable(Biases,
               format = "html",
               longtable = FALSE,
               booktabs = TRUE,
               caption = "Different design biases studied in this book related to the researchers and the individuals",
               col.names = c("Name", 
                             "Who/what is aware of what", 
                             "What changes or is compromised"))
}
```



(ref:DesignConsiderations-Caption) Design considerations. Note: Lurking variables become confounding variables when recorded in the study, and then they can be managed. The arrows indicate the main design solution to (perhaps partially) manage the indicated potential bias. Not all solutions are possible for every study.

```{r DesignConsiderations, echo=FALSE, fig.cap='(ref:DesignConsiderations-Caption)', out.width='75%', fig.align="center",  fig.width=7.00} 
# fig.height=6,
source("R/showDesignConsiderations.R")
showDesignConsiderations(studyType = "Experiment")
```




::: {.example #DesignExample name="Study design"}
In a study of student paramedics comparing chest compressions using dominant and non-dominant hands (@cross2019impact, p. 3):

> ...participants were allocated randomly to one of two groups: 'dominant hand on chest' or 'non-dominant hand on chest'. 
> Group allocation was determined by a computer-generated randomisation schedule...

The participants were blinded to the *purpose* of the study, but not to which group they were allocated.
The analyst was also blinded to the group allocations.
This study used a number of good design features.
:::






## Quick review questions {#Chap7-QuickReview}

::: {.webex-check .webex-box}
A study [@doosti2016development] wanted to determine the relationship between the surface temperature of the apple, and the depth of bruising.
The researchers purposefully hit apples with three different *forces* (200, 700 and 1200&nbsp;mJ) to inflict bruises.
The researchers then recorded the *depth* of the bruising, and recorded the *surface temperature* at each bruise location.

The study was conducted separately for three different *regions* of the apple (lower; middle; upper), and each apple was only used once.

1. The *response variable* is\tightlist
`r if( knitr::is_html_output() ) {longmcq( c(
	"The force used on the apples",
	answer = "The depth of the bruising",
	"The location of the bruising",
	"The surface temperature at the bruise site"))} else {"________________"}`
1. The *explanatory variable* is
`r if( knitr::is_html_output() ) {longmcq( c(
	"The force used on the apples",
	"The depth of the bruising",
	"The location of the bruising",
	answer = "The surface temperature at the bruise site"))} else {"________________"}`
1. What is the *best* description for the variable 'The location of the bruising'?  
`r if( knitr::is_html_output() ) {longmcq( c(
	"A confounding variable, since it may be related to the explanatory variable only",
	"A confounding variable, since it may be related to the response variable and explanatory variables",
	answer = "An extraneous variable, because it is likely to be related to the response variable only",
	"A lurking variable, since we don't know how it might be related to the response and explanatory variables"))}`
1. True or false: The researchers could minimise the effects of confounding by incorporating potential confounding variables in the analysis.  
`r if( knitr::is_html_output() ) {torf( TRUE)}`
1. True or false: The researchers could use random allocation of the treatments to the apples to minimise confounding.  
`r if( knitr::is_html_output() ) {torf( TRUE)}`
1. True or false: The *carry-over* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. True or false: The *Hawthorne* effect is likely to be a big problem in this study. 
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. True or false: The *placebo* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. True or false: *Observer* bias is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE )}`
:::



## Exercises {#DesigningExperimentsExercises}

Selected answers are available in Sect.\ \@ref(DesigningExperimentsAnswer).



::: {.exercise #DesignExpTrueFalse}
Are the following statements true or false?

1. Experimental studies **must** use random samples.\tightlist  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
2. An experimental study **must** blind the researchers.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
3. An experimental study **must** blind the participants.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
4. Experimental studies **must** use a control group.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
5. In experimental studies, the treatments **must** be allocated by the researchers.  
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
:::


::: {.exercise #DesignExpExtraneous}
Extraneous variables are variables that are related to the response variable.  
Which of the following types of variables are special types of extraneous variables?

1. Lurking variables.\tightlist
`r if( knitr::is_html_output() ) {mcq( c(answer = "Extraneous", "Not extraneous") )}` 
2. Explanatory variables.
`r if( knitr::is_html_output() ) {mcq( c("Extraneous", answer = "Not extraneous") )}` 
3. Confounding variables.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Extraneous", "Not extraneous") )}` 
:::


::: {.exercise #DesignExpWeightLoss}
Consider a study comparing the average weight loss for patients who do at least 30 minutes of exercise a day (Group A), to patients who do less than 30 minutes of exercise a day (Group B).
Which of the following statements are true?

1. The extraneous variable is the amount of exercise per day (in hours).\tightlist
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
2. The response variable is the weight loss for each person.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
3. The explanatory variable is whether or not the patient performs at least 30 minutes of exercise per day.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
4. The response variable is the **average** weight loss.
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
5. The explanatory variable is the amount of exercise the patient does per day (in hours).
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
6. Age is likely to be a lurking variable.
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
7. Age is an extraneous variable.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
8. Age is likely to be a confounding variable.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}`
9. Which of the following are possible **confounding** variables?
  * The sex of the patients.\tightlist
  `r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
  * The initial weight of the patients.
  `r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
  * The names of the patients.
  `r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
:::


::: {.exercise #DesignExpParamedicsPills}
Paramedics were involved in a study to compare two new pills (Treatment A, and Treatment B) to treat Post Traumatic Stress Disorder (PTSD).  

1. What would be the control group?\tightlist
`r if( knitr::is_html_output() ) {
   longmcq( c("The group receiving Treatment A",
              "A group of paramedics who do not have PTSD",
              "The group receiving Treatment B",
              "A group of paramedics not involved in the study",
              "A group of people with PTSD who are not paramedics",
              answer = "A group receiving a pill that looks just like Treatment A and B, but has no effective ingredient"))}`

2. The patients did not know which treatment they received.
What is this called?
`r if( knitr::is_html_output() ) {
   longmcq( c("Blinding the researchers",
              "Double blinding",
              "Managing confounding",
              answer = "Blinding the participants"))}`

3. What is the purpose of blinding the participants?
`r if( knitr::is_html_output() ) {
   longmcq( c("To ensure that researchers did not unintentionally influence the results",
              answer = "To ensure that participants did not change their behaviour because of the treatment they were receiving",
              "To manage confounding"))}`
:::


::: {.exercise #DesignExpFillBlanks}
In experiments, confounding can be managed by restricting the study group, blocking, 
`r if( knitr::is_html_output() ) {mcq( c("sampling", answer = "random allocation"))} else {"________________"}`, or special methods of 
`r if( knitr::is_html_output() ) {mcq( c(answer = "analysis", "sampling"))} else {"________________"}`.

The Carry-over Effect can be managed by using a
`r if( knitr::is_html_output() ) {mcq( c(answer = "washout", "control group"))} else {"________________"}`.

The Placebo Effect can be managed by using a
`r if( knitr::is_html_output() ) {mcq( c("washout", answer = "control group"))} else {"________________"}`.

The Observer Effect can be managed by blinding the
`r if( knitr::is_html_output() ) {mcq( c("participants", answer = "researchers"))} else {"________________"}`

The Hawthorne effect can be managed by blinding the 
`r if( knitr::is_html_output() ) {mcq( c(answer = "participants", "researchers"))} else {"________________"}`.
:::


::: {.exercise #ResearchDesignFertilizer}
A scientist compares the effects of two types of fertiliser on the yield of tomatoes (based on @klanian2018integrated).
He plants tomato seedlings, and fertilises with Fertiliser I, and later records the yield of tomatoes.
He then immediately plants more tomato seedlings in the same field, fertilises with Fertilizer II, and measures the yield of tomatoes.

What potential problems can you identify with the study design?
:::


::: {.exercise #ResearchTasteOfWater2}
A scientist is expecting that tap water will taste the same as bottled water in a taste test (based on @teillet2010consumer).
The scientist provides people with a plastic cup of either bottled or tap water, and she asks them to give a rating of the taste on a scale of 1 (terrible) to 5 (fantastic).

What potential problems can you identify with the study design?
:::


::: {.exercise #ResearchDesignTasteOfWater3}
Consider this RQ (based on @teillet2010consumer):

> Among university students, is the taste of tap water different than the taste of bottled water?

This RQ needs some clarification, but you decide to answer this question using an *experiment*.
How would you manage:

1. Random allocation?
1. Blinding?
1. Double blinding?
1. Finding a control?
1. Finding a random sample?
:::


::: {.exercise #ResearchDesignSunscreen}
In a study of time spent applying sunscreen [@data:Heerfordt2018:sunscreen] the Aim was to 'determine whether time spent on sunscreen application is related to the amount of sunscreen used' (@data:Heerfordt2018:sunscreen, p. 117).
The study is described as follows (p. 118):

> The volunteers were asked to apply the provided sunscreen [...] the way they would normally do on a sunny day at the beach in Denmark [...]
> The volunteers wore swimwear during the whole session. 
> No other information was given. 
> Participants applied sunscreen behind a curtain and were not observed during application. 
> Measurements of time and sunscreen weight were made without the subjects' being aware of this.

1. What are the response and explanatory variables?
1. The researchers also recorded age, height, weight and body surface area of each participant. 
   Why would they have done this?
1. The researchers also compared the mean values of the response variable for males and females, 
   and the mean values of the explanatory variable for males and females. 
   Why would they have done this? 
1. What design features are being used in the second quote?
:::


<!-- https://bmcoralhealth.biomedcentral.com/articles/10.1186/s12903-018-0588-1  About tooth brushing -->


<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to in-chapter questions:**

- Sect. \ref{thinkBox:HimalayaPOCI}: 1. **P**: Australians. **O**: average faecal weight. **C**: between those eating food made using refined cereal and  *Himalaya 292*. An intervention (*provided* food). 2. Faecal weight; the type of grain consumed (refined or *Himalaya 292*). 3. True experiment.
- Sect. \ref{thinkBox:Control}: *Not* just people who don't get injections. 
Ideally, controls would be people who, like the treatment group, report to a GP and receive an injection... however, the injection is non-effective.

- \textbf{\textit{Quick Revision} questions:}
**1.** Surface temperature at the bruise.
**2.** Depth of the bruising.
**3.** Extraneous: likely to be related to the response variable only.
**4.** True.
**5.** True.
**6.** False.
**7.** False.
**8.** False.
**9.** False.
:::
`r if (knitr::is_html_output()) '-->'`
