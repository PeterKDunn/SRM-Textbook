# Sample sizes for CIs {#EstimatingSampleSize}


```{r, child = if (knitr::is_html_output()) {'introductions/26-Sample-Size-Estimation-HTML.Rmd'} else {'introductions/26-Sample-Size-Estimation-LaTeX.Rmd'}}
```


## Introduction {#SampleSizeIntroduction}

A [confidence interval](#AboutCIs) is an interval which gives a range of values of the population parameter that could plausibly have given rise to our observed value of the statistic.
All other things being equal, a *larger* sample size gives a *more precise* estimate of the population parameter.
After all, that's why we prefer larger samples: to get more [*precise*](#PrecisionAccuracy) estimates, and hence narrower CIs.
If that was not the case, we could take the smallest, cheapest and easiest possible sample of size one... which is clearly absurd.

For a given level of confidence, the width of a CI depends on the size of the sample.
All other things being equal, *larger* samples produce more [*precise*](#PrecisionAccuracy) estimates of the parameter (Sect.\ \@ref(PrecisionAccuracy)), and hence *narrower* CIs.


:::{.example #SampleSizeImpact name="Impact of sample size on CIs"}
Suppose we wish to estimate an unknown proportion, and find that $\hat{p} = 0.55$ using a sample of size $n = 25$.
The approximate $95$% CI is $0.55 \pm 0.199$ (and the *margin of error* is $0.199$)

If the estimate of $\hat{p} = 0.55$ was found from a sample of size $n = 100$, we should expect a more precise estimate.
The approximate $95$% CI is $0.55\pm 0.100$; the margin of error is $0.100$.

If the estimate of $\hat{p} = 0.55$ was found from a sample of size $n = 400$, the approximate $95$% CI is $0.55\pm 0.050$; the margin of error is $0.050$.
:::


```{r, child = if (knitr::is_html_output())  './children/SampleSizeCI/SampleSizeCI-HTML.Rmd'}
```

```{r, child = if (knitr::is_latex_output()) './children/SampleSizeCI/SampleSizeCI-LaTeX.Rmd'}
```

That is, improving precision gets more difficult as sample sizes get larger.
Large gains in precision are made by moderately increasing small sample sizes, but only small gains in precision are made by large increases in already-large sample sizes. 


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Remember that the sample size is the number of [*units of analysis*](#UnitsObsAnalysis).
:::



## General ideas {#SampleSizeIdeas}

If larger samples give more precise estimates, should we use the largest sample possible?
Not necessarily: using large samples also has disadvantages: 

* Studies with larger samples sizes take longer to complete.
* Studies with larger samples sizes cost more money.
* Ethics committees aim to keep sample sizes as small as possible, so that:
  - As little (potential) harm as possible is done to the environment.
  - As little (potential) harm as possible is done to as few animals as possible. 
  - As little (potential) harm as possible is done to as few people as possible. 
  - Resources, time and money are not wasted.


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/blueberries-801571_1920.jpeg" width="200px"/>
</div>


Determining the sample size to use is a trade-off between the advantages of increasing precision, and the challenges of cost, time, and remaining ethical. 


::: {.example #Biochar name="The cost of research"}
Consider a project studying the residual effect of organic biochar compound fertilizers (BCFs) *two years* after application [@farrar2021biochar].
This study requires planting turmeric in pots using soil previously treated with BCFs.

After the turmeric was grown, the concentration of potassium, phosphorus and nitrogen---as well as many trace minerals---was determined from the soil in *every* pot.
In addition, *every* turmeric plant was analysed for the number of shoots, the leaf mass fraction, and foliar nutrient information.

Clearly, every pot that is used comes with a substantial cost, both in terms of time and money.
:::


In this chapter, we learn how to compute the (approximate) minimum sample size needed to obtain a given precision for a confidence interval.
We only study estimating sample sizes for descriptive RQs:

* Estimating sample size for estimating a proportion: Sect.\ \@ref(SampleSizeProportions).
* Estimating sample size for estimating a mean: Sect.\ \@ref(SampleSizeOneMean).
* Estimating sample size for estimating a mean difference: Sect.\  \@ref(SampleSizeMeanDifferences).



<iframe src="https://learningapps.org/watch?v=pfduds6kt22" style="border:0px;width:100%;height:500px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>



## One proportion {#SampleSizeProportions}

In Sect.\ \@ref(Female-Coffee-Drinkers), a CI was formed for the *population* proportion of female college students in the United States that drink coffee daily.
From a sample of $n = 360$, the CI was $0.1694 \pm 0.0395$ (i.e., the *margin of error* is $0.0395$), or from $0.130$ to $0.209$.

To obtain a more precise estimate (i.e., a narrower CI), a larger sample is needed.
For instance, suppose we would like a CI with margin of error of $0.02$.
What size sample is needed?
Since we seek a *more* precise estimate, a *larger* sample is needed... but how much larger?


:::{.definition #SampleSizeProportion name="Sample size (proportion)"}
Conservatively, the size of the [*simple random sample*](#SRS) needed *for a $95$% CI for a proportion* with a specified margin-of error is *at least*  
\[
   \frac{1}{(\text{Margin of error})^2}.
\]
We say "conservatively", since the sample may be a little too large, but that's better than being too small.
:::

For the coffee-drinking problem above, then, a sample size of at least $\displaystyle 1\div (0.02^2) = 2\ 500$ female college students in the US is needed.
This is a substantial increase from the original sample size of $360$.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Always **round up** the result of the sample size calculation.
:::


::: {.example #SampleSizep name="Sample size calculations for one proportion"}
To estimate the population proportion of Australians that smoke, to within $0.07$ with $95$% confidence, a sample size of at least  
\[
  \frac{1}{(\text{Margin of error})^2} { = \frac{1}{0.07^2}}
\]
is needed; *at least* $n = 204.0816$ people.

In practice, *at least* $205$ people are needed to achieve this desired level of precision (that is, **always round up** in sample size calculations).
:::



`r if (knitr::is_html_output()){
  'The following short video may help explain some of these concepts:'
}`


<iframe width="560" height="315" src="https://www.youtube.com/embed/-fflEggczG4" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture"></iframe>


## One mean {#SampleSizeOneMean}

As with proportions, estimating a population *mean* is more *precise* with a larger sample.
All other things being equal, *larger* samples produce more [*precise*](#PrecisionAccuracy) estimates of the parameter (Sect.\ \@ref(PrecisionAccuracy)), and hence *narrower* CIs.
Again, large gains in precision are made by moderately increasing small sample sizes, but only small gains in precision are made by large increases in already-large sample sizes. 


<!-- ```{r SampleSizeCIWidthMean, fig.align="center", out.width = "65%", fig.cap='The approximate width of a $95$\\% CI for a mean, when various size samples are used. No values are given on the vertical axis, as the actual values depend on the value of the standard deviation, $s$', fig.height = 4.5} -->
<!-- ME <- function(n, s = 1){ -->
<!--   1.96 * 2 * s / sqrt( n ) -->
<!-- } -->
<!-- n <- seq(5, 50, by = 1) -->

<!-- par( mfrow = c(1, 1), -->
<!--      mar = c(4, 5, 5, 3), # LINES on each side of plot -->
<!--      oma = c(1, 1, 1, 1) ) # OUTER margins, between plots and edges of canvas -->


<!-- plot( x = c( min(n), max(n) ),  -->
<!--       y = c(-2, 2), -->
<!--       type = "n", -->
<!--       pch = 19, -->
<!--       las = 1, -->
<!--       axes = FALSE, -->
<!--       xlim = c(0, 50), -->
<!--       ylim <- c(-1.9, 1.9), -->
<!--       xlab = "Sample size", -->
<!--       ylab = "Estimates", -->
<!--       main = "The width of CI by sample size\n(for estimating a mean)") -->
<!-- axis(side = 1) -->
<!-- box() -->
<!-- abline(h = 0, -->
<!--        lwd = 1, -->
<!--        col = "grey") -->
<!-- lines(n, -->
<!--       0 + ME(n), -->
<!--       type = "b", -->
<!--       pch = 19, -->
<!--       cex = 0.75, -->
<!--       col = plot.colour, -->
<!--       lty = 1, -->
<!--       lwd = 2) -->
<!-- lines(n, -->
<!--       0.0 - ME(n), -->
<!--       type = "b", -->
<!--       pch = 19, -->
<!--       cex = 0.75, -->
<!--       col = plot.colour, -->
<!--       lty = 1, -->
<!--       lwd = 2) -->
<!-- text(10, -->
<!--      0.0, -->
<!--      srt = 90, -->
<!--      "Approximate width\nof 95% CI") -->

<!-- n.example <- 10 -->
<!-- arrows(n.example, -->
<!--        0.0 + ME(n.example), -->
<!--        n.example, -->
<!--        0.0 - ME(n.example), -->
<!--        length = 0.1, -->
<!--        angle = 15, -->
<!--        lwd = 2, -->
<!--        code = 3, # Draw arrowhead at both ends -->
<!--        col = "black") -->
<!-- mtext(expression(" "*Mean*","~bar(italic(x))), -->
<!--       side = 4, -->
<!--       las = 1) -->
<!-- ``` -->



:::{.definition #SampleSizeMean name="Sample size (mean)"}
Conservatively, the size of the [*simple random sample*](#SRS) needed *for a $95$% CI for the mean* with a specified margin-of error is *at least*  
\[
   \left( \frac{2 \times s}{\text{Margin of error}}\right)^2
\]
where $s$ is an estimate of the standard deviation in the population.
We say "conservatively", since the sample may be a little too large, but that's better than being too small.
:::



The formula requires a value for the sample standard deviation, $s$.
But if we don't have a sample yet... how can we have a value for the *sample* standard deviation?
Sometimes, an approximate value for $s$ comes from:

* The results of a [pilot study](#protocols), where the computed value of $s$ is used.
* The results of a similar study, where the value $s$ there can be used (see Example\ \@ref(exm:SampleSizePeanuts)).


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Always **round up** the results of a sample size calculation.
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/tom-hermans-ZPfd3ZobOc0-unsplash.jpg" width="200px"/>
</div>


::: {.example #SampleSizePeanuts name="Sample size estimation for one mean"}
Sect.\ \@ref(Cadmium-In-Peanuts) discusses a study about the mean cadmium concentrations in peanuts in the United States, where $s = 0.0460$\ ppm.

Suppose we wanted to estimate the mean cadmium concentration in *Australian* peanuts, to give-or-take $0.005$\ ppm with $95$% confidence.
We could use this value for $s$ as a starting point, and then compute:  
\[
   \left( \frac{2 \times 0.0460}{0.005}\right)^2 = 338.56;
\] 
we would need at least $339$ peanuts.
:::



## Mean differences {#SampleSizeMeanDifferences}

The ideas in the previous section also work for computing sample sizes for estimating *mean differences*, since the differences can be treated like a single sample.


:::{.definition #SampleSizeMeanDiff name="Sample size (mean)"}
Conservatively, the size of the [*simple random sample*](#SRS) needed *for a $95$% CI for the mean difference* with a specified margin-of error is *at least*  
\[
   \left( \frac{2 \times s_d}{\text{Margin of error}}\right)^2.
\]
where $s_d$ is an estimate of the standard deviation in the population.
We say "conservatively", since the sample may be a little too large, but that's better than being too small.
:::



```{r}
data(Diabetes)

Diabetes$Diff <- Diabetes$SBPfirst - Diabetes$SBPsecond

n.D.diff <- length( Diabetes$Diff ) - sum( is.na(Diabetes$Diff) )
se.D.diff <- sd(Diabetes$Diff, na.rm = TRUE) / sqrt(n.D.diff)


ci.lo <- mean(Diabetes$Diff) - 2 * se.D.diff
ci.hi <-  mean(Diabetes$Diff) + 2 * se.D.diff
```


::: {.example #SampleSizeWeightGain name="Sample size estimation for mean differences"}
In Sect.\ \@ref(MeanDiffCI), a CI is computed for the mean weight gain by Cornell University students from Week\ 1 to Week\ 12. 
The CI is $0.862\pm 0.232$\ kg, where the margin of error is $0.232$\ kg.

Suppose we wanted to estimate the mean weight change at a different university; we could use the value of $s$ from this study as a starting point (i.e., $s = 0.956$).
Also, suppose we wanted a more precise estimate, to give-or-take $0.15$\ kg.
For a *more precise* estimate, we would need a *larger sample*.
So we compute:  
\[
   \left( \frac{2 \times 0.965}{0.15}\right)^2 = 162.4775;
\] 
we would need at least $163$ students after rounding up (which is indeed larger than the $68$ students used at Cornell university).
:::



## Other issues related to sample size {#SampleSizeOtherIssues}

The above calculations form just one part of the information needed to make the final decision about the necessary sample size.
For example, the *cost* (time and money) of taking sample of this size has not been considered.

The calculations in this chapter assume a [*simple random sample*](#SRS) will be used, which is often unreasonable.
Other, more complex, formulas are available for computing sample sizes for other random-sampling schemes (such as [stratified samples](#StratifiedSampling)).
However, 
the above calculations do give an *estimate* of the sample size that would be required.
In addition, the calculations in this chapter are only for producing $95$% confidence intervals. 

In practice, researchers often start with a slightly larger sample than required to allow for drop-outs (for example, plants die, or people withdraw from the study).


## Example: emergency residential aged care

A study examined residential aged care residents in Australia needing emergency care [@dwyer2021residential] and recorded, among other information, the average age of such residents ($\bar{x} = 85$; $s = 7.3$) and the proportion of calls related to falls ($\hat{p} = 0.156$).

Suppose a similar study was to be conducted in New Zealand.
The aim was to estimate the mean age of residents to with $2$ years of age, and the proportion of incidents related to falls to within $0.10$.

The sample size required to meet the age requirement is at least  
\[
  n = \left(\frac{2\times s}{\text{Margin of error}}\right)^2 = \left(\frac{2\times 7.3}{2}\right)^2 = 53.29,
\]
or at least $54$ residents (rounding up!).
The sample size required to meet the falls requirement is at least  
\[
  n = \frac{1}{(\text{Margin of error}^2)} = \frac{1}{0.1^2} = 100.
\]
Since the same subjects will be required for both estimates, the study should use at least $100$ residents.


## Chapter summary

## Quick review questions {#Chap26-QuickReview}

::: {.webex-check .webex-box}
1. True or false: A *larger* sample size produces a *more* precise estimate of the parameter, all other things being equal. \tightlist  
`r if( knitr::is_html_output() ) {torf(answer = TRUE )}`
1. True or false: A *larger* sample size produces a *more random* sample.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE )}`
1. True or false: We should always take the *largest* possible sample size.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE )}`
:::


`r if (!knitr::is_html_output()) '<!--'`
`r webexercises::hide()`
1. **TRUE**. The reason why larger sample are "better" is that they estimate the unknown population parameter with greater precision.
1. **FALSE**. The *size* of the sample, and *how* the sample was obtained, are two different issues.
1. **FALSE**. We also need to consider the cost (in terms of size and time) and ethical issues also.
`r webexercises::unhide()`
`r if (!knitr::is_html_output()) '-->'`



## Exercises {#EstimatingSampleSizeExercises}


Selected answers are available in Sect.\ \@ref(EstimatingSampleSizeAnswer).


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Always **round up** the result of the sample size calculation.
:::


::: {.exercise #SampleSizeProp1}
Suppose we need to estimate a population *proportion* (with $95$% confidence).

1. What size sample is needed to estimate the population proportion within $0.04$?
1. What size sample is needed to estimate the population proportion within $0.02$ (that is, the confidence interval will be *half* as wide as in the first calculation)?
1. What size sample is needed to estimate the population proportion within $0.01$ (that is, the confidence interval will be *a quarter* as wide as in the first calculation)?
1. To get an estimate *half* as wide, how many *times* more units of analysis are needed?
1. To get an estimate *a quarter* as wide, how many *times* more units of analysis are needed?
:::


::: {.exercise #SampleSizePropEating}
Sect.\ \@ref(exr:CIOneProportionSnacking) discusses a study of the eating habits of university students in Canada [@data:Mann12017:UniStudents].
In that study, they estimated the proportion of Canadian students that ate a sufficient number of servings of grains each day.

Suppose we wished to repeat the study but for *New Zealand* university students; that is, we seek an estimate of the population proportion of New Zealand students that eat a sufficient number of servings of grains each day (with $95$% confidence).

1. What size sample would be needed if we wished to estimate the proportion to give-or-take $0.01$? 
2. What size sample would be needed if we wished to estimate the proportion to give-or-take $0.02$? 
3. What size sample would be needed if we wished to estimate the proportion to give-or-take $0.10$?
4. Do you think this study would be costly, in terms of time and money?
:::


::: {.exercise #SampleSizeMeanLungCapacity}
In Exercise \@ref(exr:CIOneMeanLungCapacityInChildren), a study by @data:Tager:FEV was discussed that measured the lung capacity of 11-year-old girls in East Boston (using the *forced expiratory volume* (FEV) of the children).
Suppose we wished to repeat the study, and find a $95$% confidence interval for the mean FEV for 11-year-old *Australian* girls.

Since Australian and American children might be somewhat similar, we could use (as a first approximation) the standard deviation from that study: $s = 0.43$ litres.

1. What size sample would be needed if we wished to estimate the mean to give-or-take $0.02$ litres? 
2. What size sample would be needed if we wished to estimate the mean to give-or-take $0.05$ litres? 
3. What size sample would be needed if we wished to estimate the mean to give-or-take $0.10$ litres?
4. Suppose we wished to find $99$% (not $95$%) confidence interval for the mean FEV for 11-year-old *Australian* girls, to give-or-take $0.10$ litres.
   Would this sample size be *larger* or *smaller* than the sample size found for a $95$% confidence interval (also with give-or-take $0.10$ litres)?
5. Do you think this study would be costly, in terms of time and money?
:::


::: {.exercise #CIOneMeanBloodLossSampleSize}
A study of paramedics [@data:Williams2007:BloodLoss] asked participants ($n = 199$) to estimate the amount of blood loss on four different surfaces.
When the actual amount of blood spill on concrete was $1000$\ ml, the mean guess was $846.4$\ ml (with a standard deviation of $651.1$\ ml).

1. How many paramedics would be needed if the mean guess was to be estimated with an precision of give-or-take $50$\ ml?
1. How many paramedics would be needed if the mean guess was to be estimated with an precision of give-or-take $25$\ ml?
1. How many times greater does the sample size need to be to *halve* the width of the margin of error?
:::



::: {.exercise #CIOneProportionAustSmokers}
We wish to estimate the population proportion of Australians that smoke.

1. Suppose we wish our $95$% CI to be give-or-take $0.05$. How many Australians would we need to survey?
1. Suppose we wish our $95$% CI to be give-or-take $0.025$; that is, we wish to *halve* the width of the interval above. 
   How many Australians would we need to survey? 
1. How many *times* as many Australians are needed to *halve* the width of the interval?
:::






<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
\textbf{Answers to \textit{Quick Revision} questions:}
**1.** True.
**2.** False.
**3.** False.
:::
`r if (knitr::is_html_output()) '-->'`


