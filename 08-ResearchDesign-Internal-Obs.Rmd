# Internal validity in observational studies {#DesignObservational}
\index{Internal validity!observational studies}\index{Research design!observational|(}


<!-- Introductions; easier to separate by format -->

```{r, child = if (knitr::is_html_output()) {'./introductions/08-ResearchDesign-Internal-Obs-HTML.Rmd'} else {'./introductions/08-ResearchDesign-Internal-Obs-LaTeX.Rmd'}}
```


## Introduction {#Chap8-Intro}

In experimental studies, many aspects of the research design typically can be controlled by the researcher.
In contrast, *observational studies* have fewer design features that can be controlled by the researchers.
For example, random allocation of treatments is impossible since treatments are not imposed in observational studies, and hence *confounding* is a potential threat to internal validity in observational studies.

A well-designed study is needed to draw solid conclusions (Def.\ \@ref(def:StudyDesign)): a study with high *internal validity* (Sect.\ \@ref(def:InternalValidity)) and high *external validity* (Sect.\ \@ref(def:ExternalValidity))).

Specific design strategies for maximising internally validity are:

* Managing confounding (Sect.\ \@ref(ObsManagingConfounding)).
* Managing the Hawthorne effect by blinding individuals (Sect.\ \@ref(HawthorneEffectObservational)).
* Managing the observer effect by blinding researchers (Sect.\ \@ref(ObserverEffectObservational)).
* Managing the carry-over effect by using washouts (Sect.\ \@ref(CarryOverEffectObservational)).

Since the placebo effect is concerned with individuals response to allocated *treatments*, it is not directly relevant to observational studies.
Not all of these strategies are relevant to every study.


<!-- ::: {.example name="Low internal validity"} -->
<!-- Researchers [@clausen2017effect] taught integrated pest management (IPM) to Ugandan small-scale farmers, used their neighbours as controls. -->
<!-- However, the IPM farmers were "different from the control farmers according to some demographic and agricultural characteristics". -->

<!-- Despite low internal validity, the study still showed some promising signs of teaching IPM to be explored in future studies. -->
<!-- ::: -->


## Managing confounding {#ObsManagingConfounding}
\index{Internal validity!observational studies!managing confounding}

In Sect.\ \@ref(ExpManagingConfounding), methods were listed for managing confounding in experimental studies.
Confounding can be managed for observational studies too:\index{Variables!confounding}

* *Restricting* the study to a certain group.
  For example, @doll1954mortality studied smoking in males aged under $35$ years since, at the time of the study, 'lung cancer [was] relatively uncommon in women and rare in men under $35$' (p.\ 1452).\index{Confounding!observational studies!control variables}
  The reason for the restriction should be justified if possible (as in this quotation).
* *Blocking*.
  Individuals that are similar to one another can be placed into different groups. 
  @doll1954mortality, for example, could have found numerous pairs of smokers and non-smokers, with both subjects in each pair *matched* by having similar ages and alcohol-consumption habits.\index{Confounding!observational studies!blocking}
* *Analysing* using special methods, after recording the values of potential confounding variables. 
  Most studies involving people record the participants' age and sex, as these two variables are common confounders.\index{Confounding!analysis}
  Once a sample is obtained, recording this extra information usually requires little extra effort.

*Randomly allocating* individuals to groups is *not possible* in observational studies.\index{Confounding!observational studies!random allocation}
For this reason, confounding is often a major threat to internal validity in observational studies, as individuals who are in one comparison group may be different, in general, to those who are in another group.

Usually the best approach for observational studies is to record the values of any potential confounding variables, and use special analysis methods to understand the data.
The groups being compared should be as similar as possible, apart from what is being studied.
Hence, researchers often compare the comparison groups on potential confounding variables.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Record* all extraneous variables likely to be important for understanding the individuals
This may include information *about* the individuals in the study, and the *circumstances* of the individuals in the study.
:::


::: {.example #ConfoundingKiwi name="Confounding"}
@data:froud2018:kiwifruit studied $2599$ kiwifruit orchards, exploring the relationship between the time since a bacterial canker was first detected (in weeks), and the orchard productivity (in tray equivalents per hectare).
The researchers also recorded extraneous variables such as 'whether or not the farm was organic', 'elevation of the orchard' and 'whether or not general fungicides were used'.
These variables were used in their analysis to manage the potential effects of confounding.
:::


::: {.example #ActiveSedentaryWomen name="Comparing study groups"}
An observational study compared the iron levels of active and sedentary women aged\ $18$ to\ $35$ [@data:woolf:ironstatus].
The active ($n = 28$) and sedentary women ($n = 28$) were compared on a variety of characteristics (Table\ \@ref(tab:SedentaryDemographics)).
The active women were similar to the sedentary women on these characteristics, but were (in general) slightly younger, slightly heavier, and slightly more likely to use hormonal contraceptives.
:::


```{r SedentaryDemographics}
WomenIron <- array( dim = c(4, 3) )
colnames(WomenIron) <- c("Characteristic", "Active women", "Sedentary women")

WomenIron[1, ] <- c("Average age (in years)", 
                    "20", 
                    "24")
WomenIron[2, ] <- c("Average height (in cm)", 
                    "169", 
                    "166")
WomenIron[3, ] <- c("Average weight (in kg)", 
                    "68", 
                    "62")
WomenIron[4, ] <- c("Percentage using hormonal contraceptives", 
                    "13", 
                    "11")

  
if( knitr::is_latex_output() ) {
  kable( pad(WomenIron[ c(1, 3, 4), ],
             surroundMaths = TRUE,
             targetLength = 2,
             digits = 0),
        format = "latex",
        longtable = FALSE,
        booktabs = TRUE,
        escape = FALSE, # For latex to work in \rightarrow
        linesep = c("", "", "", "", "", ""), # Otherwise adds a space after five lines... 
        caption = "The demographic information for those in the study of iron levels in women",
        align = "c")   %>%
   kable_styling(full_width = FALSE, 
                 font_size = 8) %>%
  row_spec(0,bold=TRUE) # Columns headings in bold
}

if( knitr::is_html_output() ) {
  kable( pad(WomenIron[ c(1, 3, 4), ],
             surroundMaths = TRUE,
             targetLength = 2,
             digits = 0),
        format = "html",
        align = c("r", "c", "c"),
        longtable = FALSE,
      caption = "The demographic information for those in the study of iron levels in women",
      booktabs = TRUE)
}
```


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Observational studies *can* (and often do) have control groups (see Example\ \@ref(exm:ConfoundingSmoking54)).
Indeed, one specific type of observational study is called a\index{Case-control study} 
`r if (knitr::is_latex_output()) {
   '*case-control study*.'
} else {
   '[*case-control study*](https://en.wikipedia.org/wiki/Case%E2%80%93control_study).'
}`
However, individuals are *not allocated* to the control group by the researchers in observational studies, so the control and study groups may be very different, which may explain any differences in the outcome.
:::


:::{.exampleExtra data-latex=""}
A study [@data:Gunnarsson2017:helicopter] examined the difference between two types of helicopter transfer (physician-staffed; non-physician-staffed) of patients with a specific type of myocardial infarction (STEMI).
The purpose of the study was:

> ...to evaluate the characteristics and outcomes of physician-staffed HEMS (Physician-HEMS) versus non-physician-staffed (Standard-HEMS) in patients with STEMI.
>
> --- @data:Gunnarsson2017:helicopter, p.\ 1

The researchers 

> ...studied $398$ STEMI patients transferred by either Physician-HEMS ($n = 327$) or Standard-HEMS ($n = 71$) for [...] intervention at $2$\ hospitals between 2006 and 2014.
>
> --- @data:Gunnarsson2017:helicopter, p.\ 1

Since the study is an observational study (patients were not allocated by the researchers to the type of helicopter transport), the researchers recorded information about the patients being transported.
They compared the patients in both groups, and found (for example) that both groups had similar average ages, and similar percentages of females and smokers, and so on.
They also compared information about the transportation, and found (for example) that both groups had similar average flight times and flight distances.

One conclusion from the study was that 'Patients with STEMI transported by Standard-HEMS had longer transport times' (p.\ 1), but one limitation of the study was that:

> The patient cohorts received treatment by $2$ different care teams at two hospitals, which is a potential confounder despite similar baseline characteristics
>
> --- @data:Gunnarsson2017:helicopter, p.\ 5

In other words, the difference between hospitals and the staff may have been a confounding variable.
:::



::: {.example #ConfoundingSmoking54 name="Confounding"}
@data:DollHill1950:Smoking studied smoking using a backward-direction study.
The control group (those without lung cancer) was chosen to include very similar individuals to those in the lung-cancer group, in terms of age and sex.
(That is, the numbers of females and males within each age group was very similar for those *with* and *without* lung cancer.)
:::




## Hawthorne effect and blinding individuals {#HawthorneEffectObservational}
\index{Hawthorne effect}\index{Blinding!individuals}


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-binoculars-8-240.png" width="50px"/>
</div>


In observational studies, individuals *may* or *may not* know they are being observed.
For example, in an observational study where subjects' blood pressure is measured, subjects clearly know they are being observed, which has the potential to alter the subjects behaviour (for example, people become tense, called 'white-coat hypertension'; @pickering2002white).
As with experimental studies, efforts should be made to ensure that individuals do not know that they are being observed (the participants are *blinded*).


::: {.example #HawthorneHH  name="Hawthorne effect"}
A study [@wu2018identifying] examined hand hygiene (HH) of staff in a tertiary teaching hospital, using *covert* observers (observers not obviously watching the HH practices) and *overt* observers (observers obviously about watching the HH practices).
HH compliance was higher with overt observation ($78$%) than with covert observation ($55$%).
:::


## Observer effect and blinding researchers {#ObserverEffectObservational}
\index{Observer effect}\index{Blinding!researchers}


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-idea-10-240.png" width="50px"/>
</div>


The observer effect can impact observational as well as experimental studies.
For example, consider a study measuring the blood pressure of smokers and non-smokers [@verdecchia1995cigarette].
This study is observational (individuals cannot be allocated to be a smoker or non-smoker), but if the researchers *know* if an individual is a smoker when they measure blood pressure, then the observer effect could still impact the results (recalling that the observer effect is an *unconscious* effect).
For example, the researchers may *expect* smokers to have a high blood pressure.

The observer effect could be managed by *first* measuring the blood pressure, and *then* asking if the individual was a smoker or not.
That is, the researchers may be *blinded* to whether or not the subject is a smoker when they measure blood pressure.
This may only be partially successful; the researcher may see the subject carrying cigarettes, or can smell smoke on their breath, for example.
Nonetheless, since it may prove at least partially successful and is easy to implement, this strategy should form part of the research design.


::: {.example #ObsEffectObs name="Observer effect"}
@zimova2020using took photos of snowshoe hares, at various stages of moulting and in various environmental conditions.
Eighteen independent observers were asked to rate the moult stage from the photographs (p.\ 4): 

> ... images were randomly named and sorted, with the dates [...] removed to minimize observer expectancy bias [i.e., the observer effect].
:::


<!-- ::: {.example #BlindingObs name="Blinding in ecology"} -->
<!-- A study of research articles in ecology found: -->

<!-- > ... 50.4% ($n = 248$) to have potential for observer bias, but only 13.3% ($n = 33$ of $248$) of these articles stated use of blind observation.  -->
<!-- > -->
<!-- > --- @kardish2015blind -->

<!-- Blinding the observer is not always possible, but should be used when possible to improve the internal validity of the study. -->
<!-- ::: -->


::: {.exampleExtra data-latex=""}
A study of the scats of gray wolves was used to study their diet [@SpauldingScats].
A scat analysis is where humans examine the scat of carnivores to determine the prey.
However, the accuracy of the results was questioned, due to 'perpetuation of the assumption that wolf scats contain only $1$\ prey item/scat' (p.\ 949).

The observers might be seeing what they expect to see: that "wolf scats contain only $1$\ prey item/scat".
:::


<!-- ::: {.example name="Blinding in health promotion"} -->
<!-- A study [@gamble2016wearing] found that bicycle riders who *wear* helmets are more likely to take risks compared to bicycle riders who *do not wear* helmets. -->
<!-- The bicycle riders in the study were blinded to the *purpose* of the study (reducing the impact of the Hawthorne effect), though the participants knew they were in a study (so it was not completely eliminated). -->
<!-- However, the study was criticised [@radun2018bicycle], since it was possible that (p.\ 1020) -->

<!-- > ... the experimenters unconsciously conveyed their expectations to participants and thereby affected their responses [...]  -->
<!-- > the double-blind procedure [...] should have been used in this study. -->

<!-- The lack of [blinding](#Blinding), when it was possible to incorporate blinding, compromised the internal validity. -->
<!-- ::: -->
<!-- TURNS OUT THIS WAS AN EXPERIMENT -->


## Carry-over effect and washout periods {#CarryOverEffectObservational}
\index{Carry-over effect}\index{Washouts}


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-chart-21-240.png" width="50px"/>
</div>


The carry-over effect is a possible compromise to internal validity in observational studies involving a within-individuals comparison.
However, since treatments are *not allocated* in observational studies, carry-over effects may be difficult to prevent as washouts cannot be *imposed*, and the order of the conditions cannot be imposed.
However, *observing* individuals exposed to Condition\ A then Condition\ B, and other individuals exposed to Condition\ B then Condition\ A, may be possible.


::: {.example #CarryoverObs name="Carry-over effects"}
@norris2005carry studied the carry-over effect in ecological observational studies of animals (p.\ 181):
  
> ...individuals occupying poor quality winter habitat may experience reduced reproductive success the following breeding season when compared to individuals occupying high quality winter habitat.
:::




## Comments on blinding {#BlindingObservational}
\index{Blinding}

Many comments about blinding made for experimental studies (Sect.\ \@ref(DescribingBlinding)) apply for observational studies also. 
In observational studies, blinding individuals *may* be (but is not always) easier than in experimental studies (Sect.\ \@ref(HawthorneEffectObservational)).
Blinding the researchers may be difficult, since the researchers need to record the value of the explanatory variable.
One strategy (also see Sect.\ \@ref(ObserverEffectExperimental)) is for one researcher can record the value of the response variable, and another can record the value of the explanatory variable.


<!-- ::: {.example #BlindingDogs  name="Blinding in observational studies"} -->
<!-- In a study of dogs with chronic pancreatitis (CP), the researchers acquired abdominal ultrasounds and pathology results of each dog. -->
<!-- The authors report that the researchers conducting the ultrasounds were not blinded (@watson2010observational, p.\ 969). -->
<!-- However: -->

<!-- > Tissue samples [...] were obtained from all dogs and re-cut sections were reviewed by one of the authors (PJW) with the help of a veterinary pathologist  -->
<!-- > (AJR or TJS), all blinded to the clinical details of the case, but aware that CP was suspected in each dog... -->

<!-- This study clearly explains which parts of the study were blinded, and which were not. -->
<!-- ::: -->


::: {.example #BlindingGymnasts  name="Blinding in observational studies"}
@emerson2010ultrasonographically studied Achilles tendinopathy in gymnasts, by comparing $40$ elite gymnasts with $41$ controls of similar non-gymnasts.
The authors state (p.\ 38):

> Although the primary investigator was blind to the clinical status of the subjects, there was no blinding to whether each subject was in the gymnast or control group during image collection [...] 
> However the examiner was blinded to both the clinical state and group of each subject when the images were reviewed. 

The paper clearly explains who was blinded and to what parts of the study they were blinded.
:::





\index{Research design!observational|)}

## Chapter summary {#Chap8-Summary}

Designing effective *observational* studies  (Fig.\ \@ref(fig:DesignConsiderationsOBS)) requires researchers to maximise internal validity.
This can be achieved by *managing confounding* where possible, as confounding is often a major threat to the internal validity of observational studies.
Confounding can be managed by *restricting* the study to certain groups; *blocking*; and/or through special *analysis* methods.

Random allocation is not possible in observational studies.
For this reason, observing, measuring, assessing or recording all the information that is likely to be important for understanding the data is important, usually to be used in analysis.
Well-designed observational studies also try to manage the *carry-over effect*, the *Hawthorne effect*, and the *observer effect*
The *placebo effect* is not relevant.

Strategies for controlling these impacts are often not under the control of the researchers in observational studies.
Recording the values of possible extraneous variables is very important for observational studies.


(ref:DesignConsiderationsOBS-Caption) Design strategies for observational studies. Note: lurking variables become confounding variables when recorded in the study, and then they can be managed. The arrows indicate the main design strategy to (perhaps partially) manage the indicated potential bias. Not all strategies are possible for every study.

```{r DesignConsiderationsOBS, fig.cap='(ref:DesignConsiderationsOBS-Caption)', out.width='75%', fig.align="center",  fig.width=7.00} 
# fig.height=6,
source("R/showDesignConsiderations.R")
showDesignConsiderations(studyType = "Observational")
```





## Quick review questions {#Chap8-QuickReview}

::: {.webex-check .webex-box}
*Formwork* is used in construction with reinforced concrete, and can be labour intensive.
@mine2015observational examined the relationship between the floor area of the building (in m^2^ per storey) and the number of hours of labour needed for constructing the formwork (in person-minutes per storey).
The researchers also recorded the average age of the workers (in years); the average years of experience of the workers (in years); and the storey height (in meters) for each of $n = 15$ multi-storey buildings in the study.

Two observers recorded the labour time by observing workers from the start to the end of the work.

1. What is the *explanatory variable*? \tightlist
`r if( knitr::is_html_output() ) {longmcq( c(
	answer = "Floor area",
	"Hours of labour",
	"Average age of workers",
	"Average years of experience of workers",
	"Storey height"))}`
1. What is the *response variable*?
`r if( knitr::is_html_output() ) {longmcq( c(
	"Floor area",
	answer = "Hours of labour",
	"Average age of workers",
	"Average years of experience of workers",
	"Storey height"))}`
1. What *type* of description is appropriate for the variable 'Average age of the workers'?
`r if( knitr::is_html_output() ) {longmcq( c(
	"A confounding variable, since it is likely to be related to the explanatory variable only",
	"A confounding variable, since it is likely to be related to the response variable only",
	answer = "An extraneous variable, because it is likely to be related to the response variable only",
	"A lurking variable, since we don't know how it might be related to the response and explanatory variables"))}`
1. What is the most likely way to manage confounding in this study?
`r if( knitr::is_html_output() ) {longmcq( c(
	"Restricting, the study to multi-storey buildings",
	"Blocking, by only studying unit blocks",
	answer = "Analysis, by using other recorded variables in the analysis",
	"Random allocation of workers to the building projects"))}`
1. True or false: The *carry-over* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. True or false: The *Hawthorne* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( TRUE)}`
1. True or false: The *placebo* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. True or false: *Observer* bias is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE )}`
:::





## Exercises {#DesigningObservationalExercises}

Answers to odd-numbered exercises are available in App.\ \@ref(Answers).

`r if( knitr::is_latex_output() ) "\\captionsetup{font=small}"`

::: {.exercise #ResearchDesignObsTrueFalse}
Which of the following statements are true?

1. Observational studies cannot have a control group.\tightlist
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
2. Only experimental studies can use random allocation to avoid confounding
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
3. Only observational studies can manage the observer effect
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
4. Only experimental studies can use random sampling
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
:::


::: {.exercise #ResearchDesignObsPollen}
A study compared the average amount of pollen returned to the hive per bee, for two types of native Australian bees: yellow and black carpenter bees, and green carpenter bees. 
In the study, the researchers also recorded the size of the hive, among other things.
*Why* did they do this?
`r if( knitr::is_html_output() ) {longmcq( 
   c("To minimize the impact of the Hawthorne effect",
     "To ensure external validity",
     "Because the size of the hive is the explanatory variable",
     answer = "In case the size of the hive is a confounding variable") )}` 
:::


::: {.exercise #ResearchDesignTasteOfWater}
Consider this RQ (based on @teillet2010consumer): 'Among university students, is the taste of tap water different than the taste of bottled water?'

You want to answer this question using an *observational study*.
Describe what these might look like for this study, and which are feasible: 
random allocation;
blinding;
double blinding;
control;
finding a random sample.
:::


::: {.exercise #ResearchDesignHawthorneEffect}
Is the Hawthorne effect only a (potential) issue for experiments.
Explain.
:::



::: {.exercise #ResearchDesignSleep}
A study of how well hospital patients sleep at night [@delaney2018they] had the stated aim 'to investigate the perceived duration and quality of patient sleep'.
In discussing the limitations of the study, the researchers state (p.\ 7):
   
> The researchers made no attempt to deceive clinical staff regarding the nature of the study so the influence of the Hawthorne Effect should be considered. 
> The presence of the observer and environmental monitoring equipment in the clinical environment could have altered behaviour among patients and nursing staff 
> seeking to conform to the presumed research objectives. 
> As a result, the findings reported may be an underestimation of the magnitude of the issues that affect sleep.

Discuss these limitations in terms of the language used in this chapter.
:::




::: {.exercise #ResearchSmokingAlfresco}
@data:Stafford2010:Alfresco studied smoking in alfresco restaurants in two cities in Western Australia.
The concentration of particulate matter with a diameter smaller than or equal to $2.5$ (per cubic metre of air) was recorded (PM~2.5~)from $12$ cafes and $16$ pubs.
The researchers were interested in the relationship between PM~2.5~ and the number of smokers.
They also recorded the wind strength (calm; light breeze; windy) and the amount of cover (fully open; overhead cover only; overhead cover and enclosed sides).


1. What are the response and explanatory variables?
1. What are the extraneous variables, if any?
:::




::: {.exercise #ResearchDesignSunscreen}
In a study of time spent applying sunscreen [@data:Heerfordt2018:sunscreen], the Aim was to 'determine whether time spent on sunscreen application is related to the amount of sunscreen used' (p.\ 117).
The study is described as follows (p.\ 118):

> The volunteers were asked to apply the provided sunscreen [...] the way they would normally do on a sunny day at the beach in Denmark [...]
> The volunteers wore swimwear during the whole session. 
> No other information was given. 
> Participants applied sunscreen behind a curtain and were not observed during application. 
> Measurements of time and sunscreen weight were made without the subjects' being aware of this.

1. What are the response and explanatory variables?
1. The researchers also recorded age, height, weight and body surface area of each participant. 
   Why would they have done this?
1. The researchers also compared the mean values of the response variable for males and females, and the mean values of the explanatory variable for males and females. 
   Why would they have done this? 
1. What design features are evident in the quote?
:::

`r if( knitr::is_latex_output() ) "\\captionsetup{font=normalsize}"`


<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to *Quick Revision* questions:**
**1.** Floor area.
**2.** Hours of labour.
**3.** Extraneous; likely to be related to the response variable only.
**4.** Analysis, using other recorded variables.
**5.** False.
**6.** True.
**7.** False.
**8.** False.
:::
`r if (knitr::is_html_output()) '-->'`

