
# More about CIs {#AboutCIs}


```{r, child = if (knitr::is_html_output()) {'./introductions/28-CIs-More-HTML.Rmd'} else {'./introductions/28-CIs-More-LaTeX.Rmd'}}
```


## General comments {#CIGeneralComments}

The previous chapters discussed forming confidence intervals (CI) for estimating a population proportion, and for estimating a mean.
CIs in other contexts will also be studied.
This chapter discusses some principles that apply to CIs in general.

CIs are formed for an unknown *population* parameter (such as the population proportion $p$), using the best estimate of the parameter: the *sample* statistic (such as the sample proportion $\hat{p}$).
Most CIs have the form  
\[
  \text{Statistic} \pm (\text{multiplier} \times \text{standard error}),
\]
where $(\text{multiplier} \times \text{standard error})$ is called the  *margin of error*.
For an *approximate* $95$%\ CI, the *multiplier* is $2$ (from the [$68$--$95$--$99.7$ rule](#def:EmpiricalRule)), provided the statistical validity conditions are met.
The statistical conditions should always be checked to see if the CI is (at least approximately) statistically valid.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Confidence intervals* tell us about the unknown *population parameter*, based on what we learn from one the countless possible sample statistics.
:::


## About writing conclusions {#CIWritingConclusions}

When reporting a CI, include:

1. the CI (including units of measurement, if relevant);
1. the level of confidence for the CI (typically, a $95$%\ CI); and 
1. the value of the statistic (the parameter estimate) and the sample size.

If the CI is an *approximate* CI (e.g., based on using an approximate multiplier of $2$), this should also be clear.

:::{.example #CIWritingConclusions name="Writing conclusions"}
In Sect.\ \@ref(Cadmium-In-Peanuts), the mean cadmium level of peanuts was estimated.
The conclusion given was:

> The sample mean cadmium concentration of peanuts is $\bar{x} = 0.0768$\ ppm (s.e.: $0.00270$; $n = 290$), with an approximate $95$%\ CI from $0.0714$ to $0.0822$\ pmm.

Each of the three elements above are given:

1. the CI: $0.0714$ to $0.0822$\ pmm;
1. the level of confidence for the CI: $95$%; and 
1. sample summary information: $\bar{x} = 0.0768$\ ppm; s.e.: $0.00270$; $n = 290$.

In addition, the CI is flagged as a *approximate* $95$%\ CI.
:::


## About interpreting CIs {#CIInterpretation}

Interpreting CIs correctly takes care.
The *correct* interpretation (Def.\ \@ref(def:ConfidenceInterval)) of a $95$%\ CI is the following:

> *If* samples of the same size were repeatedly taken many times, and the $95$% confidence interval computed for each sample, $95$% of these confidence intervals formed would contain the population [*parameter*](#def:Parameter).

This is the idea shown in
`r if (knitr::is_latex_output()) {
   'Fig.\\ \\@ref(fig:RollDiceCIFig).'
} else {
   'the animation in Sect.\\ \\@ref(ConfIntPUnknownP).'
}`
In practice, this definition is unsatisfying, since we only ever have *one* sample.
Furthermore, since the value of the parameter is unknown (after all, the reason for taking a sample was to *estimate* the value of the parameter), we don't know if *our* CI from our single sample includes the population parameter or not.

Two reasonable alternative interpretations for a $95$%\ CI are:

> * The $95$%\ CI gives a range of values of the unknown parameter that could plausibly (with $95$% confidence) have produced our observed value of the statistic.
> * There is a $95$% chance that our $95$%\ CI straddles the value of the population parameter.

These alternatives are reasonable and common interpretations.

Commonly, the CI is described as having a $95$% chance of containing the population [parameter](#StatisticsAndParameters).
This is not strictly correct (the CI either *does* or *does not* contains the value of the population parameter), but is a common and a convenient paraphrase for the correct interpretation above.

I use this analogy:
Most people say the sun rises in the east.
This is incorrect; the sun doesn't *rise* at all.
People *say* the sun rises in the east as a convenient way to explain that the earth rotates on its axis, and we see the sun each morning in the east.
Similarly, most people interpret a CI as an interval with a certain chance of containing the value of the population parameter, even though it is technically incorrect.


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/tin-1568095_640.jpg" width="200px"/>
</div>



::: {.example #EnergyDrinks name="Energy drinks in Canadian youth"}
In Example\ \@ref(exm:CanadianEnergyDrinks), the approximate $95$%\ CI was from $0.192$ to $0.236$.
The correct interpretation is:

> If many samples of $1516$ Canadian youth were taken, and the approximate $95$%\ CI computed for each one, about $95$% of those CIs would contain the population proportion.

We don't know if *our* CI from a single sample includes the value of $p$, however.
We might say:

> This $95$%\ CI (from $0.192$ to $0.236$) is likely to straddle the actual value of $p$. 

or

> The range of values of $p$ that could plausibly (with $95$% confidence) have produced $\hat{p} = 0.241$ is between $0.192$ and $0.236$.

In practice, the CI is usually interpreted as:

> There is a $95$% chance that the population proportion of Canadian youth who have experienced sleeping difficulties after consuming energy drinks is between $0.192$ to $0.236$.

This is not strictly correct, but is commonly-used, and sufficient for our use.
:::


## About statistical validity {#ValidityCIs}

When constructing confidence intervals, *statistical validity conditions* must be true to ensure the mathematics behind the calculations are sound.
For instance, if the sampling distribution has an approximate normal distribution, the statistical validity conditions ensure that the approximation is sufficiently accurate for the [$68$--$95$--$99.7$ rule](#def:EmpiricalRule) rule to apply^[Not all sample statistics have normal distributions, but all the sample statistics in this book are either normally distributed or are closely related to normal distributions.].
If these conditions are *not* met, the sampling distribution may not be close to an approximate normal distribution, so the $68$--$95$--$99.7$ rule (on which the CI is based) may not be appropriate, and the CI itself may be inappropriate.
Of course, if the statistical validity conditions are close to be satisfied, then the resulting confidence interval will still be reasonably useful.

In addition to the statistical validity condition, the *internal validity* and *external validity* of the study should be discussed (Fig.\ \@ref(fig:ValiditiesCI)).


```{r ValiditiesCI, fig.cap="Four types of validities for studies.", fig.align="center", fig.height=4, fig.width=8, out.width="80%",}
par( mar = c(0.15, 0.15, 0.15, 0.15))

ValidityColours <- viridis::viridis(8) # alpha = 0.4)
TypeCol <- ValidityColours[6]
ConditionCol <- ValidityColours[7]
ImplicationCol <- ValidityColours[8]



openplotmat()

pos <- array(NA, 
             dim = c(12, 2))
pos[1, ] <- c(0.25, 0.85) # External
pos[2, ] <- c(0.45, 0.85) # Internal
pos[3, ] <- c(0.65, 0.85)   # Ecological
pos[4, ] <- c(0.85, 0.85)   # Statistical

pos[5, ] <- c(0.25, 0.50)   # EX: conditions
pos[6, ] <- c(0.45, 0.50)   # IN: conditions
pos[7, ] <- c(0.65, 0.50)   # ECO: conditions
pos[8, ] <- c(0.85, 0.50)   # ST: conditions

pos[9, ] <- c(0.25, 0.085)   # EX: upshot
pos[10, ] <- c(0.45, 0.085)   # IN: upshot
pos[11, ] <- c(0.65, 0.085)   # ECO: upshot
pos[12, ] <- c(0.85, 0.085)   # ST: upshot

textplain( mid = c(0.07, pos[1, 2]),
           lab = "Type:",
           adj = c(0.5, 1))
textplain( mid = c(0.07, pos[5, 2]),
           lab = "Condition:",
           adj = c(0.5, 1))
textplain( mid = c(0.07, pos[9, 2]),
           lab = "Implication:",
           adj = c(0.5, 1))


straightarrow(from = pos[1, ], to = pos[5, ], 
              lwd = 2, 
              lcol = "black",
              lty = 1)
straightarrow(from = pos[2, ], to = pos[6, ], 
              lwd = 2,
              lcol = "black",
              lty = 1)
straightarrow(from = pos[3, ], to = pos[7, ], 
              lwd = 2,
              lcol = "black",
              lty = 1)
straightarrow(from = pos[4, ], to = pos[8, ], 
              lwd = 2,
              lcol = "black",
              lty = 1)


straightarrow(from = pos[5, ], to = pos[9, ], 
              lwd = 2, 
              lcol = "black",
              lty = 3)
straightarrow(from = pos[6, ], to = pos[10, ], 
              lwd = 2,
              lcol = "black",
              lty = 3)
straightarrow(from = pos[7, ], to = pos[11, ], 
              lwd = 2,
              lcol = "black",
              lty = 3)
straightarrow(from = pos[8, ], to = pos[12, ], 
              lwd = 2,
              lcol = "black",
              lty = 3)

textrect( pos[1, ], 
           lab = "External\n validity", 
           radx = 0.09, 
           rady = 0.10, 
           shadow.size = 0,
           box.col = TypeCol,
           lcol = TypeCol)
textrect( pos[2, ], 
           lab = "Internal\n validity", 
           radx = 0.09, 
           rady = 0.10, 
           shadow.size = 0,
           box.col = TypeCol,
           lcol = TypeCol)
textrect( pos[3, ], 
           lab = "Ecological\n validity", 
           radx = 0.09, 
           rady = 0.10, 
           shadow.size = 0,
           box.col = TypeCol,
           lcol = TypeCol)
textrect( pos[4, ], 
           lab = "Statistical\n validity", 
           radx = 0.09, 
           rady = 0.10, 
           shadow.size = 0,
           box.col = TypeCol,
           lcol = TypeCol)

textrect( pos[5, ], 
           lab = "Random\n samples", 
           radx = 0.09, 
           rady = 0.10, 
           shadow.size = 0,
           box.col = ConditionCol,
           lcol = ConditionCol)
textrect( pos[6, ], 
           lab = "Well-designed;\nwell conducted", 
           radx = 0.09, 
           rady = 0.10,
           shadow.size = 0,
           box.col = ConditionCol,
           lcol = ConditionCol)
textrect( pos[7, ], 
           lab = "Study like\nreal world", 
           radx = 0.09, 
           rady = 0.10, 
           shadow.size = 0,
           box.col = ConditionCol,
           lcol = ConditionCol)
textrect( pos[8, ], 
           lab = "Specific\n conditions", 
           radx = 0.09, 
           rady = 0.10, 
           shadow.size = 0,
           box.col = ConditionCol,
           lcol = ConditionCol)

textrect( pos[9, ], 
           lab = "Sample\n represents\n population", 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = ImplicationCol,
           lcol = ImplicationCol)
textrect( pos[10, ], 
           lab = c("Within-sample\n conclusions\n are sound"), 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = ImplicationCol,
           lcol = ImplicationCol)
textrect( pos[11, ], 
           lab = "Results\n seen in\n real world", 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = ImplicationCol,
           lcol = ImplicationCol)
textrect( pos[12, ], 
           lab = "Statistical\n methods\n appropriate", 
           radx = 0.09, 
           rady = 0.150, 
           adj = c(0.5, 0.25),
           shadow.size = 0,
           box.col = ImplicationCol,
           lcol = ImplicationCol)

```


In addition, CIs also require that the sample size is less than about $10$% of the population size; this is almost always the case.


<iframe src="https://learningapps.org/watch?v=paixpst9c22" style="border:0px;width:100%;height:600px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>


## Quick revision exercises {#Chap21-QuickReview}

Are the following statements *true* or *false*?

::: {.webex-check .webex-box}
1. True or false: CIs *always* have $95$% confidence. \tightlist  
`r if( knitr::is_html_output() ) {torf(answer = FALSE )}`
1. True or false: Statistical validity concern *generalisability* of the results.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE )}`
1. True or false: CIs always include the value of the *population* parameter.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE )}`
1. True or false: All other things being equal, a $95$%\ CI is *wider* than a $90$%\ CI.  
`r if( knitr::is_html_output() ) {torf(answer = TRUE )}`
1. The 'multiplier times the standard error' is called the *margin of error*.
`r if( knitr::is_html_output() ) {torf(answer = TRUE )}`
1. We are fairly sure (but *not certain*) that the CI includes the value of the statistic.
`r if( knitr::is_html_output() ) {torf(answer = FALSE )}`
:::



## Exercises {#AboutCIsExercises}

Selected answers are available in Sect.\ \@ref(AboutCIsAnswer).


::: {.exercise #AboutCIsInterpretation}
A researcher was computing a $95$%\ CI for a single proportion to estimate the proportion of trees with apple scab [@hirst1962epidemiology], and found $\hat{p} = 0.314$ and $\text{s.e.}(\hat{p}) = 0.091$.
What is wrong with the following conclusion?

> An approximate $95$%\ CI for the sample proportion is between $0.223$ and $0.405$.
:::


::: {.exercise #AboutCIsInterpretation2}
A researcher was computing a $95$%\ CI for a single proportion to estimate the proportion of trees with apple scab [@hirst1962epidemiology], and found that $\hat{p} = 0.314$ and $\text{s.e.}(\hat{p}) = 0.091$.
What would be wrong with the following conclusion?

> This CI means we are $95$% confident that between $22.3$ and $40.5$ trees are infected with apple scab.
:::


::: {.exercise #AboutCIsInterpretationMean}
A study of sodium intake in Thailand found the $95$%\ CI for the mean daily sodium intake for subjects with a secondary school education was $3565$ to\ $3903$\ mg.
What would be wrong with the following conclusion?

> This CI means that approximately $95$% of the subjects had a daily sodium intake between $3565$ to\ $3903$\ mg.
:::


::: {.exercise #AboutCIsInterpretationMean2}
A study of sodium intake in Thailand found the $95$%\ CI for the mean daily sodium intake for subjects with a secondary school education was $3565$ to\ $3903$\ mg.
What would be wrong with the following conclusion?

> A $95%\ CI for the sample mean daily sodium intake is between $3565$ to\ $3903$\ mg.
:::




<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to in-chapter questions:**

\textbf{\textit{Quick Revision} questions:}
**1.** False.
**2.** False.
**3.** False.
**4.** True.
**5.** Margin of error.
**6.** Population parameter.
:::
`r if (knitr::is_html_output()) '-->'`


