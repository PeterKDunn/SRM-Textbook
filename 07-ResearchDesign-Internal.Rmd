
# Internal validity {#DesignInternal}
\index{Internal validity}\index{Research design!internal validity|(}


<!-- Introductions; easier to separate by format -->
```{r, child = if (knitr::is_html_output()) {'./introductions/07-ResearchDesign-Internal-HTML.Rmd'} else {'./introductions/07-ResearchDesign-Internal-LaTeX.Rmd'}}
```


<!-- Define colours as appropriate -->
```{r, child = if (knitr::is_html_output()) {'./children/coloursHTML.Rmd'} else {'./children/coloursLaTeX.Rmd'}}
```



## Introduction {#Chap7-Intro}

A well-designed study is needed to draw solid conclusions: a study with high high *external validity* (Sect.\ \@ref(def:ExternalValidity)) and high *internal validity* (Sect.\ \@ref(def:InternalValidity)).
Some research design decisions to maximise internal validity are discussed in this chapter.


::: {.example #InternalValidity name="Importance of internal validity"}
@beaman2013profitability describe an experiment where free fertilizer was provided to a sample of female farmers in Mali (at the recommended rate, or at half the recommended rate).

The farmers knew they were part of a study, so changed their farm management: they employed more hired labour and used more herbicide.
Consequently, the yields for *all* farmers improved.
Knowing if changes in yield were the result of applying the fertilizer is difficult, as the study had poor *internal validity*.
:::


Specific design strategies for maximising internal validity include:

* managing confounding (Sect.\ \@ref(ManagingConfounding)).
* managing the Hawthorne effect by blinding individuals (Sect.\ \@ref(HawthorneEffect)).
* managing the observer effect by blinding the researchers (Sect.\ \@ref(ObserverEffect)).
* managing the placebo effect by using controls, objective measures and blinding (Sect.\ \@ref(PlaceboEffect)).
* managing the carry-over effect by using washouts (Sect.\ \@ref(CarryOverEffect)).

Not all of these strategies will be relevant to every study.


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


## Managing confounding {#ManagingConfounding}
\index{Internal validity!managing confounding}


:::{.example #HimalayaStudy name="Himalaya study"}
Consider this relational RQ (based on @data:Bird2008:wholegrain) with an intervention:

> Among Australians, is the average faecal weight the same for people eating provided food made from wholegrain *Himalaya 292* compared to eating provided food made from refined cereal?  
:::


Suppose that the researchers created two groups of individuals for this experimental study:

* *Group\ A*: women recruited from a female-only gym.
* *Group\ B*: men recruited from a local nursing home.

The researchers gave *Himalaya 292* to Group\ A, and the refined cereal to Group\ B.\spacex
If a difference in faecal weight was detected between the two groups, the difference may due to:

* the different *diets* (the explanatory variable) for each group;
* the different *sexes* in each groups (Group\ A was all women; Group\ B was all men);
* the different *ages* in each group (Group\ A is likely to be younger on average than those in Group\ B); or
* the different *overall health* in each group (Group\ A would generally be healthier than those in Group\ B).

Any difference in faecal weight detected between the two groups may not be due to the diets (Table\ \@ref(tab:ConfoundingGroups)): the study has very poor internal validity, due to poor research design.

Sex, age and overall health are *confounding variables* (Def.\ \@ref(def:ConfoundingVariable)), as they are associated with the type of diet (the explanatory variable) and faecal weight (the response variable).\index{Variables!confounding}
For example, the age of the subject may be associated with faecal weight (older people tend to eat less, and eat differently, than younger people), and the research design means that older people are more likely to be consuming the refined cereal.
This is an extreme case of *confounding* (Fig.\ \@ref(fig:ConfoundingDiagram)); usually, confounding is more subtle (and more difficult to detect) than in this example.


```{r}
if( knitr::is_latex_output() ) {
  ConfoundTable <- array( dim = c(4, 3) )
  
  colnames(ConfoundTable) <- c("\\textbf{Variable}", 
                               "\\textbf{Group A}",
                               "\\textbf{Group B}")
  
  ConfoundTable[1, ] <- c("\\textbf{Sex}",
                          "Women",
                          "Men")
  ConfoundTable[2, ] <- c("\\textbf{Age}",
                          "Younger",
                          "Older")
  ConfoundTable[3, ] <- c("\\textbf{Cereal}",
                          "*Himalaya 292*",
                          "Refined")
  ConfoundTable[4, ] <- c("\\textbf{Fitness}",
                          "Fitter",
                          "Less fit")
  
  ConfoundTable[3, 2] <- "\\textit{Himalaya 292}"
} else {
  ConfoundTable <- array( dim = c(4, 3) )
  
  colnames(ConfoundTable)<- c( "",
                               "Group A",
                               "Group B")
  ConfoundTable[1, ] <- c("*Sex*",
                          "Women",
                          "Men")
  ConfoundTable[2, ] <- c("*Age*",
                          "Younger (in general)",
                          "Older (in general)")
  ConfoundTable[3, ] <- c("*Cereal*",
                          "*Himalaya 292*",
                          "Refined")
  ConfoundTable[4, ] <- c("*Fitness*",
                          "Very fit (in general)",
                          "Less fit (in general)")
  
  IMG1 <- array( NA, dim = c(1, 1))
  IMG1[1, 1] <- "![](./Pics/iconmonstr-candy-5-240.png){#id .class height=60px}<br>
               ![](./Pics/iconmonstr-arrow-down-thin-240.png){#id .class height=50px} <br>
               ![](./Pics/iconmonstr-generation-4-240.png){#id .class height=60px}"
  
  IMG2 <- array( NA, dim = c(1, 1))
  IMG2[1, 1] <- "![](./Pics/iconmonstr-candy-8-240.png){#id .class height=60px} <br>
               ![](./Pics/iconmonstr-arrow-down-thin-240.png){#id .class height=50px} <br>
               ![](./Pics/iconmonstr-generation-15-240.png){#id .class height=60px}"
}
```


\begin{figure}
\begin{minipage}{0.38\textwidth}
\captionof{table}{Comparing Groups\ A and\ B: an extreme example of confounding\label{tab:ConfoundingGroups}.}
\fontsize{8}{12}\selectfont
```{r}
kable(ConfoundTable[, c(2, 1, 3)],
      format = "latex",
      longtable = FALSE,
      booktabs = TRUE,
      table.env = "@empty",
      escape = FALSE, # For LaTeX commands to work in table
      align = c("r", "c", "l"))   
```
\end{minipage}
%% Add a gap between elements
\hspace{0.08\textwidth}
%%%
\begin{minipage}{0.54\textwidth}%
```{r, fig.width=4.5, fig.height=2.5, out.width='99%'}
par( mar = c(0.1, 0.1, 0.1, 0.1))
openplotmat()

pos <- array(NA, 
             dim = c(3, 2)) 
pos[1, ] <- c(0.17, 0.25) # Faecal wt
pos[2, ] <- c(0.83, 0.25) # Diet
pos[3, ] <- c(0.50, 0.75) # Age


straightarrow(from = pos[2,], 
              to = pos[1,], 
              lty = 2, 
              lwd = 2,
              lcol = "grey")
straightarrow(from = pos[3,], 
              to = pos[1,], 
              lty = 1, 
              lwd = 2,
              lcol = "black")
straightarrow(from = pos[3,], 
              to = pos[2,], 
              lty = 1, 
              lwd = 2,
              lcol = "black")


textrect(mid= c(0.5, 0.48),
         radx = 0.2,
         rady = 0.08,
         cex = 0.85,
         lcol = makeTransparent("white"),
         box.col = makeTransparent("white"),
         shadow.size = 0,
         lab = "Actual associations")
#text(x = 0.5,
#     y = 0.46,
#     cex = 0.85,
#     pos = 3,
#     labels = "Actual associations")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 3,
     labels = "Apparent")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 1,
     labels = "assocation")

textrect( pos[1,], 
          lab = "Faecal wt",
          radx = 0.14,
          rady = 0.075,
          shadow.size = 0,
          lcol = ResponseColour,
          box.col = ResponseColour)
textrect( pos[2,], 
          lab = "Diet", 
          radx = 0.14,
          rady = 0.075,
          shadow.size = 0,
          lcol = ExplanatoryColour,
          box.col = ExplanatoryColour)
textrect( pos[3,], 
          box.col = "white",
          lcol = grey(0.75),
          shadow.size = 0,
          radx = 0.20,
          rady = 0.075,
          col = grey(0.3),
          lab = "Age")
```
\captionof{figure}{An extreme example of confounding\label{fig:ConfoundingDiagram}.}
\end{minipage}
\end{figure}


```{r ConfoundingGroups}
if ( knitr::is_html_output()) {
  
  kable( list( IMG1,
               ConfoundTable[, c(2, 1, 3)],
               IMG2),
         caption = "Comparing Groups A and B: an extreme example of confounding.",
         format = "html",
         align = "c",
         escape = FALSE) %>%
    kable_styling(full_width = FALSE)
} 
```


<!-- The figure for LaTeX is in the minipage (combined with data table), so only need show it for the HTML -->
`r if (knitr::is_latex_output()) '<!--'`
```{r ConfoundingDiagram, fig.width=5, fig.height=4, out.width='55%', fig.align="center", fig.cap="An extreme example of confounding."}
par( mar = c(0.5, 0.5, 0.5, 0.5))
openplotmat()

pos <- array(NA, 
             dim = c(3, 2)) 
pos[1, ] <- c(0.17, 0.25) # Faecal wt
pos[2, ] <- c(0.83, 0.25) # Diet
pos[3, ] <- c(0.50, 0.75) # Age


straightarrow(from = pos[3,], # Age to...
              to = pos[1,],   # ... Faceal wt
              lty = 2, 
              lwd = 2,
              lcol = "grey")
straightarrow(from = pos[3,], # Age to...
              to = pos[2,],   # ... Diet
              lty = 2, 
              lwd = 2,
              lcol = "grey")


straightarrow(from = pos[2,], 
              to = pos[1,], 
              lty = 1, 
              lwd = 2,
              lcol = "grey")
textrect(mid= c(0.5, 0.48),
         radx = 0.2,
         rady = 0.08,
         cex = 0.85,
         lcol = makeTransparent("white"),
         box.col = makeTransparent("white"),
         shadow.size = 0,
         lab = "Actual associations")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 3,
     labels = "Apparent")
text(x = 0.5,
     y = 0.25,
     cex = 0.85,
     pos = 1,
     labels = "associations")

textrect( pos[1,], 
          lab = "Faecel wt",
          radx = 0.15,
          rady = 0.075,
          shadow.size = 0,
          lcol = ResponseColour,
          box.col = ResponseColour)
textrect( pos[2,], 
          lab = "Diet", 
          radx = 0.15,
          rady = 0.075,
          shadow.size = 0,
          lcol = ExplanatoryColour,
          box.col = ExplanatoryColour)
textrect( pos[3,], 
          box.col = "white",
          lcol = grey(0.75),
          shadow.size = 0,
          radx = 0.20,
          rady = 0.075,
          col = grey(0.3),
          lab = "Age")
```

`r if (knitr::is_latex_output()) '-->'`


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*The groups being compared should be as similar as possible*, apart from the difference being studied.
:::

Since the groups being compared should be as similar as possible, apart from what is being studied, researchers often compare the comparison groups on potential confounding variables.


In *experimental* studies, an excellent way to manage confounding is:

1. *Randomly allocating* individuals to the comparison groups.\index{Confounding!analysis}

Random allocation should ensure that the values of potential confounding variables are approximately evenly spread between the comparison groups.\index{Confounding!random allocation}
This is true for identified potential confounders (such as age), and also for variables *not* even considered as confounders, or are hard to measure or observe (such as genetic conditions).

*Randomly allocating* individuals to comparison groups is *not possible* in observational or quasi-experimental studies.
For this reason, confounding is often a major threat to internal validity in these studies, as individuals who are in one comparison group may be different, in general, to those who are in another group.
Fortunately, other (less effective) means for managing confounding also exist:

<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-andrea-piacquadio-3768131.jpg" width="200px"/>
</div>


2. *Restricting* the study to a certain group, by keeping some variables approximately constant.
  These variables a type of *control variable* (Def.\ \@ref(def:ControlVariables)).\index{Confounding!control variables}
  If possible, a reason for this restriction should be given.
3. *Blocking*,\index{Confounding!blocking}
  when units of analysis are arranged into different groups containing individuals that are similar to each another (see Sect.\ \@ref(PairedTTest-SoilN) for an example).
  

::: {.definition #Blocking name="Blocking"}
*Blocking* occurs when units of analysis are arranged or analysed as separate groups of similar units (called *blocks*).
:::


4. *Analysing* using special methods (beyond this book), after recording the values of potential confounding variables.
  Because of this, *recording all potential extraneous variables* is important.
  Most studies involving people record the participants' age and sex if possible, as these two variables are common confounders.
  Once a sample is obtained, recording this extra information usually requires little extra effort.

*Restricting* and *blocking* are useful if one or two variables are known, or thought likely, to cause confounding.
Multiple approaches can be used, such as randomly allocating individuals to groups, *and* recording other variables that can be managed through analysis.

*Randomly allocating* is superior when possible, because confounding is reduced for variables not even suspected as being confounders.
Hence, *experimental* studies should use random allocation whenever possible.

For any study (but especially for observational and quasi-experimental studies), recording the values of any potential confounding variables is useful, so special analysis methods can be used to manage confounding.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Record* all the extraneous variables likely to be important for understanding the data (Sect.\ \@ref(RecordExtraneous)).
This may include information about the *individuals* in the study, and the *circumstances* of the individuals in the study (that is, the circumstances the individuals find themselves in; these may not be measured on the individuals themselves).
:::


Common to many of these methods is to ensure that any potential confounding variables are recorded (Sect.\ \@ref(RecordExtraneous)), to ensure no *lurking variables* exist that may compromise the internal validity of the results.
  

::: {.example #HimalayaConfounding name="Managing confounding: experimental study"}
For the *Himalaya* study, different methods can be used to manage confounding due to age.

The study could be *restricted* to people under $30$.
Age would be a *control variable*.

*Blocking* could be used by finding similar pairs of subjects (e.g., pairs of subjects of the same sex, with similar age and weight).
One of each pair is given the refined cereal diet, and one given the *Himalaya 292* diet.
The *differences* in faecal weight for each pair can be analysed using special methods (see Chap.\ \@ref(TestPairedMeans) for example). 

Information *about the individuals* could be *recorded*, such as age and pre-study weight.
Information *about the circumstances* of the individuals could also be *recorded*, such as where they live.
Then, special methods of analysis could be used to analyse the data.

Since the study is *experimental*, participants could be *randomly allocated* into one of two groups, so both groups would have a similar spreads of ages (and other potential confounders).
Then groups could be randomly allocated to receive one of the diets (Fig.\ \@ref(fig:RandomAllocationHimalaya)).

In the *Himalaya 292* study, individuals were randomly allocated to the diets (p.\ 1033), which manages confounding due to age and other potential confounding variables also.
:::




```{r RandomAllocationHimalaya, echo=FALSE, fig.cap="Random allocation can occur in two places for the Himalaya study.", fig.align="center", fig.height=3, out.width='65%'}
source("R/showStudyDesign.R")

showStudyDesign(studyType = "TrueExp",   
                addIndividuals = TRUE,
                addByResearchers = FALSE,
                addImages = TRUE,   
                addRandomAllocationText = TRUE, 
                imageList = c("./Pics/iconmonstr-candy-5-240.png",
                              "./Pics/iconmonstr-candy-8-240.png"),
                addCNames = c("Himalaya 292",
                              "Refined"))
```


:::{.exampleExtra  data-latex=""}
An experiment to study the effect of using ginko to enhance memory [@data:Solomon2002:Ginko] compared two groups: one using ginko ($n = 111$), and one using a fake, non-active supplement ($n = 108$).
The authors randomly allocated participants to each group, then compared the two groups to ensure that no obvious differences initially existed between the groups that might explain differences in the response variable (Table\ \@ref(tab:GinkoDemographics)).

Two groups are similar in terms of age, education and gender distribution.
Any difference in outcome between the groups is probably due to the treatment.



```{r GinkoDemographics}
Ginko <- array( dim = c(3, 3) )
colnames(Ginko) <- c("Characteristic", 
                     "Group A (Ginko)", 
		     "Group B (Fake)")

Ginko[1, ] <- c("Average age (in years)", 
                "68.7", 
		"69.9")
Ginko[2, ] <- c("Men (number; percentage)", 
                "46 (41%)", 
		"45 (42%)")
Ginko[3, ] <- c("Average years of education", 
                "14.4", 
		"14.0")

if( knitr::is_latex_output() ) {
  kable(Ginko,
        format = "latex",
        longtable = FALSE,
        booktabs = TRUE,
        #escape = FALSE, # For latex to work in \rightarrow
        linesep  =  c("", "", "", "\\addlinespace", "", "", ""), # Otherwise addes a space after five lines... 
        caption = "Comparing the two groups in the ginko-memory study.",
        align = c("r", "c", "c"))   %>%
   kable_styling(full_width = FALSE, font_size = 8) %>%
   row_spec(0,bold = TRUE) # Columns headings in bold
}

if( knitr::is_html_output() ) {
  kable(Ginko,
        format = "html",
        align = c("r", "r", "r"),
        longtable = FALSE,
        caption = "Comparing the two groups in the ginko-memory study.",
        booktabs = TRUE) 
}
```
:::


:::{.exampleExtra  data-latex=""}
Researchers explored the use of dominant and non-dominant hands for chest compression in student paramedics using an experimental study [@cross2019impact].
Students were randomly divided into two groups: DHOS (dominant hand on chest) and NDHOC (non-dominant hand on chest).
The two groups were then compared:

| Demographic                  | All participants ($n = 75$)   | DHOC ($n = 37$)   | NDHOC ($n = 38$) 
| ----------------------------:+:-----------------------------:+:-----------------:+:----------------:
| Average age (years)          | $23.4$                        | $22.5$            | $24.3$
| Gender: percentage Female    | $51$%                         | $53$%             | $47$%

The two groups appear to be very similar in terms of average age of participants, and the percentage of female participants.
If differences are observed in the study between the DHOC and NDHOC groups, it is probably due to the treatment.
The study should have reasonable internal validity.
:::



::: {.example #ConfoundingKiwi name="Managing confounding: observational study"}
@data:froud2018:kiwifruit studied $2\ 599$ kiwifruit orchards using an observational study, exploring the relationship between the time since a bacterial canker was first detected (in weeks) as the explanatory variable, and the orchard productivity (in tray equivalents per hectare) as the response variable.

The researchers also recorded extraneous variables such as 'whether or not the farm was organic', 'elevation of the orchard' and 'whether or not general fungicides were used'.
These variables were used in their analysis to manage the potential effects of confounding.
:::


::: {.example #ActiveSedentaryWomen name="Comparing study groups: observational study"}
An observational study compared the iron levels of active and sedentary women aged\ $18$ to\ $35$ [@data:woolf:ironstatus].
The active women ($n = 28$) and sedentary women ($n = 28$) were compared on a variety of characteristics (Table\ \@ref(tab:SedentaryDemographics)).
The active women were similar to the sedentary women on these characteristics, but were (in general) slightly younger, slightly heavier, and slightly more likely to use hormonal contraceptives.
:::


```{r SedentaryDemographics}
WomenIron <- array( dim = c(4, 3) )
colnames(WomenIron) <- c("Characteristic", "Active women", "Sedentary women")

WomenIron[1, ] <- c("Average age (in years)", 
                    "20", 
                    "24")
WomenIron[2, ] <- c("Average height (in cm)", 
                    "169", 
                    "166")
WomenIron[3, ] <- c("Average weight (in kg)", 
                    "68", 
                    "62")
WomenIron[4, ] <- c("Percentage using hormonal contraceptives", 
                    "13", 
                    "11")

  
if( knitr::is_latex_output() ) {
  kable( pad(WomenIron[ c(1, 3, 4), ],
             surroundMaths = TRUE,
             targetLength = 2,
             digits = 0),
        format = "latex",
        longtable = FALSE,
        booktabs = TRUE,
        escape = FALSE, # For latex to work in \rightarrow
        linesep = c("", "", "", "", "", ""), # Otherwise adds a space after five lines... 
        caption = "The demographic information for those in the study of iron levels in women.",
        align = c("r", "c", "c") )   %>%
   kable_styling(full_width = FALSE, 
                 font_size = 8) %>%
  row_spec(0,bold=TRUE) # Columns headings in bold
}

if( knitr::is_html_output() ) {
  kable( pad(WomenIron[ c(1, 3, 4), ],
             surroundMaths = TRUE,
             targetLength = 2,
             digits = 0),
        format = "html",
        align = c("r", "c", "c"),
        longtable = FALSE,
      caption = "The demographic information for those in the study of iron levels in women.",
      booktabs = TRUE)
}
```



:::{.exampleExtra data-latex=""}
A study [@data:Gunnarsson2017:helicopter] examined the difference between two types of helicopter transfer (physician-staffed; non-physician-staffed) of patients with a specific type of myocardial infarction (STEMI).
The purpose of the study was:

> ...to evaluate the characteristics and outcomes of physician-staffed HEMS (Physician-HEMS) versus non-physician-staffed (Standard-HEMS) in patients with STEMI.
>
> --- @data:Gunnarsson2017:helicopter, p.\ 1

The researchers 

> ...studied $398$ STEMI patients transferred by either Physician-HEMS ($n = 327$) or Standard-HEMS ($n = 71$) for [...] intervention at $2$\ hospitals between 2006 and 2014.
>
> --- @data:Gunnarsson2017:helicopter, p.\ 1

Since the study is an observational study (patients were not allocated by the researchers to the type of helicopter transport), the researchers recorded information about the patients being transported.
They compared the patients in both groups, and found (for example) that both groups had similar average ages, and similar percentages of females and smokers, and so on.
They also compared information about the transportation, and found (for example) that both groups had similar average flight times and flight distances.

One conclusion from the study was that 'Patients with STEMI transported by Standard-HEMS had longer transport times' (p.\ 1), but one limitation of the study was that:

> The patient cohorts received treatment by $2$ different care teams at two hospitals, which is a potential confounder despite similar baseline characteristics
>
> --- @data:Gunnarsson2017:helicopter, p.\ 5

In other words, the difference between hospitals and the staff may have been a confounding variable.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Observational studies *can* (and often do) have control groups.
Indeed, one specific type of observational study is called a *case-control study*\index{Case-control study} (Sect.\ \@ref(Backward)).
However, individuals are *not allocated to the control group* by the researchers in observational studies, so the control and study groups may be very different, which may explain any differences in the outcome.
:::



<!-- ::: {.example #ConfoundingSmoking54 name="Managing confounding: observational study"} -->
<!-- @data:DollHill1950:Smoking studied smoking using a backward-direction study. -->
<!-- The control group (those without lung cancer) was chosen to include very similar individuals to those in the lung-cancer group, in terms of age and sex. -->
<!-- (That is, the numbers of females and males within each age group was very similar for those *with* and *without* lung cancer.) -->
<!-- ::: -->


<!-- ::: {.example #Manure name="Manage confounding: experimental study"} -->
<!-- An experimental study [@schroder2015maize] compared nitrogen (N) and phosphorus (P) concentrations in maize, for evenly-injected liquid manure and band-injected liquid manure. -->
<!-- As potential confounding variables, the researchers also recorded the average temperature and the precipitation (between May\ 1 and September\ 30) at each site. -->
<!-- ::: -->

<!-- Random allocation can be shown, in general, as in Fig.\ \@ref(fig:RandomAllocationGeneral). -->




Random *sampling* and random *allocation*\index{Confounding!random allocation}\index{Sampling} are different concepts (Fig.\ \@ref(fig:RandomAllocationSampling)), with different purposes, but are often confused:

* *Random sampling* impacts *external* validity.
  Its purpose is *finding individuals* to study, and is possible in both observational and experimental studies.
* *Random allocation* helps eliminate confounding issues, by distributing possible confounders across treatment groups, and is only possible in *experimental* studies.
  *Random allocation* impacts *internal* validity.
  Its purpose is *allocating treatments to individuals*, which does not occur in observational studies.



```{r RandomAllocationSampling, echo=FALSE, fig.cap="Comparing random allocation and random sampling.", fig.align="center", fig.height=3, out.width='75%'}

showStudyDesign(studyType = "TrueExp", 
                addIndividuals = TRUE, 
                addCompareText = TRUE, 
                addResearcherControl = FALSE, 
                addInternalValidityText = TRUE,
                addByResearchers = FALSE,
                addRandomAllocationText = TRUE, 
                addRandomSamplingText = TRUE, 
                addExternalValidityText = TRUE, 
                addSampling = TRUE)
```


<iframe src="https://learningapps.org/watch?v=poh7e35e222" style="border:0px;width:100%;height:500px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>
 


## Hawthorne effect and blinding individuals {#HawthorneEffect}
\index{Hawthorne effect}\index{Blinding!individuals}

People, and perhaps animals, may behave differently if they know (or think) they are being watched, which could compromise the internal validity of the study.
This is called the *Hawthorne effect*.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-binoculars-8-240.png" width="50px"/>
</div>


::: {.definition #HawthorneEffect name="Hawthorne effect"}
The Hawthorne effect is the tendency of individuals to change their behaviour if they know (or think) they are being observed.
:::


::: {.example #HawthorneHH  name="Hawthorne effect: observational study"}
@wu2018identifying examined hand hygiene (HH) of staff in a tertiary teaching hospital, using *covert* observers (observers not obviously watching the HH practices) and *overt* observers (observers obviously about watching the HH practices).
HH compliance was higher with overt observation ($78$%) than with covert observation ($55$%).
:::


The impact of the Hawthorne effect can be minimized by blinding the individuals in the experiment, so that:

* the individuals do not know that they are *participating* in a study; and/or
* the individuals do not know the *aims of the study*; and/or 
* the individuals do not know which *comparison group they are in*. 


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>

In *experimental* studies, *people* often know they are in a study, due to ethics requirements (Sect.\ \@ref(Common-Ethical-Issues)); they may not, however, know *which* treatment they have received.
In *observational* studies, individuals *may* or *may not* know they are being observed.
For instance, in an observational study where subjects' blood pressure is measured, subjects clearly know they are being observed, which has the potential to alter the subjects behaviour (for example, people become tense, called 'white-coat hypertension'; @pickering2002white).
As far as possible, efforts should be made to ensure that individuals do not know that they are being observed (the participants are *blinded*).


::: {.example #HawthorneHimalaya name="Hawthorne effect: experimental study"}
For the *Himalaya* study (Example\ \@ref(exm:HimalayaStudy)), the article reports that (p.\ 1033):

> The study was explained fully to the subjects, both verbally and in writing, and each gave their written, informed consent... 

That is, the subjects knew they were in a study, and knew the aims of the study, so the Hawthorne effect may influence the results in this study.
However, the subjects did not know *which* diet they were given.
:::


::: {.example #HawthorneFruitVege name="Hawthorne effect: experimental study"}
People are more health-conscious if they know they will be examined regularly.
For example, a study aiming to increase fruit and vegetable intake in young adults [@clark2019educational] noted that the observed increases in intake 'could be explained by the Hawthorne effect' as they 'know they are being observed...'. (p.\ 96).
:::


::: {.example #HawthorneHealth name="Hawthorne effect: observational study"}
During the COVID-19 lockdowns in Denmark, @olesen2021we observed adults entering a large mall in Copenhagen 'while pretending to do something else' (p.\ 1).
They noticed that (p.\ 1)

> Almost all subjects [$340/345$ ($99$%)] wore a personal protective face mask, but only $141$ ($41$%) made use of the hand sanitizer.

Both masks and use of hand sanitizer were recommended by the Danish Health Authority, but the adherence to the two safety measures were markedly different.
The authors surmised that (p.\ 1):

> As no subjects were aware that they were being observed [...] wearing a face mask corresponded to being observed continuously by other customers and staff during a visit to the mall. 
> In contrast, hand hygiene takes moments to perform, and no one can see whether or not it has been done.
> Thus, the Hawthorne effect may explain why almost all subjects wore a face mask, which is very visible, whereas only $41$% performed hand hygiene. 
:::


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-photomix-company-216729.jpg" width="200px"/>
</div>


## Observer effect and blinding researchers {#ObserverEffect}
\index{Observer effect}\index{Blinding!researchers}

Perhaps surprisingly, researchers' expectations or hopes may unconsciously influence how the researchers interact with the individuals and record observations.
In addition, this may (unconsciously) influence the behaviour of the individuals in the study.
This is called *observer effect*.
(In experiments, it is sometimes called the *experimenter effect*.)
This could compromise the internally validity of the study.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-idea-10-240.png" width="50px"/>
</div>


::: {.definition #ObserverEffect name="Observer effect"}
The observer effect occurs when the researchers unconsciously change their behaviour to conform to expectations because they know what values of the explanatory variable apply to the individuals.
This may then cause the *individuals* to change their behaviour or reporting also.
:::


The impact of the observer effect can be minimized by blinding the researchers, so that they do not know which treatments the individuals are receiving.
The researchers *giving* the treatment and the researchers *evaluating* the treatment can both be blinded, by using a third party.
For example, the researchers may give an assistant two drugs, labelled\ A and\ B.\spacex
The assistant administers the drug and evaluates the participants' response to the treatments.
Later, the assistant tells the researchers whether Drug\ A or Drug\ B performed better, but only the researchers know which drugs the labels\ A and\ B refer to (Fig.\ \@ref(fig:BlindingThirdParty)).


```{r, BlindingThirdParty, echo=FALSE, fig.align="center", fig.cap="Using a third party to avoid the observer effect.", fig.height=3, fig.width=8, out.width='85%'}
showStudyDesign(studyType = "TrueExp", 
                addIndividuals = TRUE, 
                addThirdParty = TRUE)    
```



::: {.example #ObsEffectyPain name="Observer effect: experimental study"}
@seo2020role examined the impact of an injection to alleviate post-operative umbilical pain, and stated (p.\ 392):

> ...the postoperative pain scores were gathered by a nurse practitioner who was blinded to the usage of bupivacaine to avoid observer-expectancy bias [i.e., the observer effect].
:::


The observer effect does not just apply to situations with *people* as individuals.


::: {.example #CleverHans name="Observer effect"}
`r if (knitr::is_latex_output()) {
   'Clever Hans'
} else {
   "['Clever Hans'](https://en.wikipedia.org/wiki/Clever_Hans)"
}`
was a horse that seemed to perform simple mental arithmetic.
By using an experiment where the people interacting with the horse were blinded, Carl Stumpf realised that the horse was responding to involuntary (and unconscious) cues from the trainer.

The same effect has been observed in narcotic sniffer dogs [@bambauer2012defending], who may respond to their handlers' unconscious cues.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The *observer effect* is when the researcher *unconsciously* influence the individuals, and are not aware it is occurring.
*Intentionally* influencing the individuals is fraud.
:::



The observer effect can impact observational as well as experimental studies.
For example, consider a study measuring the blood pressure of smokers and non-smokers [@verdecchia1995cigarette].
This study is observational (individuals cannot be allocated to be a smoker or non-smoker), but if the researchers *know* if an individual is a smoker when they measure blood pressure, then the observer effect could still impact the results (recalling that the observer effect is an *unconscious* effect).
For example, the researchers may *expect* smokers to have a high blood pressure.

The observer effect could be managed by *first* measuring the blood pressure, and *then* asking if the individual was a smoker or not.
That is, the researchers may be *blinded* to whether or not the subject is a smoker when they measure blood pressure.
This may only be partially successful; the researcher may see the subject carrying cigarettes, or can smell smoke on their breath, for example.
Nonetheless, since it may prove at least partially successful and is easy to implement, this strategy should form part of the research design.


::: {.example #ObsEffectObs name="Observer effect: observational study"}
@zimova2020using took photos of snowshoe hares, at various stages of moulting and in various environmental conditions.
Eighteen independent observers were asked to rate the moult stage from the photographs (p.\ 4): 

> ... images were randomly named and sorted, with the dates [...] removed to minimize observer expectancy bias [i.e., the observer effect].
:::


Blinding the observer is not always possible, but should be used when possible to improve the internal validity of the study.


::: {.exampleExtra data-latex=""}
A study of the scats of gray wolves was used to study their diet [@SpauldingScats].
A scat analysis is where humans examine the scat of carnivores to determine the prey.
However, the accuracy of the results was questioned, due to 'perpetuation of the assumption that wolf scats contain only $1$\ prey item/scat' (p.\ 949).

The observers might be seeing what they expect to see: that "wolf scats contain only $1$\ prey item/scat".
:::



<iframe src="https://learningapps.org/watch?v=puedghp1c22" style="border:0px;width:100%;height:500px" allowfullscreen="true" webkitallowfullscreen="true" mozallowfullscreen="true"></iframe>



## Placebo effect, controls, objective data, and blinding {#PlaceboEffect}
\index{Placebo effect}\index{Blinding!individuals}\index{Control group}

Perhaps surprisingly, individuals in a study may report effects of a treatment, even if they have not received an active treatment.
This could compromise the internally validity of the study.
This is called the *placebo effect*, which generally only impacts people as individuals.


::: {.definition #PlaceboEffect name="Placebo effect"}
The placebo effect occurs when individuals report perceived or actual effects, despite not receiving an active treatment.
:::


For example, people who attend therapy expect a positive outcome; this expectation may result in temporary or subjective (or sometimes even real) improvements in their condition.
This is the placebo effect.

To manage the placebo effect, researchers should record *objective*\index{Response variable} data rather than patient-reported outcomes when possible [@enck2013placebo].
In addition, *blinding* the individuals and the researchers may help manage the placebo effect, as then the individuals cannot know which group they are in.


::: {.example #PlaceboColours name="Placebo effect"}
Three active pain relievers were compared to different-coloured placebo [@data:Huskisson1974:placebo] in $22$ patients.
The most pain relief was experienced by those taking *red* placebos (Fig.\ \@ref(fig:Placebos)), who experienced even more pain relief than those given true pain relievers.
Note that the outcome is subjective: a *patient*-reported outcome.\index{Response variable!subjective}
:::


```{r Placebos, echo=FALSE, fig.align="center", out.width='65%', fig.width=5.75, fig.height=3.5, fig.cap="Pain relief, for various pain relief medicine and placebos."}
data(Placebos)

par( xpd = TRUE,   # Allows plotting outside plot area
     mar = c(4, 4, 4, 4) + 0.1 )  # DEFAULT: c(5, 4, 4, 2) + 0.1
	 
plot( c(0, 2.75) ~ range(Time), 
      data = Placebos,
      las = 1, 
      type = "n", 
      axes = FALSE,
      main = "Average pain relief for various medications",
      xlab = "Time (hours)", 
      ylab = "Pain relief score")
axis(side = 1)
axis(side = 2,
     las = 1,
     at = seq(0, 2, by = 0.5))
box()

# abline seems to go outside margins...? Because of xpd?
lines( x = c(0, 6.3),
       y = c(1, 1), 
       lty = 2,
       col = "grey")
lines( x = c(0, 6.3),
       y = c(2, 2), 
       lty = 2,
       col = "grey")
mtext(" Moderate\n relief",
      side = 4,
      at = c(5.75, 2),
      las = 1,
      adj = 0,
      cex = 0.9)
mtext(" Slight\n relief",
      side = 4,
      at = c(5.5, 1),
      las = 1,
      adj = 0,
      cex = 0.9)

lines( Asp ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       col = "black", 
       lty = 1,
       lwd = 2)

lines( Placebo ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       col = "orange", 
       lty = 3,
       lwd = 2)

lines( PlaceboRed ~ Time, 
       data = Placebos,
       type = "b",
       pch = 19,
       cex = 0.5,
       lty = 2,
	     col = "red", 
       lwd = 2)

legend("top", 
	col = c("red", 
	        "black", 
	        "orange"), 
	lwd = 2, 
	lty = c(2, 1, 3),
	bty = "n",
	ncol = 2,
	#horiz = TRUE,
	legend = c("Red placebos    ", # Extra spaces to separate the two columns of the legend a bit more
	           "Aspirin", 
	           "All Placebos"))
# Add initial point at t = 0, as all lines start there and last plot overtakes the colour
points(x = 0,
       y = 0,
       pch = 21,
       bg = "white",
       col = "black")
```


Since the placebo effect is concerned with individuals response to *allocated treatments*, it is not directly relevant to observational studies.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-help-3-240.png" width="50px"/>
</div>



::: {.example #HimalayaPlacebo name="Placebo effect"}
In the *Himalaya* study, the individuals 'were not told the identity of the test cereal in the foods provided' (@data:Bird2008:wholegrain, p.\ 1033).
The subjects were blinded to the diet they were exposed to.
However, some may *think* they are on the refined cereal or *Himalaya* diet, and respond accordingly (perhaps unconsciously).
The use of the refined cereal was acting as a control (Def.\ \@ref(def:Control)).
Researchers measured faecal weight, an *objective* outcome, to minimise the placebo effect.
:::


:::{.exampleExtra  data-latex=""}
A study of placebos [@data:Waber2008:Placebo] gave half the subjects a placebo, but told them the pill was an expensive (implying 'effective') pain killer.
The other half were also given a placebo, but were told the pill was a discount (implying 'less effective') pain killer.
About $85$% of participants in the first group reported a pain reduction, yet only $61$% in the second group reported a pain reduction.
Remember: *both* groups actually received a placebo!
Again, 'pain relief' is subjective.
:::


## Carry-over effect and washouts {#CarryOverEffect}
\index{Carry-over effect}\index{Washouts}

In the *Himalaya* study (Example\ \@ref(exm:HimalayaStudy)), the diet is a *between-individuals* comparison: one group of patients was given the refined cereal diet (the control), and a different group of people was given *Himalaya 292*.
The study *also* used a *within-individuals* comparison: each person in the study was actually placed on both diets at different times.

Suppose all patients spent four weeks on the *Himalaya 292* diet, then the next four weeks on the refined cereal diet.
Potentially, the first diet could still be impacting the subjects' faecal weight for a little while after stopping the first diet.
This could compromise the internally validity of the study.
This is an example of the *carry-over effect*: when the influence of one treatment or condition on the response variable carries over to influence the value of the response variable for next treatment or condition.
The carry-over effect is only a concern for *within-individuals* comparisons.


<div style="float:right; width: 75px; padding:10px">
<img src="Pics/iconmonstr-chart-21-240.png" width="50px"/>
</div>


::: {.definition #CarryoverEffect name="Carryover effect"}
The carry-over effect occurs when the influence of one treatment or condition on the response variable influences the response variable for subsequent treatments or conditions.
:::


The impact of the carry-over effect may be minimized by using a *washout* or similar between treatments or conditions.
For example, after tasting a food sample, participants may rinse their mouth with water before tasting another food sample.
For the *Himalaya* study, the participants could spend two weeks on their usual (before-study) diet, before starting each of the diets in the study.
This is called a *washout period*.


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-gil-goldman-4268507.jpg" width="200px"/>
</div>


::: {.example #HimalayaCarryOver name="Carry-over effect: experimental study"}
In the *Himalaya* study, 'there was no washout period' (@data:Bird2008:wholegrain, p.\ 1033) since the response variable was only recorded after individuals spent four weeks on each diet.
Since faecal weight was not measured until the *end* of the four week periods, the carry-over effect is essential irrelevant.
:::


<!-- ::: {.example #HimalayaWashout name="Carry-over effect"} -->
<!-- An engineering study [@miller2019behavioral] examined drivers' exposure to lane-keeping systems on their driving performance. -->
<!-- Subjects were exposed to a driving simulation that used a lane-keeping system, and then to a driving simulation without using a lane-keeping system. -->
<!-- The researchers found that driving performance was impacted when drivers moved from a simulation *with* a lane-keeping system to one *without* a lane-keeping system. -->
<!-- ::: -->


::: {.exampleExtra  data-latex=""}
In @jaskiewicz2020chest, student paramedics performed chest compression in real-life (RL), and also using virtual reality (VR).
Researchers were assessing the relaxation percentage of the students while undertaking the compressios (a relaxation percentage of about $50$% is ideal).

When used by itself, the VR method produced an average relaxation percentage of $45.5$%.
However, when the RL method was used first, and then followed by the VR method, the average VR relaxation method percentage was $74.7$%.

The response of the individuals was different depending on whether the RL method was used first.
This is an example of the carry-over effect.
:::


Sometimes, in experimental studies, researchers can *randomly allocate* the *order* in which the treatments are used (a *cross-over study*).\index{Study types!crossover studies}
That is, some participants start by spending four weeks on the *Himalaya 292* diet, then four weeks on the refined cereal diet; meanwhile, other participants start by spending four weeks on the refined cereal diet, then four weeks on the *Himalaya 292* diet.


::: {.example #HimalayaCarryOver2 name="Carry-over effect"}
In the *Himalaya* study (Example\ \@ref(exm:HimalayaStudy)), the subjects were allocated randomly to whether they began the study on the *Himalaya 292* diet *or* the refined cereal diet.
:::


::: {.example #ParamedOrder name="Washout periods: experimental study"}
@data:MacDonald:Resuscitation required paramedics to conduct eight different tasks (such as electrical defibrillation and intravenous cannulation).
Each of the $16$ paramedics began the series of tasks at a random task, to mitigate the carry-over effect.
A washout period between tasks (i.e., a rest time) was also used.
:::


The carry-over effect is a possible compromise to internal validity in observational studies involving a within-individuals comparison.
However, since treatments are *not allocated* in observational studies, carry-over effects may be difficult to prevent, as washouts cannot be *imposed*, and the order of the conditions cannot be imposed.
However, *observing* individuals exposed to Condition\ A then Condition\ B, and other individuals exposed to Condition\ B then Condition\ A, may be possible.


::: {.example #CarryoverObs name="Carry-over effects: observational study"}
@norris2005carry studied the carry-over effect in ecological observational studies of animals (p.\ 181):
  
> ...individuals occupying poor quality winter habitat may experience reduced reproductive success the following breeding season when compared to individuals occupying high quality winter habitat.
:::


## Describing blinding {#DescribingBlinding}
\index{Blinding!descriptions}\index{Blinding}

*Blinding* occurs when those involved in the study do not know information about the study.
*Individuals* in the study may be blinded (to help manage the Hawthorne effect) to 

* whether they are *involved in a study*;
* the *aims of the study* in which they are participants; and/or 
* *which comparison group* they are in.

The *researchers* and the *analysts* can be blinded to which comparison groups apply to the individuals (to help manage the observer effect). 

When blinding is used in as many ways as possible, the internal validity of the study is increased and bias reduced.
However, when people are the individuals, ethics requirements may mean that they need to know they are in a study (especially if the study is experimental), and the purpose of the study.

If *only* the individuals are blinded to the comparison groups, the study is called *single blind*.\index{Blinding!single}
If *both* the researchers and participants are blinded to the comparison groups, the study is called *double blind*.\index{Blinding!double}
If the researchers, participants *and* the analyst are blinded to the comparison groups, the study is sometimes called *triple blind*.\index{Blinding!triple}
Rather than using these terms, explicitly stating who or what is blinded is clearer.

Blinding should be considered in all studies when possible (it is *not* always possible).
*Blinding participants does not just apply to people*; it also may apply to animals (Example\ \@ref(exm:CleverHans)).


::: {.example #BlindingCowpea name="Double-blinding"}
@bulte2014behavioral compared yields from modern and traditional cowpea crops in Tanzania.
The two seed types ('traditional' and 'modern') were made similar in appearance so the farmers were blinded to which group they were in (control or treatment).
The seed type would eventually become obvious as the crop grew, but 'key inputs were already provided' by then (p.\ 817).
:::


In observational studies, blinding individuals *may* be (but is not always) easier than in experimental studies (Sect.\ \@ref(HawthorneEffect)).
Blinding the researchers may be difficult, since the researchers need to record the value of the explanatory variable.


<!-- ::: {.example #BlindingDogs  name="Blinding in observational studies"} -->
<!-- In a study of dogs with chronic pancreatitis (CP), the researchers acquired abdominal ultrasounds and pathology results of each dog. -->
<!-- The authors report that the researchers conducting the ultrasounds were not blinded (@watson2010observational, p.\ 969). -->
<!-- However: -->

<!-- > Tissue samples [...] were obtained from all dogs and re-cut sections were reviewed by one of the authors (PJW) with the help of a veterinary pathologist  -->
<!-- > (AJR or TJS), all blinded to the clinical details of the case, but aware that CP was suspected in each dog... -->

<!-- This study clearly explains which parts of the study were blinded, and which were not. -->
<!-- ::: -->


::: {.example #BlindingGymnasts  name="Blinding: observational studies"}
@emerson2010ultrasonographically studied Achilles tendinopathy in gymnasts, by comparing $40$ elite gymnasts with $41$ similar controls who were non-gymnasts.
The authors state (p.\ 38):

> Although the primary investigator was blind to the clinical status of the subjects, there was no blinding to whether each subject was in the gymnast or control group during image collection [...] 
> However the examiner was blinded to both the clinical state and group of each subject when the images were reviewed. 

The paper clearly explains who was blinded and to what parts of the study they were blinded.
:::


## Recording extraneous variables {#RecordExtraneous}
\index{Variables!extraneous}

One way to design a quality study is to record information about many (potential) extraneous variables.
Various reasons for doing this have been given:

* To evaluate *external validity* to determine if the sample is representative of the population (Sect.\ \@ref(Representative-samples)), by comparing the sample and population. \tightlist
* To improve *internal validity*, by helping to manage confounding:

  * by avoiding lurking variables (Sect.\ \@ref(ExtraneousVariables)).\tightlist
  * by determining if the comparison groups are similar (Sect.\ \@ref(ManagingConfounding)).
  * by using the information in analysis (Sect.\ \@ref(ManagingConfounding)). 


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Record the values of all extraneous variables that may be important in the study*!
:::


:::{.example #ConfoundingChildbirth name="Poor internal validity"}
In the 1800s, Semmelweis recorded mortality rates of women after childbirth over many years [@dunn2005ignac] at two clinics:

* In Clinic\ 1, with male doctors delivering babies: $9.9$%.
* In Clinic\ 2, with female midwives delivering babies: $3.4$%.

Was the difference in mortality rate (the outcome) due to the sex of the person delivering the babies (the comparison)?

One possible confounder was the clinic; however, the clinic was eliminated as an explanation.
For example, Clinic\ 2 was actually *more* overcrowded than Clinic\ 1, and the climate was similar for both clinics.

However, an important *lurking variable* was present.
In the 1800s, the benefits of hand washing were not understood, nor commonplace.
Many (male) doctors performed autopsies immediately before delivering babies, without washing their hands between procedures.
In contrast, autopsies were not performed by the (female) nurses.

The lurking variable was 'whether the baby was delivered by someone with clean hands', which was related to the mortality rate *and* to the sex of the person delivering the baby.
The female midwives had clean hands, and hence the mortality rate was (relatively) low.
The male doctors did *not* have clean hands, and hence the mortality rate was high.

After instituting hand washing for doctors, the mortality rate in Clinic\ 1 reduced to a rate similar to that in Clinic\ 2.
::: 

\index{Research design!internal validity|)}


## Chapter summary {#Chap7-Summary}

Designing effective studies (Fig.\ \@ref(fig:DesignConsiderations)) requires researchers to *manage or minimise confounding* where possible, by *restricting* the study to certain groups; *blocking* individuals into similar groups; through special *analysis* methods; and/or through *random allocation* of the units of analysis.
Random allocation is only possible for experimental studies.

Well-designed studies also try to manage the *Hawthorne effect* (e.g., by blinding *participants*); the *observer effect* (e.g., by blinding the *researchers*); the *placebo effect* (experimental studies only; e.g., by using controls, objective outcomes and blinding subjects); and the *carry-over effect* (e.g., by using a washout, or randomly allocating the treatment order).
Using these measures, when possible, ensures that the results and conclusions from our studies are correctly interpreted.


`r if (knitr::is_html_output()){
  'The following short video may help explain some of these concepts:'
}`

<div style="text-align:center;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/eic_LjXT4qc" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture"></iframe>
</div>


Often, however, not all of these strategies can be used.
For instance, people often know they are involved in an experimental study, so the Hawthorne effect may impact conclusions.
In these cases, the possible impacts should be minimized as far as possible, and then the likely impact on the conclusions discussed.
The impact of these issues are often reported as *limitations* in a journal article (Chap.\ \@ref(Interpretation)).


(ref:DesignConsiderations-Caption) Design considerations for designing studies. Note: lurking variables become confounding variables when recorded in the study, and so can be managed as a confounding variable. The arrows indicate the main design strategies to (perhaps partially) manage the indicated potential bias. Not all strategies are possible for every study.

```{r DesignConsiderations, echo=FALSE, fig.cap='(ref:DesignConsiderations-Caption)', out.width='95%', fig.align="center",  fig.width=7.0, fig.height=4.5}
source("R/showDesignConsiderations.R") 
showDesignConsiderations()
```




::: {.example #DesignExample name="Research design"}
@cross2019impact (p.\ 3) compared chest compressions by student paramedics using dominant and non-dominant hands, and stated:

> ...participants were allocated randomly to one of two groups: 'dominant hand on chest' or 'non-dominant hand on chest'. 
> Group allocation was determined by a computer-generated randomisation schedule...

The participants were blinded to the *purpose* of the study, but not to which group they were allocated.
The analyst was also blinded to the group allocations.
This study used many good design features.
:::



## Quick review questions {#Chap7-QuickReview}

::: {.webex-check .webex-box}
A study [@doosti2016development] wanted to determine the relationship between the depth of bruising on apples and the size of the impact force.
The researchers purposefully hit apples with three different *forces* ($200$, $700$ and $1200$\mJs) to inflict bruises on the apples.
The researchers then recorded the *depth* of the bruising.
The study was conducted separately for three different *regions* of the apple (lower; middle; upper), and each apple was only used once.

1. What is the *response variable*? \tightlist
`r if( knitr::is_html_output() ) {longmcq( c(
	"The force used on the apples",
	answer = "The depth of the bruising",
	"The location of the bruising"))}`
2. What is the *explanatory variable*?
`r if( knitr::is_html_output() ) {longmcq( c(
	answer = "The force used on the apples",
	"The depth of the bruising",
	"The location of the bruising"))}`
`r if (knitr::is_html_output()) '<!--'`  
3. How would the variable 'location of the bruising' be classified?  
   a. A confounding variable: it may be related to the explanatory variable only.
   b. A confounding variable: it may be related to the response variable and explanatory variables.
   c. An extraneous variable: it may be related to the response variable only.
   d. A lurking variable: we don't know how it might be related to the response and explanatory variables.
`r if (knitr::is_html_output()) '-->'`
`r if (knitr::is_latex_output()) '<!--'`
3. How would the variable 'location of the bruising' be classified?  
`r longmcq( c(
	"A confounding variable: it may be related to the explanatory variable only",
	"A confounding variable: it may be related to the response variable and explanatory variables",
	answer = "An extraneous variable: it may be related to the response variable only",
	"A lurking variable: we don't know how it might be related to the response and explanatory variables"))`
`r if (knitr::is_latex_output()) '-->'`
4. True or false: The researchers could minimise the effects of confounding by using potential confounding variables in the analysis.  \tightlist
`r if( knitr::is_html_output() ) {torf( TRUE)}`
5. True or false: The researchers could use random allocation of the treatments to the apples to minimise confounding.  
`r if( knitr::is_html_output() ) {torf( TRUE)}`
6. True or false: The *carry-over* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
7. True or false: The *Hawthorne* effect is likely to be a big problem in this study. 
`r if( knitr::is_html_output() ) {torf( FALSE)}`
8. True or false: The *placebo* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
9. True or false: The *observer* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE )}`
:::


## Exercises {#DesigningExperimentsExercises}

Answers to odd-numbered exercises are available in App.\ \@ref(Answers).

`r if( knitr::is_latex_output() ) "\\captionsetup{font=small}"`

::: {.exercise #DesignTrueFalse}
Are the following statements *true* or *false*?

1. Experimental studies *must* use random samples. \tightlist  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
2. An experimental study *must* blind the researchers.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
3. Only observational studies can manage the observer effect
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
4. Experimental studies *must* use a control group. 
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
5. Using random samples is important in observational studies as a way to manage confounding.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
:::


::: {.exercise #DesignTrueFalse2}
Which of the following statements are true?

1. Observational studies cannot have a control group.\tightlist
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
2. Only experimental studies can use random allocation to avoid confounding
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
3. An experimental study *must* blind the participants.  
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
4. Only experimental studies can use random sampling
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
5. In experimental studies, the treatments *must* be allocated by the researchers.  
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
:::


::: {.exercise #DesignExpImproveIV}
Which of the following can be used to improve internal validity in *experimental* studies?

:::: {.webex-check .webex-box}
* Blinding the individuals.  \tightlist
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Using a control group.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Using special methods of analysis.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Randomly allocating treatments to groups.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Blinding the researchers.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Using random samples.
`r if( knitr::is_html_output() ) {mcq( c("Yes", answer = "No"))}` 
::::
:::



::: {.exercise #DesignObsImproveIV}
Which of the following can be used to improve internal validity in *observational* studies?

:::: {.webex-check .webex-box}
* Blinding the individuals.  \tightlist
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Using a control group.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Using special methods of analysis.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Randomly allocating treatments to groups.
`r if( knitr::is_html_output() ) {mcq( c("Yes", answer = "No"))}` 
* Blinding the researchers.
`r if( knitr::is_html_output() ) {mcq( c(answer = "Yes", "No"))}` 
* Using random samples.
`r if( knitr::is_html_output() ) {mcq( c("Yes", answer = "No"))}` 
::::
:::


::: {.exercise #ResearchDesignHawthorneEffect}
Is the Hawthorne effect only a (potential) issue for experiments.
Explain.
:::


::: {.exercise #HawthorneTeeth}
@lorenz2019effect compared the efficacy of a new type of toothpaste.
Participants were given either a new or an existing toothpaste formulation, and evaluations of plaque remaining on the teeth were taken.
All participants knew they were being assessed after brushing.

Would the Hawthorne effect likely impact the internal validity of this study?
Explain.
:::


::: {.exercise #ResearchDesignObsPollen}
A study compared the average amount of pollen returned to the hive per bee, for two types of native Australian bees: yellow and black carpenter bees, and green carpenter bees. 
In the study, the researchers also recorded the size of the hive, among other things.
*Why* did they do this?
`r if( knitr::is_html_output() ) {longmcq( 
   c("To minimize the impact of the Hawthorne effect",
     "To ensure external validity",
     "Because the size of the hive is the explanatory variable",
     answer = "In case the size of the hive is a confounding variable") )}` 
:::


::: {.exercise #ResearchDesignSeptic}
In a study to treat septic shock, @hwang2020combination used two study groups of size $n = 58$ each: one group received the treatment of interest (intravenous infusion of vitamin\ C and thiamine) and the other group received intravenous saline.

Explain why the researchers gave saline to $58$ subjects, when it has no chance of successfully treating septic shock.
Is this ethical?
:::


::: {.exercise #DesignExpWeightLoss}
Consider a study comparing the average weight loss for patients who are *instructed* to do about $30$\mins of exercise a day (Group\ A), to patients who are instructed to do about $60$\mins of exercise a day (Group\ B).
Which of the following statements are true?

1. This is an experimental study.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
2. The extraneous variable is the amount of exercise per day (in hours).\tightlist
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
3. The response variable is the weight loss for each person.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
4. The explanatory variable is whether the patient performs about $30$ or $60$ minutes of exercise per day.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
5. The response variable is the *average* weight loss.
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
6. The explanatory variable is the amount of exercise the patient does per day (in hours).
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
7. Age is likely to be a lurking variable.
`r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
8. Age is an extraneous variable.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
9. Age is likely to be a confounding variable.
`r if( knitr::is_html_output() ) {torf(answer = TRUE)}`
10. Which (if any) of the following are possible *confounding* variables?

    * The sex of the patients. \tightlist
   `r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
    * The initial weight of the patients.
   `r if( knitr::is_html_output() ) {torf(answer = TRUE)}` 
    * The names of the patients.
   `r if( knitr::is_html_output() ) {torf(answer = FALSE)}` 
:::




::: {.exercise #ResearchSmokingAlfresco}
@data:Stafford2010:Alfresco studied smoking in alfresco restaurants in two cities in Western Australia.
The concentration of particulate matter with a diameter smaller than or equal to $2.5$ (per cubic metre of air) was recorded (PM~$2.5$~) from $12$ cafes and $16$ pubs.
The researchers were interested in the relationship between PM~$2.5$~ and the number of smokers.
They also recorded the wind strength (calm; light breeze; windy) and the amount of cover (fully open; overhead cover only; overhead cover and enclosed sides).

1. Is this an experimental or observational study?
1. What are the response and explanatory variables?
1. What are the extraneous variables, if any?
1. Is blinding the individuals possible?
1. Is random allocation possible?
:::


::: {.exercise #ResearchDesignSunscreen}
In a study of time spent applying sunscreen [@data:Heerfordt2018:sunscreen], the Aim was to 'determine whether time spent on sunscreen application is related to the amount of sunscreen used' (p.\ 117).
The study is described as follows (p.\ 118):

> The volunteers were asked to apply the provided sunscreen [...] the way they would normally do on a sunny day at the beach in Denmark [...]
> The volunteers wore swimwear during the whole session. 
> No other information was given. 
> Participants applied sunscreen behind a curtain and were not observed during application. 
> Measurements of time and sunscreen weight were made without the subjects' being aware of this.

1. Is this an experimental or observational study?
1. What are the response and explanatory variables?
1. The researchers also recorded age, height, weight and body surface area of each participant. 
   Why would they have done this?
1. The researchers also compared the average values of the response variable for males and females, and the average values of the explanatory variable for males and females. 
   Why would they have done this? 
1. What design features are evident in the quote?
:::


::: {.exercise #DesignExpParamedicsPills}
Paramedics were involved in a study to compare two treatments (Treatment\ A; Treatment\ B) for Post Traumatic Stress Disorder (PTSD), as randomly allocated to two groups of patients.

1. Is this an experimental or observational study?\tightlist
1. What would be the control group? 
`r if( knitr::is_html_output() ) {
   longmcq( c("The group receiving Treatment A",
              "A group of paramedics who do not have PTSD",
              "The group receiving Treatment B",
              "A group of paramedics not involved in the study",
              "A group of people with PTSD who are not paramedics",
              answer = "A group receiving a pill that looks just like Treatment A and B, but has no effective ingredient"))}`
`r if (knitr::is_html_output()) "<!--"`
   a. The group receiving Treatment\ A.
   b. A group of paramedics who do not have PTSD.
   c. The group receiving Treatment\ B.
   d. A group of paramedics not involved in the study.
   e. A group of people with PTSD who are not paramedics.
   f. A group receiving a pill that looks just like Treatment\ A and\ B, but has no effective ingredient.
`r if (knitr::is_html_output()) "-->"`
2. The patients did not know which treatment they received.
What is this called?
`r if( knitr::is_html_output() ) {
   longmcq( c("Blinding the researchers",
              "Double blinding",
              "Managing confounding",
              answer = "Blinding the participants"))}`
`r if (knitr::is_html_output()) "<!--"`
   a. Blinding the researchers.
   b. Double blinding.
   c. Managing confounding.
   d. Blinding the participants.
`r if (knitr::is_html_output()) "-->"`

3. What is the purpose of blinding the participants?
`r if( knitr::is_html_output() ) {
   longmcq( c("To ensure that researchers did not unintentionally influence the results",
              answer = "To ensure that participants did not change their behaviour because of the treatment they were receiving",
              "To manage confounding"))}`
`r if (knitr::is_html_output()) "<!--"`
   a. To ensure that researchers did not unintentionally influence the results.
   b. To ensure that participants did not change their behaviour because of the treatment they were receiving.
   c. To manage confounding.
`r if (knitr::is_html_output()) "-->"`
:::


::: {.exercise #ResearchTasteOfWater2}
A scientist is testing whether tap water tastes the same as bottled water in a taste test (based on @teillet2010consumer).
She provides people with a plastic cup of either bottled or tap water, and she asks them to give a rating of the taste on a scale of $1$ (terrible) to $5$ (fantastic).
The RQ is:

> For university students, is the taste of tap water better than the taste of bottled water?

This RQ needs some clarification, but you decide to answer this question using an *experiment*.
Describe what these might look like for this study, and which are feasible: 
random allocation;
blinding;
double blinding;
control;
carry-over effect;
finding a random sample.

What potential problems can you identify with the research design?

:::


::: {.exercise #ResearchDesignTasteOfWater}
Consider this RQ (based on @teillet2010consumer): 'Among university students, is the taste of tap water different than the taste of bottled water?'

You want to answer this question using an *observational study*.
Describe what these might look like for this study, and which are feasible: 
random allocation;
blinding;
double blinding;
control;
carry-over effect;
finding a random sample.
:::



::: {.exercise #ResearchDesignFertilizer}
A scientist compares the effects of two types of fertiliser on the yield of tomatoes (based on @klanian2018integrated).
He plants tomato seedlings, and fertilises with Fertiliser\ I, and later records the yield of tomatoes.
He then immediately plants more tomato seedlings in the same field, fertilises with Fertilizer\ II, and measures the yield of tomatoes.

What potential problems can you identify with the research design?
:::




::: {.exercise #ResearchDesignDust}
@data:skulberg:dust compared two office-cleaning methods (p.\ 72):

> The participants were randomly allocated to an intervention group or a control group using group level matching by sex, level of irritation symptom index, and allergy status [...]
> The participants and the field researchers were blinded to the group status of the participants [...]
> the cleaning was done in the evening after the employees had left the building.

The researchers then compared the change in nasal congestion for the two groups (intervention: 'a comprehensive cleaning of all surfaces'; control: 'only a superficial cleaning'), finding only small differences between the two groups.
In the analysis, the researchers incorporated age and sex of the office workers.

1. How did the researchers manage confounding?
1. What other design features are evident from the quote?
1. What is the response variable?
1. What is the explanatory variable?
1. What are the extraneous variables?
:::


::: {.exercise #ResearchDesignFormwork}
*Formwork* is used in construction with reinforced concrete, and can be labour intensive.
@mine2015observational examined the relationship between the floor area of the building (in m^2^ per storey) and the number of hours of labour needed for constructing the formwork (in person-minutes per storey).
The researchers also recorded the average age of the workers (in years); the average years of experience of the workers (in years); and the storey height (in meters) for each of $n = 15$ multi-storey buildings in the study.

Two observers recorded the labour time by observing workers from the start to the end of the work.

1. What is the *explanatory variable*? \tightlist
`r if( knitr::is_html_output() ) {longmcq( c(
	answer = "Floor area",
	"Hours of labour",
	"Average age of workers",
	"Average years of experience of workers",
	"Storey height"))}`
`r if (knitr::is_html_output()) "<!--"`
   a. Floor area.
   b. Hours of labour.
   c. Average age of workers.
   d. Average years of experience of workers.
   e. Storey height.
`r if (knitr::is_html_output()) "-->"`
1. What is the *response variable*?
`r if( knitr::is_html_output() ) {longmcq( c(
	"Floor area",
	answer = "Hours of labour",
	"Average age of workers",
	"Average years of experience of workers",
	"Storey height"))}`
`r if (knitr::is_html_output()) "<!--"`
   a. Floor area.
   b. Hours of labour.
   c. Average age of workers.
   d. Average years of experience of workers.
   e. Storey height.
`r if (knitr::is_html_output()) "-->"`
1. What *type* of description is appropriate for the variable 'Average age of the workers'?
`r if( knitr::is_html_output() ) {longmcq( c(
	"A confounding variable, since it is likely to be related to the explanatory variable only",
	"A confounding variable, since it is likely to be related to the response variable only",
	answer = "An extraneous variable, because it is likely to be related to the response variable only",
	"A lurking variable, since we don't know how it might be related to the response and explanatory variables"))}`
`r if (knitr::is_html_output()) "<!--"`
   a. A confounding variable, since it is likely to be related to the explanatory variable only.
   b. A confounding variable, since it is likely to be related to the response variable only.
   c. An extraneous variable, because it is likely to be related to the response variable only.
   d. A lurking variable, since we don't know how it might be related to the response and explanatory variables.
`r if (knitr::is_html_output()) "-->"`
1. What is the most likely way to manage confounding in this study?
`r if( knitr::is_html_output() ) {longmcq( c(
	"Restricting, the study to multi-storey buildings",
	"Blocking, by only studying unit blocks",
	answer = "Analysis, by using other recorded variables in the analysis",
	"Random allocation of workers to the building projects"))}`
`r if (knitr::is_html_output()) "<!--"`
   a. Restricting, the study to multi-storey buildings.
   b. Blocking, by only studying unit blocks.
   c. Analysis, by using other recorded variables in the analysis.
   d. Random allocation of workers to the building projects.
`r if (knitr::is_html_output()) "-->"`
1. True or false: The *carry-over* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. True or false: The *Hawthorne* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( TRUE)}`
1. True or false: The *placebo* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. True or false: *Observer* effect is likely to be a big problem in this study.  
`r if( knitr::is_html_output() ) {torf( FALSE )}`
:::




`r if( knitr::is_latex_output() ) "\\captionsetup{font=normalsize}"`


<!-- https://bmcoralhealth.biomedcentral.com/articles/10.1186/s12903-018-0588-1  About tooth brushing -->


<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to *Quick Revision* questions:**
**1.** Surface temperature at the bruise.
**2.** Depth of the bruising.
**3.** Extraneous: likely to be related to the response variable only.
**4.** True.
**5.** True.
**6.** False.
**7.** False.
**8.** False.
**9.** False.
:::
`r if (knitr::is_html_output()) '-->'`
