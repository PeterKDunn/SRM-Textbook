
# Reading and critiquing research {#Reading}

<!-- Introductions; easier to separate by format -->
```{r, child = if (knitr::is_html_output()) {'./introductions/37-Read-HTML.Rmd'} else {'./introductions/37-Read-LaTeX.Rmd'}}
```


<!-- Define colours as appropriate -->
```{r, child = if (knitr::is_html_output()) {'./children/coloursHTML.Rmd'} else {'./children/coloursLaTeX.Rmd'}}
```



## Introduction {#Chap36-Intro}


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-pixabay-258353.jpg" width="200px"/>
</div>


Scientific practice requires reading the research of others; that's how to stay up-to-date with the discipline and to keep learning.
Current practice and advances in every evidence-based discipline builds on the research, so being able to critique the research is important.
(A *critique* evaluates: identifying what is good, and what can be improved.)
Research is usually communicated in *journal articles* or, less formally, in *presentations* (Chap.\ \@ref(WritingResearch)).

At some time during your studies or employment, you will need to read research articles: 

* to understand current practices in your discipline; 
* to know *why* your discipline does things as it does; 
* to learn about new procedures and practices to be adopted;
* to critique the evidence for current or new practices; and 
* to identify open or unresolved questions in your discipline.

Understanding the language and concepts of research is important for understanding these articles, even if you will not be conducting your own research.

Reading research articles can be challenging.
Rather than reading articles thoroughly from start to finish, first read the *Abstract* (also called a *Summary*, or *Overview*) to obtain a useful overview of the whole article, without the details.
Then, read the *Conclusion*, which highlights the important findings.
Next, skim the rest of the article (perhaps focusing on graphs and tables of results).
Finally, if necessary, read the article for details.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Terminology varies widely in research (Sect.\ \@ref(LexicalAmbiguity)).
For example, *explanatory variables*\index{Variables!explanatory} can be called, among other terms, *independent variables*, *predictors*, *regressors*, *covariates* [@dunn2016learning].
Check the terminology being used if unsure!
:::


The six steps of the research process (Sect.\ \@ref(SixStepsOfResearch)) can be used as a guide to critiquing the research, though the expectations vary greatly between disciplines and between journals:\index{Research!six steps}

1. *Asking the question*:
   * What research question is the article answering?
   * Why is this RQ important?\index{RQ}
   * To what population will the results apply?
   * Are there important inclusion and/or exclusion criteria that apply?
   * What are the units of analysis\index{Units of analysis} and units of observation?\index{Units of observation}
   * How are important terms defined?
2. *Designing the study*:\index{Research design}
   * Is the study observational or experimental?
   * Is the study well-designed?
     What is not explained or clear?
   * How many individuals are in the study?
   * How was the sample obtained? 
     What are the implications for external validity?\index{External validity}
   * Is the study designed to maximize internal validity?\index{Internal validity}
   * What are the design limitations?
   * Are there ethical concerns?\index{Ethics}
   * What is the source of funding?
3. *Collecting the data*:
   * How were the data collected?\index{Data collection}
   * Are the necessary details provided so the study can be approximately replicated?
4. *Summarising the data*:
   * Is the data summary appropriate, complete and clear?
   * What does the data summary reveal about the data?
   * What do the tables and graphs reveal about the data and relationships?
5. *Analysing the data*:
   * What types of confidence intervals and/or hypothesis tests were used?
   * Is the analysis appropriate, accurate, valid and clear?
   * What do the results mean?
   * What software was used?
   * Are the results statistically valid?
6. *Reporting the results*:
   * What are the main conclusions, and how do they answer the RQ?
   * Are the conclusion consistent with the results?
   * Are the results accurate, appropriate and well-reported?
   * Are the results of practical importance?
   * Are the study limitations acknowledged, and their implications discussed? 
   * What other questions have emerged?


## Example: blue light and sleep {#ReadBlueLightExample}

The *Abstract* of a study of the impact of 'blue light' emitted by electronic devices on sleep [@randjelovic2023effect], slightly edited for clarity, appears below:

> The exposure of humans to artificial light at night... with predominant blue part of the visible spectrum is strongly influencing... sleep...\smallskip
>
> We hypothesized that reducing the amount of emitted blue light from screens of mobile phones during the night will increase sleep quality in our student population.\smallskip
>
> The aim [...] was to investigate the effect of reducing blue light from smartphone screen during the night on subjective quality of sleep among students of medicine.
> The target population was students of medicine aged $20$ to $22$ years old of both sexes. 
> The primary outcome of the study was subjective sleep quality, assessed by the Serbian version of the Pittsburgh Sleep Quality Index (PSQI).\smallskip
>
> The mean total PSQI score before intervention was $6.83\pm 2.73$ (bad), while after the intervention the same score was statistically significant reduced to $3.93 \pm 1.68$ (good)...\smallskip
>
> The study has shown that a reduction of blue light emission from LED backlight screens of mobile phones during the night leads to improved subjective quality of sleep in students...


As this is the *Abstract*, many details will be absent (but explained in the article itself).
Nonetheless, a lot can be learnt about the study from the *Abstract*:

* *Asking* the RQ:\index{Research question!relational}
  * This is a repeated-measures (paired) RQ: data are collected before and after the intervention from the same people.
  * The *population* is 'students of medicine aged $20$ to $22$ years old'.
  * The *units of analysis* and *observation* are the individual students in the study:\index{Units of analysis}\index{Units of observation}
    each person has a before and after measurement.
  * The outcome is the (average) subjective sleep quality, as measured by PSQI (the operational definition).\index{Definitions!operational}
* *Designing* the study:
  * The sampling method is not stated, but likely to be voluntary-response.
  * The sample size is not given in the Abstract.
* *Analyse* the data:
  * A quantitative variable is being compared *within* individuals, so a paired $t$-test is the likely method of analysis (Sect.\ \@ref(AnalysisPaired)).
* *Report the results*:
  * Means are given *before* and *after*, but no information on the *change* is given.
  * The numbers that follow the $\pm$ are not explained: are they confidence interval limits, standard deviations, IQRs, ranges, standard errors?
  * No $P$-values or confidence intervals for the change are given.

Reading more of the article obviously provides more information.


### Further details {#ReadFurtherDetails}

Further details revealed from reading the article include:

* The *population*\index{Population} comprises students of medicine from the University of Nis, Helsinki aged $20$ to $22$ (p.\ 336), so the results will only apply to these people.
  However, other students of a similar age are probably not substantially different in this regard.
  The results may not apply to older people (whose phone use, for instance, may be quite different).
* The *inclusion* criteria are 'owning and daily usage of mobile phone with Android operating system and AMOLED screen' (p.\ 336).\index{Inclusion criteria}
  This suggests that results may not apply to users of iPhones.
* The *exclusion* criteria are 'sleep disorders, usage of sedative drugs, psychoactive substances, usage of phone apps or glasses that reduce blue light during the night, recent stressful situations' (p.\ 336).\index{Exclusion criteria}
* The *response variable*\index{Variables!response} is the PSQI total score, which ranges from $0$ to $21$; the *Abstract* implies smaller scores are better.
* The *intervention*\index{Intervention} is the use of a 'free Android application Twilight [...] on mobile phones of participants [which] automatically decreases brightness and content of emitted blue color from the screen during the night time' (p.\ 336).
* Thirty students (p.\ 337) were used in the study (the study started with $37$ students; seven dropped out).\index{Drop outs}
* Results are 'presented as mean and standard deviation before and after intervention' (p.\ 337), so presumably the numbers in the *Abstract* after the $\pm$ are *standard deviations*.
* The method of analysis was a paired $t$-test (p.\ 337).
  The $P$-value for the $t$-test is $p < 0.0001$ (p.\ 337), so there is very strong evidence to support a change in mean PSQI.
* *Ethical approval*\index{Ethics} was granted (p.\ 336).
* The *funding* was from the Ministry of Education, Science and Technological Development, Republic of Serbia (p.\ 341), suggesting no conflicts of interest.
* The data and analysis details are not available, so the research is not completely *reproducible*.\index{Research!reproducibility}


### Strengths

Strengths of the study include:

* The researchers compared the students who *remained* in the study with those who *dropped out* of the study (Table\ 1); they found no evidence that those who dropped out and those who stayed were different on the variables studied (i.e., the drop outs did not introduce a bias).\index{Bias}
* The sample size of $n = 30$ suggests the $t$-test is *statistically valid*.\index{Statistical validity}
  The required sample size was estimated using software (p.\ 336).
* An excellent case-profile plot is shown of the data (their Fig.\ 1), and the data usefully summarised in their Table\ 2. 

The authors identify strengths of the study as (p.\ 341):

> ... being specific to investigate the impact of mobile phones to sleep quality, natural setting of the intervention...


### Limitations

Limitations of the study identified include:

* The study is conducted 'in complete dark room without additional light'; that is, a partially artificial environment, so the results may not be *ecologically valid*.\index{Ecological validity}
* Since 'each participant was informed about the detailed plan of the study...' due to ethics requirements,\index{Ethics} (p.\ 336) the participants were not blinded to being in a study, nor the purpose of the study.\index{Blinding}
  In addition, no *control group*\index{Control} was used (p.\ 337).
  That is, the *Hawthorne effect*\index{Hawthorne effect} may impact the results.
  This means the change in PSQI may have been because students knew they were in the study, and not due to the reduction in blue light.
  The use of a control group\index{Control} would have been useful.
* Participants for the study were chosen 'on voluntary basis'\index{Sampling!non-random!voluntary} (p.\ 336), so the sample was not a random sample.
  The study may not be *externally valid*,\index{External validity} but the students *in* the study probably would not be very different from students who *did not* volunteer for the study.
* Since the response variable (assessed using PSQI) is completed by participants completing a *subjective* questionnaire, the *placebo effect*\index{Placebo effect} may be of concern (using objective measures is better when possible).
* Participants completed the questionnaire pre-intervention, then 'used the app for one month period [and] at the end they completed PSQI once again'.
  This suggests that the *carry-over effect*\index{Carry-over effect} may be an issue, since no random allocation\index{Random allocation} was used to decide which situation was evaluated  first.
* Scores are only reported for *before* and *after* intervention, not for the *changes* themselves.
* No potential confounding variable\index{Variables!confounding} are identified.

The authors identify limitations\index{Limitations} of the study as (p.\ 341):\index{Limitations}

> ... lack of generalization to other population groups, the lack of control group, the very nature of questionnaire as subjective instrument, duration of intervention, difference in devices used as well as usage time, confounding by other light sources at night. 

These include the acknowledgement of potential *confounding variables*.\index{Variables!confounding}


## Chapter summary {#Read-ChapterSummary}

The six steps of research can be used as a scaffold for critiquing research articles.
Starting by reading the *Abstract* (or *Summary*) for an overview, then the *Conclusion*, and then skim the rest of the article (perhaps focusing on graphs and tables of results).
If necessary, read the article for details if needed.


## Quick review questions {#Read-QuickReview}


::: {.webex-check .webex-box}
Are these statements true or false?

1. The best way to read an article is to read the whole article thoroughly, from start to finish.\tightlist
`r if( knitr::is_html_output() ) {torf( FALSE)}`
1. The six steps of research are a useful scaffold for critiquing an article.
`r if( knitr::is_html_output() ) {torf( TRUE) }`
1. Critiquing an article means to find all the problems.
`r if( knitr::is_html_output() ) {torf( FALSE)}`
:::


## Exercises {#ReadExercises}

Answers to odd-numbered exercises are available in App.\ \@ref(Answers).

`r if( knitr::is_latex_output() ) "\\captionsetup{font=small}"`

::: {.exercise #ReadExerciseiPhoneStepCounts}
@duncan2018walk examined the accuracy of step counts, as recorded on iPhones.
The article states that participants

> ... were recruited through word of mouth and posters displayed around the [researcher's] university.
> Participants were eligible if they were ambulatory, $\ge 18$ years of age, and owned an iPhone 6 [...] or newer model.

1. How would you describe the sampling method?
   What is the implication?
2. How would you describe  the information given about the subjects needing to be ambulatory and 18 years of age or over?

Although $33$ participants were selected, the authors note some parts of the study used a smaller sample size because one subject lost their phone, while others chose to withdraw from the study.

3. Why did the authors discuss these changes in sample size for some parts of the study?

The article notes that previous studies have been able to:

> [...] demonstrate the accuracy of the iPhone pedometer function in laboratory test conditions. However, no studies have attempted to evaluate evidence [...] in the field.

4. Describe the issue that the authors raise with previous studies, using the language in this book.


5. Among many other things, the researchers compared the *mean difference* between the number of step counts recorded by manually counting steps (mean: $92.6$) and the iPhone-recorded number of steps (mean: $85.4$). 
   What statistical test would be appropriate?
6. What hypotheses are being tested?
7. While walking at $2.5$\kms.h^$-1$^, the above statistical test resulted in $t = 2.95$.
   What is the approximate $P$-value?
   Interpret the results.
8. The sample size for the part of the study mentioned above was $n = 32$. 
   Is the test statistically valid?
:::


::: {.exercise #ReadExerciseHeadphones}
@mohammadpoorasl2019prevalence studied the relationship between hearing loss, and headphone and earphone use among Iranian students, using a non-directional study.
The article states that:

> ... $890$ students were randomly selected from five schools at QUMS (Medicine, Dentistry, Nursing and Midwifery, Public Health, and Paramedical Sciences schools) using a proportional cluster sampling method...

Only $866$ of the $890$ students agreed to participated in the study; of these, $745$ used *ear*phones.
The participants completed a hearing test and a Hearing Loss Questionnaire (HLQ; values between $17$ and $34$; higher scores indicating more severe hearing loss).

1. What is the population?
2. Is this an observational or experimental study?
3. Critique the sampling method.
   What is the implication for interpreting the results of the study?

One question in the HLQ is:

> Does a hearing problem cause you difficulty when listening to TV or radio?

4. What is a potential problem with this question?
5. Compute the $95$% confidence interval for the proportion of students who had used earphones.

Some of the results are presented in Table\ \@ref(tab:HearingLossTable), including a comparison of the mean HLQ scores for females and males.

6. What statistical test was appropriate for comparing the mean scores for males and females?
7. What are the hypotheses being tested?
8. What is the standard error for the *difference* between the means?
9. Perform the hypothesis tests; what do the results mean?
10. Compute the approximate $95$% confidence interval for the difference between the means.
11. Are the test and the CI statistically valid?

Table\ \@ref(tab:HearingLossTable) also compares the HLQ scores for the frequency of *earphone* use specifically.

12. What are the hypotheses being tested?
13. Why is the sample size for this comparison only $791$ and not $845$?
14. Interpret the $P$-value for this test; what do the results mean?

Table\ \@ref(tab:HearingLossTable) also compares the HLQ scores for those who use and do not use *earphones*.

15. Form an approximate $95$%\ CI for the mean hearing loss score for students who use earphones. 
16. Compute the standard error of the *difference* between the mean hearing loss score for students who use and do earphones.
17. Perform a hypothesis tests to compare the *difference* between the mean hearing loss score for students who use and do not use earphones, and confirm that the $P$-value is indeed very small. 
:::

<!-- http://jhealthscope.com/en/articles/65901.html -->


```{r HearingLossTable}
HearingTable <- array( dim = c(7, 5) )

HearingTable[, 1] <- c("Female", 
                       "Male", 
                       "Yes", 
                       "No", 
                       "$0$, $1$ times/day", 
                       "$2$ to $3$ times/day", 
                       "More than $3$ times/day")
HearingTable[, 2] <- c(543, 302, 745, 100, 194, 319, 278)
HearingTable[, 3] <- c(19.37, 19.99, 19.8, 19.0, 19.2, 19.6, 20.2)
HearingTable[, 4] <- c(2.91, 3.51, 3.08, 1.71, 2.87, 2.66, 3.54)
HearingTable[, 5] <- c("$0.009$", NA, "$< 0.001$", NA, "$0.001$", NA, NA)
tab.cap.HL <- "The Hearing Loss Questionnaire scores for various demographic variables."

# Swap rows around so the space inserted by kable is in a useful place
HearingTable[ c(1, 2, 6, 7, 3, 4, 5), ] <- HearingTable

colnames(HearingTable) <- c("Levels", 
                            "Sample size", 
                            "Mean", 
                            "Std dev.", 
                            "$P$-value")

if( knitr::is_latex_output() ) {
  kable(pad(HearingTable, 
            surroundMaths = TRUE, 
            targetLength = c(0 , 3 , 5 , 4 , 0), 
            decDigits = c(0 , 0 , 2 , 2 , 0)),
        format = "latex",
        longtable = FALSE,
        booktabs = TRUE,
        escape = FALSE,
        align = c("r", "c", "c", "c", "c"),
        linesep = c("", "\\addlinespace", 
                    "", "", "\\addlinespace",
                    "",""), # Otherwise adds a space after five lines... which looks odd when there are only six
        col.names = colnames(HearingTable),
        caption = tab.cap.HL) %>%
    add_header_above( c(" " = 2,
                        "HLQ" = 2,
                        " " = 1),
                      bold = TRUE,
                      line = TRUE) %>%
   row_spec(row = 0, 
            bold = TRUE) %>%
    kable_styling(font_size = 8) %>%
    pack_rows("Sex",
              start_row = 1,
              end_row = 2) %>%
    pack_rows("Frequency of earphone use",
              start_row = 3,
              end_row = 5) %>%
    pack_rows("Earphone use",
              start_row = 6,
              end_row = 7)
}

if( knitr::is_html_output() ) {
  kable(pad(HearingTable, 
            surroundMaths = TRUE, 
            targetLength = c(0 , 3 , 5 , 4 , 0), 
            decDigits = c(0 , 0 , 2 , 2 , 0)),
               format = "html",
               longtable = FALSE,
               booktabs = TRUE,
               align = "c",
               col.names = colnames(HearingTable),
               caption = tab.cap.HL ) %>%
    add_header_above( c(" " = 2,
                        "HLQ" = 2,
                        " " = 1),
                      bold = TRUE,
                      line = TRUE) %>%
    column_spec(column = 1, 
                bold = TRUE) %>%
    row_spec(row = 0, 
             bold = TRUE) %>%
    pack_rows("Sex",
              start_row = 1,
              end_row = 2) %>%
    pack_rows("Frequency of earphone use",
              start_row = 3,
              end_row = 5) %>%
    pack_rows("Earphone use",
              start_row = 6,
              end_row = 7)
}
```


::: {.exercise #ReadExerciseQuakes}
@mesrkanlou2023effect studied the effect of an earthquake on pregnant mothers in Varzaghan, Iran (p.\ 2), using:

> ... $1000$ cases of pregnant women living in urban and rural areas of Varzaghan city that consisted of $550$ pre-earthquake and $450$ post-earthquake cases.

The researchers compared the mothers in the two groups (pre- and post-earthquake) on various measurements.
For example, the mean age of mothers in the *pre*-group was $25.82$\ y, and the mean age of the mothers in the *post*-group was $26.71$\ y; the difference has a $P$-value of $0.084$.

1. What does this result *mean*?
2. *Why* did the researchers make this comparison between the mothers' ages in two groups?
3. What type of hypothesis test was used to make this conclusion?

The researchers also compared the mean birth weights of the babies born to the mothers in the two groups.
In the *pre*-group, the mean birth weight was $3.25$\kgs ($s = 0.52$) and in the *post*-group the mean birth weight was $3.18$\kgs ($s = 0.54$).

4. Compute the standard error for comparing the *difference* between the two means.
5. Perform a hypothesis test to compare the mean birthweights.
6. What does this result *mean*?
7. The researchers give the (two-tailed) $P$-value for this test as $0.001$.
   Is this consistent with your calculations?

The researchers also compared the percentage of babies with a Low Birth Weight (LBW; less than $2.5$\kgs).
For the *pre*-group, the percentage was $6.01$%; for the *post*-group, the percentage was $8.92$%.
<!-- The $P$-value is given as $< 0.001$. -->

8. What *type* of definition is given for LBW?
9. Construct the two-way table for displaying these data.
10. What type of test was probably used for this comparison?
11. For the test, $\chi^2 = 3.052$.
    Deduce the equivalent $z$-score and the approximate $P$-value.
12. What limitations can you identify for this study?
:::


::: {.exercise #ReadExerciseSelinium}
@tracy1990selenium studied the selenium (Se) concentration in irrigation and stock water sources in California.
For drinking water, the maximum recommended concentration was $10$\ $\mu$g.L^$-1$^; for irrigation water, the maximum recommended concentration was $20$\ $\mu$g.L^$-1$^

Part of the study examined the area within $5$\ k of wells.
When Pliocene rocks were within this radius, the relationship between the Se concentration $y$ in the water and the electrical conductivity of the water $x$ (in deciSiemens per meter, dS.m^$-1$^) was
$$
  \hat{y} = -3.1 + 7.0x,
$$
where $R^2 = 27$%.

1. Interpret the meaning of $R^2$.
2. What is the value of the correlation coefficient?
3. The $P$-value for testing the slope is given as $<0.001$. 
   Interpret what this means in this context.
4. What are the measurement units of the slope?

For the $n = 151$ wells in the study, Table\ \@ref(tab:seleniumTable) shows the selenium concentration of the water and the geology within $5$\kms of the well.

5. What hypotheses are being tested by the table?
6. The article states that $\chi^2 = 31.5$.
   What is the equivalent $z$-score for the test?
7. What is the approximate $P$-value for the test?
8. Interpret what this means in this context.
:::

```{r seleniumTable}
seleniumTab <- array(dim = c(2, 2))

seleniumTab[1, ] <- c(78, 15)
seleniumTab[2, ] <- c(23, 35)

rownames(seleniumTab) <- c("Se concentration $\\le 2$ $\\mu$g.L$^{-1}$",
                           "Se concentration $> 2$ $\\mu$g.L$^{-1}$")
colnames(seleniumTab) <- c("No", 
                           "Yes")

if( knitr::is_latex_output() ) {
  kable(pad(seleniumTab,
            surroundMaths = TRUE,
            targetLength = c(2, 2),
            decDigits = 0),
        format = "latex",
        booktabs = TRUE,
        longtable = FALSE,
        escape = FALSE,
        align = "c",
        caption = "Number of wells with dissolved Se above $2$ $\\mu$g.L$^{-1}$, and the geology within $5$\\kms radius of the well."
  ) %>%
     column_spec(1, bold = TRUE)  %>%
     row_spec(0, bold = TRUE) %>%
     add_header_above(c(" " = 1,
                        "Plioscene rocks present?" = 2),
                      bold = TRUE,
                      line = TRUE) %>%
	kable_styling(font_size = 8)
 }


 if( knitr::is_html_output() ) {
  kable(pad(seleniumTab,
            surroundMaths = TRUE,
            targetLength = c(2, 2),
            decDigits = 0),
               format = "html",
               booktabs = TRUE,
               longtable = FALSE,
               align ="c",
        caption = "Number of wells with dissolved Se above $2$ $\\mu$g.L$^{-1}$, and the geology within $5$\\kms radius of the well.")
 }   
```

```{r}
# seleniumBars <- c(69, 27, 29, 15, 5, 2, 0, 1)
# 
# barplot( seleniumBars,
#          space = 0,
#          width = c(1, 2, 7, 10, 30, 30, 70, 120),
#          names.arg = c("0 to under 1",
#                        "1 to under 3",
#                        "3 to under 10",
#                        "10 to under 20",
#                        "20 to under 50",
#                        "50 to under 80",
#                        "80 to under 150",
#                        "150 to under 270")
# )

```


::: {.exercise #ReadExerciseLarva}
@russell2023difference compared the larvae of two types of mosquitoes: *Ae. albopictus* (an invasive specie) and *Cx. pipiens* (a native species).
One study compared the survival rates of the larvae at two temperatures (p.\ 4):

> The probability of survival among *Ae. albopictus* control larvae was $86.8$% at $15$^o^C and $86.1$% at $25$^o^C and did not differ significantly based on temperature ($\text{$p$-value} = .8076$).

1. What type of test was probably used?
2. Interpret what the $P$-value means in this context.

The researchers also compared the size of the surviving larvae (p.\ 4 and\ 5):

> The results of a Welch two sample $t$-test showed that surviving *Cx. pipiens* control larvae were significantly larger than surviving *Ae. albopictus* control larvae ($\text{mean}\pm\text{SD}$: *Cx. pipiens*${} = 1.64 ± 0.18$\mms, *Ae. albopictus*${} = 1.36 ± 0.13$\mms; $\text{$p$-value} =< .0001$).

The two sample sizes are $n = 410$ and $n = 498$ respectively.

3. How would these results be interpreted?
4. What type of test would probably have been used?
5. Compute the standard error for the difference between the two types of mosquitoes.
6. Compute the $t$-score and approximate $P$-value for the test. 
   What does the mean?
7. Is the $P$-value in the article consistent with your calculations?
8. Is the test statistically valid?

The length of the surviving larvae from both species were compared for the two temperatures also (p.\ 5; line break added):

> Within *Cx. pipiens*, surviving control larvae were significantly larger from replicates held at $15$^o^C, relative to those from $25$^o^C ($\text{mean} \pm \text{SD}$: $15$^o^C ${}= 1.66 \pm 0.01$\mms, $25$^o^C ${} = 1.60 \pm 0.02$\mms; $\text{$p$-value} = .0065$). 
>
> For *Ae. albopictus* surviving control larvae, there was no significant difference in length due to temperature ($\text{mean}\pm\text{SD}$: $15$^o^C${}= 1.35 \pm 0.01$\mms, $25$^o^C${} = 1.36 \pm 0.01$\mms; $\text{$p$-value} = .4343$).

9. How would these results be interpreted?
10. What type of test would probably have been used?

The linear association between predation efficiency ($y$; as a percentage) and predator--prey size-ratio ($x$; no units) was found (using $n = 45$) to be
$$
   \hat{y} = -19.56 + 31.64x.
$$
The standard errors of the two regression coefficients were $17.92$ (intercept) and $13.88$ (slope).

11. Find an approximate $95$% confidence interval for each regression parameter.
12. Estimate the $P$-value for testing if the population slope is zero or not. 
    Interpret what this means.
13. Is this test statistically valid?
14. Interpret the meaning of the slope.
15. The value of $R^2$ was given as $0.087$ (i.e., $8.7$%); interpret this value,
16. Find the value of the correlation coefficient, $r$.
:::


::: {.exercise #ReadExerciseMouth}
@li2017normal studied the maximum mouth opening (MMO; in mm) for $452$ Chinese adults aged from $20$ to\ $35$.

1. Would the individuals in the study likely have been blinded?
   Explain.
   What are the implications?
   
The correlation between height and MMO was given as $r = 0.54$ with $P < 0.001$.

2. What does this *mean*?
3. Compute and interpret the value of $R^2$.

The regression equation relating the height $x$ (in cm) and MMO $y$ was given as $\hat{y} = 0.36x - 10.15$.

4. Interpret the estimates of the regression parameters.
5. Use the regression equation to predict the MMO for a person $179$\cms tall.

The article states that the mean MMO of males was $54.18$\mms ($s = 5.21$), and for females was $49.62$\mms ($s = 3.69$).

6. What *type* of hypothesis tests would have been used to compare the mean MMO for males and females?
7. The article reports the $t$-score for comparing MMO for males and females as $t = 10.63$.
   What would the $P$-value be?
8. Is this results statistically valid?
9. What is the meaning of this comparison?
10. Is gender likely to be a confounding variable in this regression analysis?
    Explain carefully.

The authors state one of the limitations as:

> First, participants were recruited from a pool of people who were undergoing regular medical examinations in our hospital [...]

11. What does this mean?
    What are the implications?
    Are there other limitations?
:::



::: {.exercise #ReadExerciseTomatoes}
@drinkwater1995fundamental compared tomatoes growing on conventional (CNV; $n = 14$) and organic (ORG; $n = 17$) farms.
The researchers (p.\ $1\,100$):

> [...] sampled tomato fields between April and September in 1989 and 1990 [...] 
> Each of these sampling areas was divided into $20$ sections, and $1$\ms of the tomato row was selected randomly within each section...
p.\ 1\,103:

1. Explain what type of sampling is being used.

One important measure of soil health is the number of actinomycetes.
Researchers found (p.\ $1\,103$):

> ... total numbers of actinomycetes isolated from tomato rhizosphere soils were significantly larger in the ORG soils compared to CNV (Student's $t$ test, $t = 5.4$, $P = 0.006$)...

2. What type of test would probably have been used to reach this conclusion?
3. Explain what the results mean.
4. Are the results statistically valid?

The researchers also found that (p.\ $1\,103$):

> ... starch hydrolyzing actinomycetes were more numerous in CNV than in ORG soil (Student's $t$ test, $t = 4.0$, $P = 0.005$).

5. What type of test would probably have been used to reach this conclusion?
6. Explain what these results mean.

They also found that (p.\ $1\,103$):

> Total actinomycete abundance [was] negatively correlated with corky root [a disease] severity ($r = -0.76$, $P = 0.08$;...).

7. Explain what these results mean.
8. Compute and interpret the value of $R^2$.
:::


::: {.exercise #ReadExerciseEyeMasks}
@teo2022eye studied pregnant Malaysian women with sleeping disruptions in the last month of pregnancy.
The $56$ patients were (p.\ 1):

> ... randomized to the use of eye-mask and earplugs or "sham" headbands during night sleep (both introduced as sleep aids). 

Thus, two groups were used: one using eye-masks and earplugs (treatment group, T; $n = 29$) and one using headbands (control or placebo group, P; $n = 27$).

1. What was the purpose of using 'sham' headbands if it was an ineffective intervention?
2. What type of study is this: experimental or observational?
   Explain.

Sleep duration was measured in Week\ 1 (no intervention) and again in Week\ 2 (with the allocated intervention) for each subject, using a 'wrist actigraphy monitor'.

3. Why is using a 'wrist actigraphy monitor' better than asking subjects for self-reported sleep duration?

The women in the two groups were compared.
For example, the mean age of the women was $30.6$\ y ($s = 3.6$) (T) and $30.1$\ y ($s = 3.3$) (P); the $P$-value for the comparison was given as $P = 0.56$.

4. *Why* was this comparison made?
5. Compute the standard error for the difference between the two mean sleep durations.
6. Compute the $t$-score for the test.
7. Is the quoted $P$-value consistent with your calculations?
8. What do these results mean?
9. Is the result statistically valid?

Another comparison was the room 'condition' where the women slept: in the treatment group, $13$ had a room with a fan ($16$ had air conditioning), while in the control group $10$ women had a fan (and $17$ air conditioning).
The $P$-value for the comparison was given as $P = 0.60$.

10. *Why* was this comparison made?
11. Construct the two-way table summarising the data.
12. The $\chi^2$-score for the test is $0.35064$.
<!-- chisq.test( matrix( c(13,10,16,17), ncol=2), correct=FALSE)-->
    Compute the equivalent $z$-score.
13. Is the quoted $P$-value consistent with your calculations?
14.  What do these results mean?
15. Is the result statistically valid?

For the subjects in the *treatment* group, the mean sleep duration in Week\ 1 was $279.0$\mins ($s = 18.9$) and in Week\ 2 was $303.6$\mins ($s = 18.8$).
The *increase* was $24.7$\mins ($s = 14.9$).

16. Conduct the appropriate statistical test to determine if sleep duration *increased* in the treatment group.
17. What do these results mean?

For the subjects in the *control* group, the mean sleep duration in Week\ 1 was $286.3$\mins ($s = 20.9$) and in Week\ 2 was $301.9$\mins ($s = 21.8$; $n = 26$ since one observation was not available).
The *increase* was $18.1$\mins ($s = 17.3$).

18. Conduct the appropriate statistical test to determine if sleep duration *increased* in the treatment group.
19. What do these results mean?
20. What could explain the *increase* in sleep duration, despite the control group using an ineffective intervention? 

The *increase* in sleep duration can be compared for the two groups.

21. Compute the standard error for difference between the mean increases $\text{s.e.}( \bar{x}_T - \bar{x}_T)$.
22. Construct an approximate $95$% confidence interval for the *difference* in the increase in sleep duration for the two groups.
23. Conduct a hypothesis test to compare the increase in sleep duration for the two groups.
    Interpret what this means.
24. Is the test statistically valid?
:::


<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to *Quick Revision* questions:**
False; True; False.
:::
`r if (knitr::is_html_output()) '-->'`




