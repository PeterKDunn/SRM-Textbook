# (PART) Tools for answering RQs {-}


```{r echo=FALSE, cache = FALSE}
source("R/showMakeDecisions.R")
```


# Making decisions: an introduction {#MakingDecisions}


```{r, child = if (knitr::is_html_output()) {'./introductions/15-Tools-DecisionMaking-HTML.Rmd'} else {'./introductions/15-Tools-DecisionMaking-LaTeX.Rmd'}}
```


## Introduction {#Chap15-Intro}

In Sect. \@ref(NHANESCaseStudyQual), the NHANES data [@data:NHANES3:Data] were numerically summarised.
The *sample mean* direct HDL cholesterol concentration was different for smokers ($\bar{x} = 1.31$mmol/L) and for non-smokers ($\bar{x} = 1.39$mmol/L).

Importantly, we must realise that the sample studied is only one of *countless* possible samples that could have been chosen.
If a different sample of people was chosen, a different value for the difference between the sample means would have been produced.
And, of course, since *countless* samples are possible, countless values for $\bar{x}$ are possible.

This leads to one of the most important observations about sampling.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Studying a sample leads to the following observations:

* Each sample is likely to be different.
* Our sample is just one of countless possible samples from the population.
* Each sample is likely to produce a different value for the sample statistic.
* Hence we only observe one of the many possible values for the sample statistic.

Since many values for the sample statistic are possible, the possible values of the sample statistic vary (called *sampling variation*) and have a *distribution* (called a *sampling distribution*).
:::


Since we only have one value of the sample statistic, out of the many values of the sample statistic that are possible, what does this difference between the *sample* means imply about the difference between the *population* means?

Two reasons could explain why the *sample* means are different:

1. The *population* means are the *same*; the difference is due to *sampling variation*.  
   That is, we just happen to have---by chance---one of those samples where the difference between the means is quite noticeable.
   The *sample* means are different only because we have data from one of the many possible samples, and every sample is likely to be different.
2. Alternatively, the *population* means are *different*, and the sample means reflect this.

How do we decide which of these explanations is supported by the data?

Similarly, in Sect. \@ref(NHANESCaseStudyQual) the *odds* of being diabetic were different for smokers (0.181) and non-smokers (0.084).
What does this difference between the *sample* odds imply about the *population* odds?

Again, two possible reasons could explain why the sample odds are different:

1. The *population* odds are the same.
   That is, we just happen to have---by chance---one of those samples where the difference between the odds is quite noticeable.
   The *sample* odds are different only because we have data from one of the many possible samples, and every sample is likely to be different, so sometimes, the sample odds are different by chance.
   Again, this is called *sampling variation*.
2. Alternatively, the odds are different in the *population*, and the sample odds reflect this.

In both situations (means; odds), the two possible explanations ('statistical hypotheses'^[The word 'hypothesis' just means 'a possible explanation'.]) have special names:

1. There is *no difference* between the population parameters: the difference is simply due to *sampling variation*. 
   This is the *null hypothesis*, or $H_0$.
2. There is *a difference* between the population parameters.
   This is the *alternative hypothesis*, or $H_1$.

How do we decide which of these explanations is supported by the data?
What is the decision-making *process*?

One approach to the *decision-making process* begins by assuming the null hypothesis is true.
Then the data are examined to see if sufficient information exists to support the alternative hypothesis.
However, conclusions drawn about the *population* from the *sample* can never be certain, since the sample studied is just one of many possible samples that could have been taken.


## The need for making decisions {#NeedForDecisionMaking}

In research, decisions need to be made about  *population [parameters](#StatisticsAndParameters)* based on *sample [statistics](#StatisticsAndParameters)*.
The difficulty is that the decision must be made using one of the many possible sample, and every sample is likely to be different (comprising different individuals from the population), and so each sample will produce different summary *statistics*.
This is called *sampling variation*.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
[Sampling variation](#def:SamplingVariation) refers to how much a sample estimate (a [*statistic*](#def:Statistic)) is likely to vary across all possible samples, because each sample is different.
:::


However, sensible decisions *can* be made (and *are* made) about population parameters based on sample statistics.
To do this though, the process of *how* decisions are made needs to be articulated, which is the purpose of this chapter.

To begin, consider the following scenario.
Suppose I produce a standard pack of cards, and shuffle them well.
The pack of cards can be considered a *population*.


::: {.tipBox .tip data-latex="{iconmonstr-info-6-240.png}"}
A standard pack of cards has 52 cards, with four *suits*: spades and clubs (both black), 
and hearts and diamonds (both red).
Each *suit* has 13 *denominations*: 2, 3, 4, 5, 6, 7, 8, 9, 10, Jack (J), Queen (Q), King (K), Ace (A).
The Ace, King, Queen and Jack are referred to as *picture cards*.
(Most packs also contain two jokers, but these are not usually considered part of a *standard* pack.)
:::


Suppose I draw a *sample* of 15 cards from the pack, and *all* are red cards.
What should you conclude?
How likely is it that this would happen simply by chance?
`r if (knitr::is_latex_output()) {
   '(See Fig. \\@ref(fig:Draw15Cards); the online version has an animation.)'
} else {
   'See the animation below.'
}`
Is this evidence that the pack of cards is somehow unfair, or rigged?


```{r echo = FALSE, animation.hook = "gifski", cache = FALSE, fig.width = 4, interval = 0.25, fig.align = "center", dev=if (is_latex_output()){"pdf"}else{"png"}}
  ### CARDS ARE OF SIZE 500 x 726
  asp.cards <- 726/500
  
  ### LOAD CARD IMAGES

  im1  <- png::readPNG("Cards/queen_of_hearts.png")
  im2  <- png::readPNG("Cards/3_of_diamonds.png")
  im3  <- png::readPNG("Cards/4_of_diamonds.png")
  im4  <- png::readPNG("Cards/7_of_hearts.png")
  im5  <- png::readPNG("Cards/ace_of_diamonds.png")
  im6  <- png::readPNG("Cards/2_of_diamonds.png")
  im7  <- png::readPNG("Cards/ace_of_hearts.png")
  im8  <- png::readPNG("Cards/jack_of_diamonds.png")
  im9  <- png::readPNG("Cards/10_of_hearts.png")
  im10 <- png::readPNG("Cards/4_of_hearts.png")
  im11 <- png::readPNG("Cards/king_of_hearts.png")
  im12 <- png::readPNG("Cards/queen_of_diamonds.png")
  im13 <- png::readPNG("Cards/3_of_hearts.png")
  im14 <- png::readPNG("Cards/5_of_diamonds.png")
  im15 <- png::readPNG("Cards/5_of_hearts.png")
  

if (knitr::is_html_output()){
  for (i in (1:18)){ # Draw 15 cards
    
    # Set up canvas
    par(mar = rep(0.05, 4)) 
    plot( c(1.2, 2.7), c(1.2, 1.8), 
          type = "n",
          xlab = "",
          asp = asp.cards,
          ylab = "",
          axes = FALSE)
    
    
    if (i >= 1 )  rasterImage(im1,  1.20, 1.27, 1.80, 1.9)
    if (i >= 2 )  rasterImage(im2,  1.25, 1.27, 1.85, 1.9)
    if (i >= 3 )  rasterImage(im3,  1.30, 1.27, 1.90, 1.9)
    if (i >= 4 )  rasterImage(im4,  1.35, 1.27, 1.95, 1.9)
    if (i >= 5 )  rasterImage(im5,  1.40, 1.27, 2.00, 1.9)
    if (i >= 6 )  rasterImage(im6,  1.45, 1.27, 2.05, 1.9)
    if (i >= 7 )  rasterImage(im7,  1.50, 1.27, 2.10, 1.9)
    if (i >= 8 )  rasterImage(im8,  1.55, 1.27, 2.15, 1.9)
    if (i >= 9 )  rasterImage(im9,  1.60, 1.27, 2.20, 1.9)
    if (i >= 10)  rasterImage(im10, 1.65, 1.27, 2.25, 1.9)
    if (i >= 11)  rasterImage(im11, 1.70, 1.27, 2.30, 1.9)
    if (i >= 12)  rasterImage(im12, 1.75, 1.27, 2.35, 1.9)
    if (i >= 13)  rasterImage(im13, 1.80, 1.27, 2.40, 1.9)
    if (i >= 14)  rasterImage(im14, 1.85, 1.27, 2.45, 1.9)
    if (i >= 15)  rasterImage(im15, 1.90, 1.27, 2.50, 1.9)
    text(1.95, 1, "How likely is it that we get\n15 red cards in a row?")
  }
}
```



```{r Draw15Cards, echo=FALSE, cache=FALSE, fig.align="center", fig.width=7, fig.height=4.5, out.width = "25%",fig.cap="How likely is it that you would get 15 red cards in a row from a fair pack?" }
if (knitr::is_latex_output()){
     
    # Set up canvas
    par(mar = rep(0.05, 4)) 
    plot( x = c(1.2, 2.7), 
          y = c(1, 2), 
          type = "n",
          xlab = "",
          asp = asp.cards,
          ylab = "",
          axes = FALSE)
    
    rasterImage(im1,  1.20, 1.27, 1.80, 1.9)
    rasterImage(im2,  1.25, 1.27, 1.85, 1.9)
    rasterImage(im3,  1.30, 1.27, 1.90, 1.9)
    rasterImage(im4,  1.35, 1.27, 1.95, 1.9)
    rasterImage(im5,  1.40, 1.27, 2.00, 1.9)
    rasterImage(im6,  1.45, 1.27, 2.05, 1.9)
    rasterImage(im7,  1.50, 1.27, 2.10, 1.9)
    rasterImage(im8,  1.55, 1.27, 2.15, 1.9)
    rasterImage(im9,  1.60, 1.27, 2.20, 1.9)
    rasterImage(im10, 1.65, 1.27, 2.25, 1.9)
    rasterImage(im11, 1.70, 1.27, 2.30, 1.9)
    rasterImage(im12, 1.75, 1.27, 2.35, 1.9)
    rasterImage(im13, 1.80, 1.27, 2.40, 1.9)
    rasterImage(im14, 1.85, 1.27, 2.45, 1.9)
    rasterImage(im15, 1.90, 1.27, 2.50, 1.9)

  }
```


Getting 15 reds cards out of 15 from a well-shuffled pack seems very unlikely, so you probably conclude that the pack is somehow unfair.
But importantly, *how* did you reach that decision?
Your unconscious decision-making process may have worked like this:

1. You *assumed*, quite reasonably, that I used a standard, well-shuffled pack of cards, where half the cards are red and half the cards are black.
   That is, you assumed the *population proportion* is $p = 0.5$.
2. Based on that assumption, you *expected* about half the cards in the sample of 15 to be red, and about half to be black.
   You wouldn't necessarily expect *exactly* half red and half black, but you'd probably expect something close to that.
   That is, you would expect that $\hat{p}$ would be close to 0.5.
3. But what you *observed* was nothing like that: *All* 15 cards were red.
   That is, $\hat{p} = 0$.
4. You then made a *decision*: since what you observed ('all red cards') was not like what you were expecting ('about half red cards'), the 15 red cards *contradict* what you were expecting, based on your assumption of a fair pack...  so your assumption of a fair pack is probably wrong.

Of course, getting 15 red cards in a row is *possible*... but very *unlikely*.
For this reason, you would probably conclude, based on the evidence, there appears to be strong evidence that the pack is not a fair pack.

You probably didn't *consciously* go through this process, but it seems reasonable.
This process of decision making is similar to the process used in research.


## How decisions are made {#DecisionMaking}

Based on the ideas in the last section, a formal process of decision making in research can be described.
To expand:

1. **Assumption**:
   Make an assumption about the population parameter.
   Initially, assume that the *sampling variation* explains any discrepancy between the observed sample and assumed value of the population parameter.
   The initial assumption is that there has been 'no change, no difference, no relationship', depending on the context.
   <!-- For example:  -->

   <!-- - the [*population* parameters](#StatisticsAndParameters) are the same in various groups; sampling variation explains the difference between the [*sample* statistics](#StatisticsAndParameters); -->
   <!-- - the  [*population* parameter](#StatisticsAndParameters) is some given value; sampling variation explains why the [*sample* statistic](#StatisticsAndParameters) is not equal to this parameter value. -->

2. **Expectation**:
   Based on the assumption about the parameter, describe what values of the *sample [statistic](#StatisticsAndParameters)* might reasonably be observed from all the possible samples that might be obtained (due to sampling variation).

3. **Observation**:
   Observe the data from one of the many possible samples, and compute the observed sample statistic from this sample. 
4. **Decision**:
   If the observed *sample statistic* is:
    - *unlikely* to have happened by chance, it **contradicts** the assumption about the *population parameter*, and the assumption is probably **wrong**.
      The *evidence* suggests that the assumption is wrong (but it is not *certainly* wrong).
    - *likely* to have happened by chance, it is **consistent with** the assumption about the *population parameter*, and the assumption may be **correct**.
      No *evidence* exists to suggest the assumption is wrong (though it may be wrong).

This is one way to describe the formal process of decision making in science
`r if( knitr::is_html_output() ) {
   '(Fig. \\@ref(fig:DecisionFlow)).'
} else {
   '(Fig. \\@ref(fig:DecisionFlow2)).'
}`


```{r DecisionFlow2, echo = FALSE, fig.cap = "A way to make decisions", fig.align="center", out.width='100%', fig.width = 9.5, fig.height = 5}
showDecisionMaking()
```


<!-- ```{r DMPtable, echo = FALSE} -->
<!-- if( knitr::is_latex_output() ) {  -->
<!--   DMP <- array( "",  -->
<!--                 dim = c(4, 2)) # DMP:: Decision Making Process -->
<!--   DMP[, 1] <- c("\\textbf{Assumption:\ }", -->
<!--                 "\\textbf{Expectation:\ }", -->
<!--                 "\\textbf{Observation:\ }", -->
<!--                 "\\textbf{Decision:\ }")  -->

<!--   DMP[1, 2] <- "Assume  that sampling  variation explains the discrepancy between the sample statistic, and what is assumed about the population parameter" -->
<!--   DMP[2, 2] <- "Based on this assumption, describe what might be observed in the sample, such as values of the sample statistic that might reasonably be observed from all possible samples." -->
<!--   DMP[3, 2] <- "Observe the sample statistic. Then, if the observed sample statistic is..." -->
<!--   DMP[4, 2] <- "\\begin{minipage}[t]{45mm}...\\textit{unlikely} to happen by chance, it \\textbf{contradicts} the assumption.\\end{minipage} \\hfill \\hfill \\begin{minipage}[t]{45mm}...\\textit{likely} to happen by chance, it is \\textbf{consistent with} the assumption.\\end{minipage}" -->
<!--     kable(DMP,  -->
<!--           format = "latex", -->
<!--           linesep = "\\addlinespace", -->
<!--           col.names = NA, -->
<!--           booktabs = TRUE, -->
<!--           caption = "The decision-making process", -->
<!--           align = c("r", "l"), -->
<!--           escape = FALSE) %>% -->
<!--      column_spec(1, width = "25mm", bold=FALSE) %>% -->
<!--      column_spec(2, width = "12cm", bold=FALSE) -->
<!-- } -->
<!-- if( knitr::is_html_output() ) { -->
<!--   DMP <- array( "",  -->
<!--                 dim = c(4, 3)) # DMP:: Decision Making Process -->
<!--   DMP[, 1] <- c("**Assumption:**", -->
<!--                 "**Expectation:**", -->
<!--                 "**Observation:**", -->
<!--                 "**Decision:**")  -->

<!--   DMP[1, 2] <- "Assume  that sampling  variation explains what is seen in the sample, and hence assuming a value for the population parameter" -->
<!--   DMP[2, 2] <- "Based on this assumption, describe what might be observed in the sample, such as values of the sample statistic that might reasonably be observed from all possible samples." -->
<!--   DMP[3, 2] <- "Observe the sample statistic. Then, if the observed sample statistic is..." -->

<!--   DMP[4, 2] <- "...**unlikely** to happen by chance, it **contradicts** the assumption." -->
<!--   DMP[4, 3] <- "...**likely** to happen by chance, it is **consistent with** the assumption." -->

<!--   kable(DMP,  -->
<!--     format = "html", -->
<!--     col.names = NA, -->
<!--     booktabs = TRUE, -->
<!--     caption = "The decision-making process", -->
<!--     align = c("r", "l"), -->
<!--     escape = FALSE) %>% -->
<!--   column_spec(1, width = "12mm", bold=FALSE) %>% -->
<!--   column_spec(2, width = "12mm", bold=FALSE) %>% -->
<!--   column_spec(3, width = "12mm", bold=FALSE) -->
<!-- } -->

<!-- ``` -->





<!-- ```{r DMPtable3, echo = FALSE} -->
<!-- DMP <- array( "", dim = c(4, 4)) # DMP:: Decision Making Process -->
<!-- DMP[1, ] <- c("![](./Pics/iconmonstr-delivery-6-240.png){#id .class height=70px width=70px}", -->
<!--               "![](./Pics/iconmonstr-christmas-42-240.png){#id .class height=70px width=70px}", -->
<!--               "![](./Pics/iconmonstr-shipping-box-7-240.png){#id .class height=70px width=70px}", -->
<!--               "") -->
<!-- DMP[2, ] <- c("**Assumption**", -->
<!--               "**Expectation**", -->
<!--               "**Observation**", -->
<!--               "") -->
<!-- DMP[3, ] <- c("Make a reasonable assumption about the value of a *population [parameter](#StatisticsAndParameters)*", -->
<!--               "Based on this assumption, -->
<!--    describe what values of the *sample [statistic](#StatisticsAndParameters)* might reasonably be observed", -->
<!--    "Observe the *sample statistic*. Then, if the observed *sample statistic* is:", -->
<!--    "") -->
<!-- DMP[4, 3] <- "...*unlikely* to happen by chance, it **contradicts** the assumption." -->
<!-- DMP[4, 4] <- "...*likely* to happen by chance, it is **consistent with** the assumption." -->
<!-- if( knitr::is_latex_output() ) { -->
<!-- #  # Now do some repeating, so we can "collapse" -->
<!-- #  DMP[1:3, 4 ] <- DMP[1:3, 3] -->
<!-- DMP[2, ] <- c("\\textbf{Assumption}", -->
<!--               "\\textbf{Expectation}", -->
<!--               "\\textbf{Observation}", -->
<!--               "") -->
<!-- DMP[3, ] <- c("Make a reasonable assumption about the value of a \\emph{population parameter}", -->
<!--               "Based on this assumption, -->
<!--    describe what values of the \\emph{sample statistic} might reasonably be observed", -->
<!--    "Observe the \\emph{sample statistic}. Then, if the observed \\emph{sample statistic} is:", -->
<!--    "") -->
<!-- DMP[4, 3] <- "...\\emph{unlikely} to happen by chance, it \\textbf{contradicts} the assumption." -->
<!-- DMP[4, 4] <- "...\\emph{likely} to happen by chance, it is \\textbf{consistent with} the assumption." -->
<!--   kable( t(DMP[2:4, ]),  # Removes the images -->
<!--          format = "latex", -->
<!--          booktabs = TRUE, -->
<!--          linesep = "\\addlinespace", -->
<!--          escape = FALSE, -->
<!--          longtable = FALSE, -->
<!--          align = c("r", "p{65mm}", "p{55mm}"), -->
<!--          caption = "The decision-making process") %>% -->
<!--   kableExtra::kable_styling(latex_options = "hold_position") -->
<!-- } -->
<!-- if( knitr::is_html_output() ) { -->
<!--   # Now do some repeating, so we can "collapse" -->
<!--   DMP[1:3, 4 ] <- DMP[1:3, 3] -->
<!--   out <- kable( t(DMP), -->
<!--          format = "html", -->
<!--          booktabs = TRUE, -->
<!--          longtable = FALSE, -->
<!--          caption = "The decision-making process") -->
<!--   if ( knitr::is_html_output(excludes = "epub")) { -->
<!--     column_spec(out, 2, bold = TRUE) %>% -->
<!--     kable_styling(full_width = FALSE) %>% -->
<!--     collapse_rows(1:3, valign = "middle") -->
<!--   } else { -->
<!--     out -->
<!--   } -->

<!-- } -->
<!-- ``` -->




<!-- ```{r DecisionFlow2, echo = FALSE, cache=FALSE, fig.cap = "A way to make decisions", fig.align = "center", fig.width = 6.25, fig.height = 2.75, out.width = '75%'} -->
<!-- if( knitr::is_latex_output() ) { -->

<!--   showMakeDecisions() -->
<!-- } -->
<!-- ``` -->

```{r DecisionFlow, echo=FALSE, animation.hook="gifski", cache=FALSE, interval=1.5, progress=TRUE, fig.cap="A way to make decisions", fig.align="center", fig.width=6, fig.height=3, dev=if (is_latex_output()){"pdf"}else{"png"}}
if( knitr::is_html_output() ) {
  
  for (i in (1:2)){
    par( mar = c(0.15, 0.15, 0.15, 0.15))
    openplotmat()
    
    pos <- array(NA, dim = c(6, 2))
    pos[1, ] <- c(0.10, 0.85) # Assumption
    pos[2, ] <- c(0.40, 0.85) # Expectation
    pos[3, ] <- c(0.40, 0.15) # Observation
    pos[4, ] <- c(0.40, 0.50) # Consistency?
    pos[5, ] <- c(0.80, 0.85) # YES
    pos[6, ] <- c(0.80, 0.15) # NO
    
    straightarrow(from = pos[1, ], to = pos[2, ], 
                  lty = 1, 
                  lwd = 2)
    straightarrow(from = pos[4, ], to = pos[2, ], 
                  lcol = "black",
                  lty = 2,
                  lwd = 2)
    straightarrow(from = pos[4, ], to = pos[3, ], 
                  lcol = grey(0.4),
                  arr.pos = 0.5, # Then cover with box
                  lty = 2)
    if (i == 1 ) {
      curvedarrow(from = pos[4, ] + c(0, 0.065), to = pos[5, ], 
                lcol = grey(0.4),
                curve = 0.35,
                arr.pos = 0.5, # Then cover with box
                lty = 2)
      textrect( pos[5, ],  
              radx = 0.11,
              rady = 0.1,
              shadow.size = 0,
              lcol = "darkseagreen2",
              box.col = "darkseagreen2",
              lab = "Yes: Supports\nassumption", 
              col = grey(0)) # CROSS
        }
    if (i == 2 ) {
      curvedarrow(from = pos[4, ] - c(0, 0.065), to = pos[6, ] , 
                  lcol = grey(0.4),
                  curve = -0.35,
                  arr.pos = 0.5, # Then cover with box
                  lty = 2)
      textrect( pos[6, ],
                radx = 0.11,
                rady = 0.1,
                shadow.size = 0,
                lcol = "darksalmon",
                box.col = "darksalmon",
                lab = "No: Contradicts\nassumption", 
                col = grey(0)) # CROSS
    }
    textrect( pos[4, ],
              radx = 0.11,
              rady = 0.1,
              shadow.size = 0,
              lcol = "snow2",
              box.col = "snow2",
              lab = "Compare:\nConsistency?",
              col = grey(0)) # CHECKMARK
    textrect( pos[1, ], 
              lab = "Population:\nAssumption",
              radx = 0.11,
              rady = 0.1,
              shadow.size = 0,
              lcol = "slategray1",
              box.col = "slategray1",
              cex = 1)
    textrect( pos[2, ], 
              lab = "Sample:\nExpectation", 
              radx = 0.11,
              rady = 0.1,
              shadow.size = 0,
              lcol = "slategray2",
              box.col = "slategray2",
              cex = 1)
    textrect( pos[3, ], 
              box.col = "slategray3",
              lcol = "slategray3",
              shadow.size = 0,
              radx = 0.11,
              rady = 0.1,
              lab = "Sample:\nObservation",
              cex = 1)
  }
}

```


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-ketut-subiyanto-4546136.jpg" width="200px"/>
</div>

This approach is similar to how we unconsciously make decisions  every day.
For example, suppose I ask my son to brush his teeth [@data:Budgett:RandomizationTest], and later I want to decide if he really did.

1. **Assumption**: I *assume* my son brushed his teeth (because I told him to).
2. **Expectation**: Based on that assumption, I *expect* to find a damp toothbrush when I check.
3. **Observation**: When I check later, I observe a *dry* toothbrush.
4. **Decision**: The evidence *contradicts* what I expected to find based on my assumption, so my assumption is probably *false*.
   He probably *didn't* brush his teeth.

I may have made the wrong decision:  He may have brushed his teeth, but dried his brush with a hair dryer.
However, based on the evidence, quite probably he has not brushed his teeth.

The situation may have ended differently: When I check later, I observe a *damp* toothbrush.
In this case, the evidence seems *consistent* with what I expected to find based on my assumption, so my assumption is probably *true*.
He probably did brush his teeth.

Again, I may be wrong:  He may have just ran his toothbrush under a tap.
I don't have any evidence that he didn't brush his teeth, though.

Similar logic underlies most decision making in science^[Other ways exist to make decisions too, such as incorporating prior knowledge. For example, if my son had a reputation for wetting his toothbrush under the tap instead of brushing his teeth, that information can be incorproated into the decision making. This approach is called *Bayesian statistics*.].


::: {.example #DecisionMakingProcess name="The decision-making process"}
Consider the cards example from Sect. \@ref(NeedForDecisionMaking) again.
The formal process might look like this:

1. **Assumption**: *Assume* the pack is fair and well-shuffled pack of cards: the population proportion of red cards is $p = 0.5$ (the value of the *parameter*). 
2. **Expectation**: Based on this assumption, roughly equal (but not necessarily *exactly*) equal numbers of red and black cards would be expected in a sample of 15 cards.
   The sample proportion of red cards  (the value of the *statistic*) is expected to be close to, but maybe not exactly, 0.5. 
  
3. **Observation**: Suppose I then deal 15 cards, and *all* 15 are red cards: $\hat{p} = 0$.
4. **Decision**: 15 red cards from 15 cards seems unlikely to occur if the pack is fair and well-shuffled.
   The data seem *inconsistent* with what I was expecting based on the assumption (Fig. \@ref(fig:DecisionFlowCards)).
   The evidence suggests that the assumption is probably false.

Of course, getting 15 red cards out of 15 is not *impossible*, so I may be wrong... but it is *very* unlikely.
Based on the evidence, concluding that a problem exists with the pack of cards seems reasonable.
:::




```{r DecisionFlowCards, echo = FALSE, fig.cap = "A way to make decisions for the cards example", fig.align="center", out.width='100%', fig.width = 9.5, fig.height = 4.95}
showDecisionMaking(populationText = expression( atop(I~bold(assume)~the,
                                                     pack~is~fair)),
                   expectationText = expression(atop(I~bold(expect)~to~find,
                                                     about~half~red~cards)),
                   oneSampleText = expression( atop(Deal~one~hand,
                                                    of~15~cards) ),
                   oneStatisticText =  expression( atop(bold(All)~cards,
                                                        are~red)),
                   Decision = "Reject"     
)

```






<!-- ```{r DecisionFlowCards, echo = FALSE, fig.cap = "A way to make decisions for the cards example", fig.align = "center", fig.width = 6.25, fig.height = 2.75, out.width = '75%'} -->

<!-- showMakeDecisions(arrowYes = FALSE, -->
<!--                   assumptionText = "Assumption:\n Fair pack", -->
<!--                   expectationText = "Expectation:\n Half red") -->
<!-- ``` -->


## Making decisions in research {#MakingDecisionsInResearch}

Let's think about each step in the decision-making process
`r if( knitr::is_html_output()){
  '(Fig. \\@ref(fig:DecisionFlow))'
} else {
  '(Fig. \\@ref(fig:DecisionFlow2))'
}`
individually.

* The **assumption** about the parameter (Sect. \@ref(Assumption));
* The **expectation** of the statistic (Sect. \@ref(ExpectationOf));
* The **observations** (Sect. \@ref(Observation)); and
* Make a **decisions** (Sect.\@ref(MakeDecision)).


### Assumption about the population parameter {#Assumption}


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Pics/iconmonstr-delivery-6-240.png" width="50px"/>
</div>

The initial assumption is that there has been 'no change, no difference, no relationship', depending on the context.
Using this idea, a reasonable assumption can be made about the *population* [parameter](#StatisticsAndParameters):

* We might **assume** that *no difference* exists between the parameter for two groups in the *population*, since we don't have any evidence yet to say there *is* a difference.
  For example, we might assume that the mean HDL cholesterol is the same for current smokers and non-smokers in the *population*, for the NHANES data.
  If we already *knew* there was a difference, why would we be performing a study to see if there is a difference?

* We might be interested in testing a claim, or evaluating a benchmark, about a *population* parameter, to determine if the evidence supports this claim or benchmark.

These assumptions about the population parameter are called *null hypotheses*.


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Illustrations/pexels-ketut-subiyanto-4546136.jpg" width="200px"/>
</div>


::: {.example #Assumptions name="Assumptions about the population"}
Many dental associations recommend brushing teeth for two minutes.
One study [@data:Macgregor1979:BrushingDurationKids] recorded the tooth-brushing time for 85 uninstructed schoolchildren (11 to 13 years old) from England.

We could *assume* the *population* mean tooth-brushing time in the population (11 to 13 year-old children from England) is two minutes, as recommended.
After all, we don't have evidence to suggest any other value for the mean.
A sample can then be obtained to determine if the sample mean is consistent with, or contradicts, this assumption.
:::


### Expectations of sample statistics {#ExpectationOf}


<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Pics/iconmonstr-christmas-42-240.png" width="50px"/>
</div>


Having assumed a value for the population parameter, the *second step* is to determine **what values to expect from the sample [statistic](#StatisticsAndParameters)**, based on this assumption.

Since many samples are possible, and every sample is likely to be different (['sampling variation'](#def:SamplingVariation)), the value of the sample statistic depends on which one of the possible samples we obtain: the sample statistic is likely to be different for every sample.

Think about the cards in Sect. \@ref(NeedForDecisionMaking).
Assuming a fair pack, then *half* the cards are red in the *population* (the pack of cards), so the *population* proportion is assumed to be $p = 0.5$.
In a *sample* of 15 cards, what values could be reasonably expected for the *sample* proportion $\hat{p}$ of red cards (the statistic)?
If samples of size 15 were repeatedly taken, the sample proportion of red cards would vary from hand to hand, of course.

*How* would $\hat{p}$ vary from sample to sample? 
Perhaps 15 red cards out of 15 cards happens reasonably frequently... or perhaps it doesn't. 
How could we find out?
We could:

* use mathematical theory.
* shuffle a pack of cards and deal 15 cards many hundreds of times, then count how often we see 15 red cards of out 15 cards.
* *simulate* (using a computer) dealing 15 cards many hundreds of times, and count how often we get 15 red cards of out 15 cards.

The third option is the most practical...
To begin, suppose we simulated only ten hands of 15 cards each;
`r if (knitr::is_latex_output()) {
   'Fig. \\@ref(fig:RollDice10) shows the sample proportion of red cards from each of the ten repetitions. (The online version has an animation.)'
} else {
   'the animation below shows the sample proportion of red cards from each of the ten repetitions.'
}`
Not one of those ten hands produced 15 red cards in 15 cards.


```{r echo=FALSE, animation.hook="gifski", cache=FALSE, interval=0.25, dev=if (is_latex_output()){"pdf"}else{"png"}}
if (knitr::is_html_output()){
  set.seed(99999)
    num.in.hand <- 15
    num.sims <- 10
    x.loc <- 1:(num.in.hand)
    y.loc <- 1
    prop.red <- array(dim = num.sims)
    all.hands <- array( dim = c(num.sims, num.in.hand))
    for (i in 1:num.sims){
      par ( mar = c(5.1, 5.1, 4.1, 2.1)) # DEFAULT is 5.1, 4.1, 4.1, 2.1
      plot( x = c(1, (num.in.hand + 2)), 
            y = c(1, num.sims),
            type = "n",
            las = 1,
            xlab = "",
            ylab = "",
            main = paste("Hand number",i),
            axes = FALSE)
      hand <- sample( c("B", "R"), 
                      num.in.hand, 
		      replace = TRUE)
      all.hands[i, ] <- hand
      prop.red[i] <- sum( (hand == "B")/2 == floor( (hand == "B")/2) ) / num.in.hand
      num.all.hands <- (all.hands == "B")
      
      for (j in 1:i){
        text(y = j, 
	     x = 1:num.in.hand,
             labels = all.hands[j, ],
             col = ifelse( num.all.hands[j, ]/2 == floor(num.all.hands[j, ]/2), "red", "grey") )
      }
      # Add p-hat heading
      mtext(expression(hat( italic(p) ) ), 
            side = 3, 
	    line = 0, 
	    at = num.in.hand + 2 )
      # Add the hand number to the left-hand side
      axis(side = 2, 
           at = 1:i,
           las = 1,
           labels = paste("Hand ", 1:i, sep = "") )
      
      # Add the sample proportion to right-hand side 
      text(num.in.hand + 2, 1 : i, 
           labels = format(round(prop.red[1 : i], 2), nsmall = 2) )
      #Add dividing line
      abline(v = num.in.hand + 1, 
             col = "grey")
      
      # Divide each hand set
      abline(h = (1 : i) - 0.5, 
             col = "grey")
    }
  }
```


```{r RollDice10, echo = FALSE, fig.align = "center", fig.width = 6.5, out.width='75%', fig.cap = "Ten hands of 15 cards: The sample proportion that is red varies from hand to hand (as shown on the right-hand side)" , cache = FALSE}
if (knitr::is_latex_output()){
  set.seed(99999)
  num.in.hand <- 15
  num.sims <- 10
  x.loc <- 1:(num.in.hand)
  y.loc <- 1
  prop.red <- array(dim = num.sims)
  all.hands <- array( dim = c(num.sims, num.in.hand))
  
  plot( x = c(1, (num.in.hand + 2)), 
        y = c(1, num.sims),
        type = "n",
        las = 1,
        xlab = "",
        ylab = "",
        main = "Ten example hands of 15 cards",
        axes = FALSE)
  
  for (i in 1:num.sims){
    par ( mar = c(0.1, 4.3, 4.1, 0.1)) # DEFAULT is 5.1, 4.1, 4.1, 2.1
    
    hand <- sample( c("B", "R"), 
                    num.in.hand, 
                    replace = TRUE)
    all.hands[i, ] <- hand
    prop.red[i] <- sum( (hand == "B")/2 == floor( (hand == "B")/2) ) / num.in.hand
    num.all.hands <- (all.hands == "B")
  }   
  for (j in 1:i){
    text(y = j, 
         x = 1:num.in.hand,
         labels = all.hands[j, ],
         col = ifelse( num.all.hands[j,]/2 == floor(num.all.hands[j,]/2),
                       "black", 
                       grey(0.7)),
         font = ifelse( num.all.hands[j,]/2 == floor(num.all.hands[j,]/2),
                       2, # BOLD 
                       1) # NORMAL FONT
         )
  }
  # Add p-hat heading
  mtext(expression(hat( italic(p) ) ), 
        side = 3, 
        line = 0, 
        at = num.in.hand + 2 )
  # Add the hand number to the left-hand side
  axis(side = 2, 
       at = 1:i,
       las = 1,
       labels = paste("Hand ", 1:i, sep = "") )
  
  # Add the sample proportion to right-hand side 
  text(num.in.hand+2, 1:i, 
       labels = format( round(prop.red[1:i], 2), nsmall = 2) )
  #Add dividing line
  abline(v = num.in.hand + 1, 
         col = "grey")
  
  # Divide each hand set
  abline(h = (1:i) - 0.5, 
         col = "grey")
  #    }
  
}
```


Suppose we repeated this for *hundreds* of hands of 15 cards (rather than the ten above), and for each hand we recorded the sample proportion of cards that were red.
The proportion of red cards would vary from sample to sample (['sampling variation'](#def:SamplingVariation)), and we could record the proportion of red cards from each of those hundreds of hands.
A histogram of these hundreds of sample proportions could be constructed;
`r if (knitr::is_latex_output()) {
   'Fig. \\@ref(fig:HandRedHist1000) shows a histogram of the sample proportions from 1000 simulations of a hand of 15 cards. (The online version has an animation.)'
} else {
   'the animation below shows a histogram of the sample proportions from 1000 repetitions of a hand of 15 cards.'
}`
This histogram shows how we might expect the sample proportions $\hat{p}$ to vary from sample to sample, when the *population* proportion of red cards is $p = 0.5$.


```{r DiceHist, echo=FALSE, animation.hook = "gifski", cache = FALSE, interval = 0.025, dev=if (is_latex_output()){"pdf"}else{"png"}}
if (knitr::is_html_output()){
  set.seed(9900991)
    num.in.hand <- 25
    num.sims <- 1000
    prop.red <- array(dim=num.sims)
    for (i in 1:num.sims){
      hand <- sample( c("B", "R"), 
                      num.in.hand, 
		      replace = TRUE)
      prop.red[i] <-  sum( (hand == "B")/2 == floor( (hand == "B")/2) ) / num.in.hand
      
      out <- hist( prop.red,
                   breaks = seq(0.02, 0.98, by = 0.04),
                   las = 1,
                   ylim = c(0, 200),
                   xlim = c(0, 1),
                   col = plot.colour,
                   main = paste("Histogram of sample proportions\nHand number:", i),
                   xlab = "Proportion of the 15 cards that are red",
                   sub = paste("(For this hand: proportion of cards red: ", format(round(prop.red[i], 3), nsmall = 3), ")", sep = "" ),
                   ylab = "Frequency",
                   right = FALSE,
                   axes = FALSE)
      axis(side = 1)
      axis(side = 2, 
           las = 1)
      
      xx <- seq(0, 1, length = 500)
      yy <- dnorm(xx, 
                  mean = 0.5, 
		  sd = 0.1 )
      yy <- yy/max(yy) * max(out$count)
      
      lines(yy ~ xx, 
            col = "grey",
            lwd = 2)  
    }
}
```


```{r HandRedHist1000, echo=FALSE, fig.align="center", fig.height=4,fig.width=5.25, fig.cap="A histogram of the sample proportion of red cards, in hands of 15 cards, for 1000 repetitions", cache=FALSE }
if (knitr::is_latex_output()){
    set.seed(99030991)
    num.in.hand <- 25
    num.sims <- 1000
    prop.red <- array(dim = num.sims)
    
    for (i in 1:num.sims){
      hand <- sample( c("B", "R"), num.in.hand, 
                      replace = TRUE)
      prop.red[i] <-  sum( (hand == "B")/2 == floor( (hand == "B")/2) ) / num.in.hand
    }
    
      out <- hist( prop.red,
                   breaks = seq(0.02, 0.98, by = 0.04),
                   las = 1,
                   ylim = c(0, 200),
                   xlim = c(0, 1),
                   col = plot.colour,
                   main = "Histogram of sample proportions\nfor 1000 hands",
                   xlab = "Proportion of 15 cards that are red",
                   ylab = "Frequency",
                   right = FALSE,
                   axes = FALSE)
      axis(side = 1)
      axis(side = 2, 
           las = 1)
      
      xx <- seq(0, 1, length = 500)
      yy <- dnorm(xx, 
                  mean = 0.5, 
		  sd = 0.1 )
      yy <- yy/max(yy) * max(out$count)
      
      lines(yy ~ xx, 
            col = "grey", 
            lwd = 2)  
}
```


### Observations about our sample {#Observation}

We then take a sample (one of the many samples that are possible), and observe the sample statistic.
In this situation, we observe 15 red cards out of 15 cards.


### Making a decision {#MakeDecision}

<div style="float:right; width: 222x; border: 1px; padding:10px">
<img src="Pics/iconmonstr-shipping-box-7-240.png" width="50px"/>
</div>


Using the sample data, we make a decision.

We note that observing 15 red cards out of 15 cards is quite rare: it never happened once in the 1000 simulations.
So based on simulating one thousand hands, we could conclude that we would *almost never* find 15 red cards in 15 cards... *if the assumption of a fair pack was true*.
But we *did* find 15 red cards in 15 cards... so the assumption ('a fair pack') is probably wrong.

What if we had observed 4 red cards in a hand of 15 cards (a sample proportion of $\hat{p} = 4/15 = 0.267$), rather than 15 red cards out of 15?
The conclusion is not quite so obvious then: these values of $\hat{p}$ are uncommon, but they certainly do happen when $p = 0.5$.
In these situations, a more sophisticated approach for making a decision is needed.

Special tools are needed to describe what to **expect** from the *sample* statistic after making **assumptions** about the *population* parameter.
These special tools are discussed in the next chapters.


::: {.example #SamplingVariation name="Sampling variation"}
Many dental associations recommend brushing teeth for two minutes.
One study [@data:Macgregor1979:BrushingDurationKids] recorded the tooth-brushing time for 85 uninstructed schoolchildren (11 to 13 years old) from England.

Of course, every possible sample of 85 children will include different children, and so produce a different sample mean $\bar{x}$.
Even if the *population* mean toothbrushing time really is two minutes ($\mu = 2$), the *sample* mean probably won't be exactly two minutes, because of [sampling variation](#def:SamplingVariation).

We could *assume* the population mean tooth-brushing time is two minutes ($\mu = 2$).
*If* this assumption is true, we then could describe what values of the sample statistic $\bar{x}$ to *expect* from all possible samples.
Then, after obtaining a sample and computing the sample mean, we could determine if the sample mean seems *consistent* with the assumption of two minutes, or whether it seems to *contradict* this assumption.
:::



## Tools for describing sampling variation

Making decisions about population [parameters](#StatisticsAndParameters) based on a sample statistic is difficult:
Only one of the many possible samples is selected, and every sample is likely to be different, and can produce a different value of the sample [statistic](#StatisticsAndParameters).
In this chapter, though, a process for making decisions has been studied
`r if( knitr::is_html_output()){
  '(Fig. \\@ref(fig:DecisionFlow)).'
} else {
  '(Fig. \\@ref(fig:DecisionFlow2)).'

}`

To apply this process to research, describe *how* sample statistics vary from sample to sample ([sampling variation](#def:SamplingVariation)) is necessary.
Some of those tools are discussed in the following chapters:

* Tools to describe the distribution of the population and the sample: Chap. \@ref(SamplingDistributions).
* Tools to describe how sample statistics vary from sample to sample (sampling variation), and hence what to expect from the sample statistic:  Chap. \@ref(SamplingVariation).
* Tools to describe the random nature of what happens with sample statistics,  and so determine if the sample statistic is consistent with the assumption:  Chap. \@ref(Probability).


## Summary {#Chap15-Summary}

Decisions are often made by making an *assumption* about the population parameter, which leads to an *expectation* of what might occur in the sample statistics.
We can then make *observations* about our sample, and then make a *decision* about whether the sample data support or contradict the initial assumption.


## Quick review questions {#Chap15-QuickReview}

::: {.webex-check .webex-box}
1. True or false: Parameters describe *populations*.\tightlist  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = TRUE )}`
1. True or false: Both $\bar{x}$ and $\mu$ are *statistics*.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = FALSE )}`
1. True or false: The value of a statistic is likely to be different in every sample.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = TRUE )}`
1. True or false: *Sampling variation* describes how the value of a *statistic* varies from sample to sample.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = TRUE )}`
1. True or false: The initial assumption is made about the *sample statistic*.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = FALSE )}`
1. True or false: The variation in statistics from sample to sample is called sampling variation
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = TRUE )}`
1. True or false: If the sample results seem inconsistent with what was expected, then the assumption about the population is probably true.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = FALSE )}`
1. True or false: In the sample, we know exactly what to expect.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = FALSE )}`
1. True or false: Hypotheses are made about the population.  
`r if( knitr::is_html_output(exclude = "epub") ) {torf(answer = TRUE )}`
:::




## Exercises {#MakingDecisionsExercises}

Selected answers are available in Sect. \@ref(MakingDecisionsAnswer).


::: {.exercise #MakingDecisionsDice}
Suppose you are playing a die-based game, and your opponent rolls a `r include_graphics("Dice/die6.png", dpi=1250)` ten times in a row.

1. Do you think there is a problem with the die?
1. Explain how you came to this decision.
:::


::: {.exercise #MakingDecisionsClaim}
In a 2012 advertisement, an Australian pizza company claimed that their 12-inch pizzas were 'real 12-inch pizzas' [@mypapers:Dunn:PizzaSize].

1. What is a reasonable assumption to make to test this claim?
1. The claim is based on a sample of 125 pizzas, for which the sample mean pizza diameter was $\bar{x} = 11.48$ inches.
   What are the two reasons why the sample mean is not 12-inches?
1. Does the claim appear to be supported by, or contradicted by, the data? 
   Why?
3. Would your conclusion change if the sample mean was $\bar{x} = 11.25$ inches, rather than 11.48 inches?
   Does the claim appear to be supported by, or contradicted by, the data? 
   Why?
1. Does your answer depend on the sample size?
   For example, is observing a sample mean of 11.25 inches from a sample of size 10 equivalent to observing a sample mean of 11.25 inches from a sample of size 125?
:::






<!-- QUICK REVIEW ANSWERS -->
`r if (knitr::is_html_output()) '<!--'`
::: {.EOCanswerBox .EOCanswer data-latex="{iconmonstr-check-mark-14-240.png}"}
**Answers to in-chapter questions:**

- \textbf{\textit{Quick Revision} questions:}
**1.** True.
**2.** False.
**3.** True.
**4.** True.
**5.** False.
**6.** True.
**7.** False.
**8.** False.
**9.** True.
:::
`r if (knitr::is_html_output()) '-->'`





